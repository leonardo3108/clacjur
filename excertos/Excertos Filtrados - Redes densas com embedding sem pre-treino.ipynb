{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD          DESCR_AREA                                           filtrado\n",
       "0  1400    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1  1700   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2  5700    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3   284  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4   298             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22972 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 30000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado'].astype(str))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'].astype(str))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " 269.96507339104255,\n",
       " 509,\n",
       " 142.93907674539003,\n",
       " 13285,\n",
       " 19,\n",
       " 0.0014301844185171245)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = 0\n",
    "lens = []\n",
    "for seq in sequences:\n",
    "    lens.append(len(seq))\n",
    "np.min(lens), np.mean(lens), np.max(lens), np.std(lens), len(lens), sum(pd.Series(lens) > limite_texto), sum(pd.Series(lens) > limite_texto)/len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(lens))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152.0, 240.0, 387.0, 500.0, 500.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(lens, 25), np.percentile(lens, 50), np.percentile(lens, 75), np.percentile(lens, 90), np.percentile(lens, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.358246697195892,\n",
       " 228.16377684126218,\n",
       " 0.2698266994442811,\n",
       " 2.897900096084454,\n",
       " 790.4967633680508)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.log10(lens)), 10**np.mean(np.log10(lens)), np.std(np.log10(lens)), (np.mean(np.log10(lens)) + 2*np.std(np.log10(lens))), 10**(np.mean(np.log10(lens)) + 2*np.std(np.log10(lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13285, 500), (13285, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1121 07:08:02.543875 139979849807680 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1121 07:08:02.642590 139979849807680 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1121 07:08:02.644637 139979849807680 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1121 07:08:02.672413 139979849807680 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1121 07:08:02.678738 139979849807680 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1121 07:08:02.679327 139979849807680 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1121 07:08:02.708112 139979849807680 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1121 07:08:02.730357 139979849807680 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1121 07:08:02.744158 139979849807680 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 106,807,774\n",
      "Trainable params: 106,807,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 07:08:10.973312 139979849807680 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 46s 4ms/step - loss: 1.2057 - categorical_accuracy: 0.5923 - val_loss: 1.3208 - val_categorical_accuracy: 0.5687\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.4248 - categorical_accuracy: 0.8739 - val_loss: 1.1662 - val_categorical_accuracy: 0.6628\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0991 - categorical_accuracy: 0.9794 - val_loss: 1.3808 - val_categorical_accuracy: 0.6970\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0689 - categorical_accuracy: 0.9928 - val_loss: 1.4814 - val_categorical_accuracy: 0.7117\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0595 - categorical_accuracy: 0.9944 - val_loss: 1.6122 - val_categorical_accuracy: 0.7098\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0633 - categorical_accuracy: 0.9946 - val_loss: 1.6201 - val_categorical_accuracy: 0.7132\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0561 - categorical_accuracy: 0.9953 - val_loss: 1.7653 - val_categorical_accuracy: 0.6767\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0598 - categorical_accuracy: 0.9950 - val_loss: 1.7139 - val_categorical_accuracy: 0.7151\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0535 - categorical_accuracy: 0.9954 - val_loss: 1.8128 - val_categorical_accuracy: 0.6933\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0537 - categorical_accuracy: 0.9952 - val_loss: 1.8043 - val_categorical_accuracy: 0.7102\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0522 - categorical_accuracy: 0.9955 - val_loss: 1.8315 - val_categorical_accuracy: 0.7049\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0471 - categorical_accuracy: 0.9954 - val_loss: 1.8558 - val_categorical_accuracy: 0.6978\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0530 - categorical_accuracy: 0.9956 - val_loss: 1.8413 - val_categorical_accuracy: 0.6997\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0528 - categorical_accuracy: 0.9955 - val_loss: 1.9412 - val_categorical_accuracy: 0.6899\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0461 - categorical_accuracy: 0.9960 - val_loss: 1.9299 - val_categorical_accuracy: 0.6940\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0591 - categorical_accuracy: 0.9953 - val_loss: 1.9708 - val_categorical_accuracy: 0.6839\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0535 - categorical_accuracy: 0.9960 - val_loss: 1.8992 - val_categorical_accuracy: 0.7049\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0531 - categorical_accuracy: 0.9955 - val_loss: 1.8620 - val_categorical_accuracy: 0.7083\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0466 - categorical_accuracy: 0.9957 - val_loss: 1.9625 - val_categorical_accuracy: 0.7030\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0470 - categorical_accuracy: 0.9955 - val_loss: 1.8925 - val_categorical_accuracy: 0.7102\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 106,807,774\n",
      "Trainable params: 106,807,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 1.2042 - categorical_accuracy: 0.5846 - val_loss: 1.0101 - val_categorical_accuracy: 0.6575\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.3964 - categorical_accuracy: 0.8833 - val_loss: 1.2089 - val_categorical_accuracy: 0.6492\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0806 - categorical_accuracy: 0.9881 - val_loss: 1.3639 - val_categorical_accuracy: 0.6729\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0472 - categorical_accuracy: 0.9943 - val_loss: 1.4536 - val_categorical_accuracy: 0.6891\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0430 - categorical_accuracy: 0.9941 - val_loss: 1.5684 - val_categorical_accuracy: 0.6722\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0354 - categorical_accuracy: 0.9946 - val_loss: 1.4426 - val_categorical_accuracy: 0.7004\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0295 - categorical_accuracy: 0.9947 - val_loss: 1.5510 - val_categorical_accuracy: 0.6921\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0313 - categorical_accuracy: 0.9943 - val_loss: 1.5560 - val_categorical_accuracy: 0.6955\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0264 - categorical_accuracy: 0.9946 - val_loss: 1.5554 - val_categorical_accuracy: 0.6978\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0261 - categorical_accuracy: 0.9951 - val_loss: 1.5317 - val_categorical_accuracy: 0.6854\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0225 - categorical_accuracy: 0.9950 - val_loss: 1.6311 - val_categorical_accuracy: 0.6914\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0244 - categorical_accuracy: 0.9945 - val_loss: 1.6148 - val_categorical_accuracy: 0.6944\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0224 - categorical_accuracy: 0.9947 - val_loss: 1.5320 - val_categorical_accuracy: 0.7019\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0218 - categorical_accuracy: 0.9947 - val_loss: 1.5876 - val_categorical_accuracy: 0.7004\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0190 - categorical_accuracy: 0.9947 - val_loss: 1.7463 - val_categorical_accuracy: 0.6827\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0202 - categorical_accuracy: 0.9945 - val_loss: 1.6737 - val_categorical_accuracy: 0.6967\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0198 - categorical_accuracy: 0.9952 - val_loss: 1.6076 - val_categorical_accuracy: 0.7072\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0196 - categorical_accuracy: 0.9946 - val_loss: 1.6855 - val_categorical_accuracy: 0.7034\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0192 - categorical_accuracy: 0.9945 - val_loss: 1.6746 - val_categorical_accuracy: 0.6997\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0206 - categorical_accuracy: 0.9948 - val_loss: 1.7199 - val_categorical_accuracy: 0.6997\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1121 08:17:46.472817 140551704823616 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1121 08:17:46.766660 140551704823616 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1121 08:17:46.795849 140551704823616 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1121 08:17:46.845992 140551704823616 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1121 08:17:46.852275 140551704823616 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1121 08:17:46.902267 140551704823616 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1121 08:17:46.915624 140551704823616 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1121 08:17:47.138247 140551704823616 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 57s 5ms/step - loss: 1.2095 - categorical_accuracy: 0.5870 - val_loss: 1.2284 - val_categorical_accuracy: 0.5529\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.3717 - categorical_accuracy: 0.8895 - val_loss: 1.1313 - val_categorical_accuracy: 0.6714\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0702 - categorical_accuracy: 0.9891 - val_loss: 1.3598 - val_categorical_accuracy: 0.6978\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0529 - categorical_accuracy: 0.9935 - val_loss: 1.4230 - val_categorical_accuracy: 0.6989\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0405 - categorical_accuracy: 0.9947 - val_loss: 1.4418 - val_categorical_accuracy: 0.6959\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0373 - categorical_accuracy: 0.9945 - val_loss: 1.4097 - val_categorical_accuracy: 0.7015\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0337 - categorical_accuracy: 0.9952 - val_loss: 1.5234 - val_categorical_accuracy: 0.7034\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0358 - categorical_accuracy: 0.9946 - val_loss: 1.4987 - val_categorical_accuracy: 0.7064\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0304 - categorical_accuracy: 0.9946 - val_loss: 1.5538 - val_categorical_accuracy: 0.7091\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0298 - categorical_accuracy: 0.9948 - val_loss: 1.4872 - val_categorical_accuracy: 0.7162\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0213 - categorical_accuracy: 0.9951 - val_loss: 1.6083 - val_categorical_accuracy: 0.6940\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0264 - categorical_accuracy: 0.9949 - val_loss: 1.6109 - val_categorical_accuracy: 0.7004\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0237 - categorical_accuracy: 0.9954 - val_loss: 1.5998 - val_categorical_accuracy: 0.6993\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0239 - categorical_accuracy: 0.9949 - val_loss: 1.6333 - val_categorical_accuracy: 0.7008\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0211 - categorical_accuracy: 0.9951 - val_loss: 1.5843 - val_categorical_accuracy: 0.7091\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0234 - categorical_accuracy: 0.9948 - val_loss: 1.6553 - val_categorical_accuracy: 0.7008\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0217 - categorical_accuracy: 0.9943 - val_loss: 1.5835 - val_categorical_accuracy: 0.7091\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0206 - categorical_accuracy: 0.9954 - val_loss: 1.6425 - val_categorical_accuracy: 0.7117\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0175 - categorical_accuracy: 0.9956 - val_loss: 1.6127 - val_categorical_accuracy: 0.7076\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0179 - categorical_accuracy: 0.9947 - val_loss: 1.6784 - val_categorical_accuracy: 0.7072\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 24s 2ms/step - loss: 1.2178 - categorical_accuracy: 0.5838 - val_loss: 0.9918 - val_categorical_accuracy: 0.6899\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.4143 - categorical_accuracy: 0.8741 - val_loss: 1.0777 - val_categorical_accuracy: 0.6850\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0811 - categorical_accuracy: 0.9855 - val_loss: 1.3140 - val_categorical_accuracy: 0.6970\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0579 - categorical_accuracy: 0.9937 - val_loss: 1.4560 - val_categorical_accuracy: 0.6872\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0503 - categorical_accuracy: 0.9944 - val_loss: 1.4681 - val_categorical_accuracy: 0.6921\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0412 - categorical_accuracy: 0.9946 - val_loss: 1.5541 - val_categorical_accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0391 - categorical_accuracy: 0.9942 - val_loss: 1.5444 - val_categorical_accuracy: 0.7117\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0367 - categorical_accuracy: 0.9945 - val_loss: 1.5341 - val_categorical_accuracy: 0.7113\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0327 - categorical_accuracy: 0.9950 - val_loss: 1.5494 - val_categorical_accuracy: 0.7121\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0321 - categorical_accuracy: 0.9948 - val_loss: 1.5237 - val_categorical_accuracy: 0.7158\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0288 - categorical_accuracy: 0.9945 - val_loss: 1.4714 - val_categorical_accuracy: 0.7219\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0244 - categorical_accuracy: 0.9951 - val_loss: 1.5742 - val_categorical_accuracy: 0.7053\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0288 - categorical_accuracy: 0.9950 - val_loss: 1.5257 - val_categorical_accuracy: 0.7166\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0225 - categorical_accuracy: 0.9949 - val_loss: 1.5718 - val_categorical_accuracy: 0.7125\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0229 - categorical_accuracy: 0.9949 - val_loss: 1.6063 - val_categorical_accuracy: 0.7046\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0217 - categorical_accuracy: 0.9948 - val_loss: 1.6562 - val_categorical_accuracy: 0.7098\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0225 - categorical_accuracy: 0.9955 - val_loss: 1.6238 - val_categorical_accuracy: 0.7053\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0214 - categorical_accuracy: 0.9950 - val_loss: 1.5972 - val_categorical_accuracy: 0.7162\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0222 - categorical_accuracy: 0.9951 - val_loss: 1.6055 - val_categorical_accuracy: 0.7200\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0205 - categorical_accuracy: 0.9953 - val_loss: 1.6019 - val_categorical_accuracy: 0.7158\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.2540 - categorical_accuracy: 0.5739 - val_loss: 1.2261 - val_categorical_accuracy: 0.5743\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.4316 - categorical_accuracy: 0.8691 - val_loss: 1.0657 - val_categorical_accuracy: 0.7015\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0921 - categorical_accuracy: 0.9814 - val_loss: 1.3899 - val_categorical_accuracy: 0.6948\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0483 - categorical_accuracy: 0.9939 - val_loss: 1.4154 - val_categorical_accuracy: 0.6970\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0392 - categorical_accuracy: 0.9944 - val_loss: 1.4939 - val_categorical_accuracy: 0.7106\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0388 - categorical_accuracy: 0.9936 - val_loss: 1.5316 - val_categorical_accuracy: 0.7143\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0314 - categorical_accuracy: 0.9947 - val_loss: 1.5414 - val_categorical_accuracy: 0.7189\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0301 - categorical_accuracy: 0.9947 - val_loss: 1.6466 - val_categorical_accuracy: 0.7034\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0331 - categorical_accuracy: 0.9940 - val_loss: 1.5646 - val_categorical_accuracy: 0.7162\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0250 - categorical_accuracy: 0.9948 - val_loss: 1.5946 - val_categorical_accuracy: 0.7196\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0309 - categorical_accuracy: 0.9943 - val_loss: 1.5882 - val_categorical_accuracy: 0.7174\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0207 - categorical_accuracy: 0.9955 - val_loss: 1.6851 - val_categorical_accuracy: 0.7046\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0213 - categorical_accuracy: 0.9953 - val_loss: 1.6461 - val_categorical_accuracy: 0.7189\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0253 - categorical_accuracy: 0.9946 - val_loss: 1.6179 - val_categorical_accuracy: 0.7245\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0221 - categorical_accuracy: 0.9953 - val_loss: 1.6576 - val_categorical_accuracy: 0.7174\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0194 - categorical_accuracy: 0.9954 - val_loss: 1.6704 - val_categorical_accuracy: 0.7219\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0199 - categorical_accuracy: 0.9951 - val_loss: 1.6807 - val_categorical_accuracy: 0.7155\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0207 - categorical_accuracy: 0.9946 - val_loss: 1.6671 - val_categorical_accuracy: 0.7117\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0174 - categorical_accuracy: 0.9949 - val_loss: 1.6575 - val_categorical_accuracy: 0.7279\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0178 - categorical_accuracy: 0.9946 - val_loss: 1.6584 - val_categorical_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 13s 1ms/step - loss: 1.2655 - categorical_accuracy: 0.5689 - val_loss: 0.9818 - val_categorical_accuracy: 0.6850\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.4720 - categorical_accuracy: 0.8557 - val_loss: 1.1743 - val_categorical_accuracy: 0.6466\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.1068 - categorical_accuracy: 0.9766 - val_loss: 1.3373 - val_categorical_accuracy: 0.6711\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0517 - categorical_accuracy: 0.9922 - val_loss: 1.4269 - val_categorical_accuracy: 0.7012\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0433 - categorical_accuracy: 0.9944 - val_loss: 1.4721 - val_categorical_accuracy: 0.7012\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0403 - categorical_accuracy: 0.9938 - val_loss: 1.6107 - val_categorical_accuracy: 0.6910\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0333 - categorical_accuracy: 0.9944 - val_loss: 1.5857 - val_categorical_accuracy: 0.7072\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0311 - categorical_accuracy: 0.9954 - val_loss: 1.6648 - val_categorical_accuracy: 0.6978\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0333 - categorical_accuracy: 0.9944 - val_loss: 1.6621 - val_categorical_accuracy: 0.7042\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0326 - categorical_accuracy: 0.9940 - val_loss: 1.6678 - val_categorical_accuracy: 0.6982\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0263 - categorical_accuracy: 0.9955 - val_loss: 1.6998 - val_categorical_accuracy: 0.7019\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0303 - categorical_accuracy: 0.9944 - val_loss: 1.6641 - val_categorical_accuracy: 0.6997\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0208 - categorical_accuracy: 0.9957 - val_loss: 1.7109 - val_categorical_accuracy: 0.6955\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0272 - categorical_accuracy: 0.9946 - val_loss: 1.6482 - val_categorical_accuracy: 0.7083\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0239 - categorical_accuracy: 0.9951 - val_loss: 1.6681 - val_categorical_accuracy: 0.7170\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0218 - categorical_accuracy: 0.9950 - val_loss: 1.7317 - val_categorical_accuracy: 0.7057\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0241 - categorical_accuracy: 0.9947 - val_loss: 1.7380 - val_categorical_accuracy: 0.6963\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0199 - categorical_accuracy: 0.9954 - val_loss: 1.7127 - val_categorical_accuracy: 0.7128\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0245 - categorical_accuracy: 0.9945 - val_loss: 1.6782 - val_categorical_accuracy: 0.7094\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0215 - categorical_accuracy: 0.9952 - val_loss: 1.8044 - val_categorical_accuracy: 0.6835\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 13s 1ms/step - loss: 1.2829 - categorical_accuracy: 0.5578 - val_loss: 1.0164 - val_categorical_accuracy: 0.6628\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.4816 - categorical_accuracy: 0.8555 - val_loss: 1.0343 - val_categorical_accuracy: 0.6820\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.1278 - categorical_accuracy: 0.9684 - val_loss: 1.2562 - val_categorical_accuracy: 0.6887\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0608 - categorical_accuracy: 0.9903 - val_loss: 1.4355 - val_categorical_accuracy: 0.6985\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0453 - categorical_accuracy: 0.9935 - val_loss: 1.5223 - val_categorical_accuracy: 0.7012\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0400 - categorical_accuracy: 0.9944 - val_loss: 1.5815 - val_categorical_accuracy: 0.6842\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0321 - categorical_accuracy: 0.9945 - val_loss: 1.6334 - val_categorical_accuracy: 0.6899\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0350 - categorical_accuracy: 0.9947 - val_loss: 1.6547 - val_categorical_accuracy: 0.6967\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0271 - categorical_accuracy: 0.9947 - val_loss: 1.7423 - val_categorical_accuracy: 0.6918\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0280 - categorical_accuracy: 0.9952 - val_loss: 1.7476 - val_categorical_accuracy: 0.6955\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0299 - categorical_accuracy: 0.9954 - val_loss: 1.7524 - val_categorical_accuracy: 0.6887\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0269 - categorical_accuracy: 0.9946 - val_loss: 1.8387 - val_categorical_accuracy: 0.6906\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0281 - categorical_accuracy: 0.9950 - val_loss: 1.7457 - val_categorical_accuracy: 0.7113\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0227 - categorical_accuracy: 0.9953 - val_loss: 1.7985 - val_categorical_accuracy: 0.7000\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.9955 - val_loss: 1.7519 - val_categorical_accuracy: 0.7110\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0250 - categorical_accuracy: 0.9946 - val_loss: 1.7464 - val_categorical_accuracy: 0.7042\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0235 - categorical_accuracy: 0.9946 - val_loss: 1.7279 - val_categorical_accuracy: 0.7053\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0226 - categorical_accuracy: 0.9949 - val_loss: 1.7204 - val_categorical_accuracy: 0.7087\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0158 - categorical_accuracy: 0.9956 - val_loss: 1.8122 - val_categorical_accuracy: 0.7091\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.0168 - categorical_accuracy: 0.9955 - val_loss: 1.8487 - val_categorical_accuracy: 0.7057\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
