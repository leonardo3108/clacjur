{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD          DESCR_AREA                                           filtrado\n",
       "0  1400    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1  1700   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2  5700    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3   284  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4   298             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22972 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 30000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 22972\n",
      "Encontrados no modelo: 18860 = 82.09994776249347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13285, 500), (13285, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 23:31:18.234893 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1201 23:31:18.315308 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1201 23:31:18.316971 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1201 23:31:18.324665 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1201 23:31:18.325224 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1201 23:31:19.225429 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1201 23:31:19.269268 140444132321088 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1201 23:31:19.366316 140444132321088 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 29,962\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 282us/step - loss: 1.2344 - categorical_accuracy: 0.6096 - val_loss: 1.2197 - val_categorical_accuracy: 0.5932\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1s 126us/step - loss: 0.7534 - categorical_accuracy: 0.7507 - val_loss: 1.2384 - val_categorical_accuracy: 0.6041\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1s 126us/step - loss: 0.6009 - categorical_accuracy: 0.8008 - val_loss: 1.0346 - val_categorical_accuracy: 0.6869\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1s 131us/step - loss: 0.4870 - categorical_accuracy: 0.8398 - val_loss: 1.6011 - val_categorical_accuracy: 0.5634\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1s 124us/step - loss: 0.4003 - categorical_accuracy: 0.8659 - val_loss: 1.0893 - val_categorical_accuracy: 0.7015\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1s 123us/step - loss: 0.3327 - categorical_accuracy: 0.8897 - val_loss: 1.2234 - val_categorical_accuracy: 0.6421\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1s 141us/step - loss: 0.2708 - categorical_accuracy: 0.9086 - val_loss: 1.1517 - val_categorical_accuracy: 0.6985\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1s 138us/step - loss: 0.2190 - categorical_accuracy: 0.9293 - val_loss: 1.1798 - val_categorical_accuracy: 0.6918\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1s 122us/step - loss: 0.1809 - categorical_accuracy: 0.9409 - val_loss: 1.3341 - val_categorical_accuracy: 0.6805\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1s 124us/step - loss: 0.1536 - categorical_accuracy: 0.9514 - val_loss: 1.4024 - val_categorical_accuracy: 0.6692\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1s 122us/step - loss: 0.1348 - categorical_accuracy: 0.9571 - val_loss: 1.4128 - val_categorical_accuracy: 0.6997\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1s 121us/step - loss: 0.1225 - categorical_accuracy: 0.9628 - val_loss: 2.3110 - val_categorical_accuracy: 0.5980\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1s 132us/step - loss: 0.1104 - categorical_accuracy: 0.9685 - val_loss: 1.9996 - val_categorical_accuracy: 0.6082\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1s 136us/step - loss: 0.1008 - categorical_accuracy: 0.9692 - val_loss: 1.6413 - val_categorical_accuracy: 0.6948\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1s 124us/step - loss: 0.0983 - categorical_accuracy: 0.9714 - val_loss: 1.5855 - val_categorical_accuracy: 0.6846\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1s 124us/step - loss: 0.0961 - categorical_accuracy: 0.9750 - val_loss: 1.8088 - val_categorical_accuracy: 0.6485\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1s 121us/step - loss: 0.0914 - categorical_accuracy: 0.9766 - val_loss: 1.7526 - val_categorical_accuracy: 0.6820\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1s 125us/step - loss: 0.0920 - categorical_accuracy: 0.9724 - val_loss: 1.9419 - val_categorical_accuracy: 0.6639\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1s 139us/step - loss: 0.0888 - categorical_accuracy: 0.9779 - val_loss: 1.9166 - val_categorical_accuracy: 0.6903\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 148us/step - loss: 0.0844 - categorical_accuracy: 0.9794 - val_loss: 2.1302 - val_categorical_accuracy: 0.6507\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 2,327,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 244us/step - loss: 1.1713 - categorical_accuracy: 0.6173 - val_loss: 1.2385 - val_categorical_accuracy: 0.5472\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 197us/step - loss: 0.7344 - categorical_accuracy: 0.7549 - val_loss: 1.3510 - val_categorical_accuracy: 0.5950\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 202us/step - loss: 0.5577 - categorical_accuracy: 0.8090 - val_loss: 1.0173 - val_categorical_accuracy: 0.7094\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 212us/step - loss: 0.4422 - categorical_accuracy: 0.8495 - val_loss: 1.1800 - val_categorical_accuracy: 0.6790\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.3391 - categorical_accuracy: 0.8855 - val_loss: 0.9930 - val_categorical_accuracy: 0.7072\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.2594 - categorical_accuracy: 0.9142 - val_loss: 1.1215 - val_categorical_accuracy: 0.7019\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 224us/step - loss: 0.1988 - categorical_accuracy: 0.9335 - val_loss: 1.2278 - val_categorical_accuracy: 0.6839\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 222us/step - loss: 0.1577 - categorical_accuracy: 0.9493 - val_loss: 1.3188 - val_categorical_accuracy: 0.6775\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 215us/step - loss: 0.1226 - categorical_accuracy: 0.9636 - val_loss: 1.3129 - val_categorical_accuracy: 0.6940\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 214us/step - loss: 0.1075 - categorical_accuracy: 0.9694 - val_loss: 1.3679 - val_categorical_accuracy: 0.6933\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 207us/step - loss: 0.0931 - categorical_accuracy: 0.9753 - val_loss: 1.8737 - val_categorical_accuracy: 0.6304\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 215us/step - loss: 0.0895 - categorical_accuracy: 0.9784 - val_loss: 1.5317 - val_categorical_accuracy: 0.6974\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 3s 241us/step - loss: 0.0814 - categorical_accuracy: 0.9814 - val_loss: 1.5325 - val_categorical_accuracy: 0.7030\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 219us/step - loss: 0.0848 - categorical_accuracy: 0.9792 - val_loss: 1.5904 - val_categorical_accuracy: 0.7064\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 218us/step - loss: 0.0731 - categorical_accuracy: 0.9830 - val_loss: 1.7493 - val_categorical_accuracy: 0.6906\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 208us/step - loss: 0.0770 - categorical_accuracy: 0.9849 - val_loss: 1.6625 - val_categorical_accuracy: 0.7136\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 222us/step - loss: 0.0837 - categorical_accuracy: 0.9839 - val_loss: 3.2059 - val_categorical_accuracy: 0.5318\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.0720 - categorical_accuracy: 0.9853 - val_loss: 1.7750 - val_categorical_accuracy: 0.6955\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 199us/step - loss: 0.0753 - categorical_accuracy: 0.9862 - val_loss: 2.4043 - val_categorical_accuracy: 0.6131\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.0778 - categorical_accuracy: 0.9868 - val_loss: 2.9401 - val_categorical_accuracy: 0.6150\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 2,327,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 242us/step - loss: 1.2283 - categorical_accuracy: 0.6292 - val_loss: 2.2550 - val_categorical_accuracy: 0.4042\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 191us/step - loss: 0.8249 - categorical_accuracy: 0.7419 - val_loss: 1.0259 - val_categorical_accuracy: 0.6865\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 191us/step - loss: 0.6712 - categorical_accuracy: 0.7890 - val_loss: 1.1973 - val_categorical_accuracy: 0.6470\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 197us/step - loss: 0.5671 - categorical_accuracy: 0.8278 - val_loss: 2.1247 - val_categorical_accuracy: 0.5740\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 203us/step - loss: 0.4911 - categorical_accuracy: 0.8479 - val_loss: 1.3115 - val_categorical_accuracy: 0.6650\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 195us/step - loss: 0.4146 - categorical_accuracy: 0.8786 - val_loss: 1.8852 - val_categorical_accuracy: 0.6199\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 195us/step - loss: 0.3552 - categorical_accuracy: 0.8933 - val_loss: 2.0250 - val_categorical_accuracy: 0.5849\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 218us/step - loss: 0.3030 - categorical_accuracy: 0.9114 - val_loss: 1.5965 - val_categorical_accuracy: 0.7083\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 217us/step - loss: 0.2613 - categorical_accuracy: 0.9249 - val_loss: 1.5899 - val_categorical_accuracy: 0.6940\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 199us/step - loss: 0.2435 - categorical_accuracy: 0.9338 - val_loss: 1.9709 - val_categorical_accuracy: 0.7204\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 202us/step - loss: 0.2391 - categorical_accuracy: 0.9400 - val_loss: 2.0343 - val_categorical_accuracy: 0.7015\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.2186 - categorical_accuracy: 0.9449 - val_loss: 2.0265 - val_categorical_accuracy: 0.7083\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 219us/step - loss: 0.2021 - categorical_accuracy: 0.9514 - val_loss: 2.3606 - val_categorical_accuracy: 0.7091\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.1809 - categorical_accuracy: 0.9581 - val_loss: 2.2616 - val_categorical_accuracy: 0.7200\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 199us/step - loss: 0.1836 - categorical_accuracy: 0.9612 - val_loss: 2.3966 - val_categorical_accuracy: 0.7335\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 206us/step - loss: 0.1819 - categorical_accuracy: 0.9611 - val_loss: 2.4364 - val_categorical_accuracy: 0.7079\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 225us/step - loss: 0.1799 - categorical_accuracy: 0.9656 - val_loss: 2.7200 - val_categorical_accuracy: 0.7125\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 210us/step - loss: 0.1666 - categorical_accuracy: 0.9669 - val_loss: 2.5810 - val_categorical_accuracy: 0.7211\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 207us/step - loss: 0.1720 - categorical_accuracy: 0.9683 - val_loss: 3.0096 - val_categorical_accuracy: 0.6722\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 229us/step - loss: 0.1674 - categorical_accuracy: 0.9697 - val_loss: 3.7978 - val_categorical_accuracy: 0.6394\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=5e-3),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,356,862\n",
      "Trainable params: 2,356,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 287us/step - loss: 1.1473 - categorical_accuracy: 0.6394 - val_loss: 1.9088 - val_categorical_accuracy: 0.4464\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 3s 241us/step - loss: 0.6954 - categorical_accuracy: 0.7693 - val_loss: 1.2796 - val_categorical_accuracy: 0.6157\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 235us/step - loss: 0.5123 - categorical_accuracy: 0.8312 - val_loss: 1.3291 - val_categorical_accuracy: 0.6135\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 230us/step - loss: 0.3757 - categorical_accuracy: 0.8754 - val_loss: 1.1342 - val_categorical_accuracy: 0.6963\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 3s 259us/step - loss: 0.2731 - categorical_accuracy: 0.9107 - val_loss: 1.1767 - val_categorical_accuracy: 0.6767\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 3s 236us/step - loss: 0.2031 - categorical_accuracy: 0.9401 - val_loss: 1.5523 - val_categorical_accuracy: 0.6680\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 3s 235us/step - loss: 0.1502 - categorical_accuracy: 0.9553 - val_loss: 1.1932 - val_categorical_accuracy: 0.7215\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 3s 239us/step - loss: 0.1299 - categorical_accuracy: 0.9626 - val_loss: 1.5792 - val_categorical_accuracy: 0.6793\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 3s 245us/step - loss: 0.1147 - categorical_accuracy: 0.9689 - val_loss: 1.4700 - val_categorical_accuracy: 0.7174\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 3s 239us/step - loss: 0.1020 - categorical_accuracy: 0.9756 - val_loss: 1.4806 - val_categorical_accuracy: 0.7004\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 3s 239us/step - loss: 0.0958 - categorical_accuracy: 0.9785 - val_loss: 1.7264 - val_categorical_accuracy: 0.6692\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 3s 242us/step - loss: 0.1072 - categorical_accuracy: 0.9764 - val_loss: 1.5583 - val_categorical_accuracy: 0.7027\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 234us/step - loss: 0.0959 - categorical_accuracy: 0.9809 - val_loss: 1.5991 - val_categorical_accuracy: 0.7110\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 3s 237us/step - loss: 0.0899 - categorical_accuracy: 0.9806 - val_loss: 1.9624 - val_categorical_accuracy: 0.6598\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 3s 243us/step - loss: 0.1007 - categorical_accuracy: 0.9811 - val_loss: 1.6646 - val_categorical_accuracy: 0.7076\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 3s 236us/step - loss: 0.0987 - categorical_accuracy: 0.9837 - val_loss: 1.8803 - val_categorical_accuracy: 0.6963\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 230us/step - loss: 0.0990 - categorical_accuracy: 0.9820 - val_loss: 1.8306 - val_categorical_accuracy: 0.7110\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 234us/step - loss: 0.0981 - categorical_accuracy: 0.9824 - val_loss: 2.0223 - val_categorical_accuracy: 0.6703\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 3s 236us/step - loss: 0.0887 - categorical_accuracy: 0.9859 - val_loss: 1.8084 - val_categorical_accuracy: 0.7102\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 232us/step - loss: 0.0972 - categorical_accuracy: 0.9849 - val_loss: 1.8792 - val_categorical_accuracy: 0.7305\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1201 23:34:10.835468 140444132321088 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,125,374\n",
      "Trainable params: 3,125,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 275us/step - loss: 1.3815 - categorical_accuracy: 0.6267 - val_loss: 1.5694 - val_categorical_accuracy: 0.6263\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 231us/step - loss: 0.6475 - categorical_accuracy: 0.7931 - val_loss: 1.1868 - val_categorical_accuracy: 0.7079\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 224us/step - loss: 0.4083 - categorical_accuracy: 0.8670 - val_loss: 1.3027 - val_categorical_accuracy: 0.6677\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 222us/step - loss: 0.2557 - categorical_accuracy: 0.9214 - val_loss: 1.6523 - val_categorical_accuracy: 0.6974\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 232us/step - loss: 0.1616 - categorical_accuracy: 0.9537 - val_loss: 1.7470 - val_categorical_accuracy: 0.7030\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 3s 241us/step - loss: 0.1333 - categorical_accuracy: 0.9652 - val_loss: 2.1433 - val_categorical_accuracy: 0.6756\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 232us/step - loss: 0.1183 - categorical_accuracy: 0.9721 - val_loss: 2.6703 - val_categorical_accuracy: 0.6609\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 224us/step - loss: 0.1052 - categorical_accuracy: 0.9762 - val_loss: 2.2811 - val_categorical_accuracy: 0.6997\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 3s 241us/step - loss: 0.1043 - categorical_accuracy: 0.9776 - val_loss: 2.6530 - val_categorical_accuracy: 0.7004\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 227us/step - loss: 0.0892 - categorical_accuracy: 0.9797 - val_loss: 3.1584 - val_categorical_accuracy: 0.6214\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 225us/step - loss: 0.0842 - categorical_accuracy: 0.9820 - val_loss: 2.6758 - val_categorical_accuracy: 0.6549\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 231us/step - loss: 0.0822 - categorical_accuracy: 0.9831 - val_loss: 3.1324 - val_categorical_accuracy: 0.6583\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 234us/step - loss: 0.0846 - categorical_accuracy: 0.9846 - val_loss: 2.9848 - val_categorical_accuracy: 0.6650\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 232us/step - loss: 0.0828 - categorical_accuracy: 0.9851 - val_loss: 2.7964 - val_categorical_accuracy: 0.7079\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 225us/step - loss: 0.0825 - categorical_accuracy: 0.9850 - val_loss: 3.5059 - val_categorical_accuracy: 0.6285\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 3s 237us/step - loss: 0.0771 - categorical_accuracy: 0.9843 - val_loss: 3.2174 - val_categorical_accuracy: 0.6680\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 0.0727 - categorical_accuracy: 0.9849 - val_loss: 3.0768 - val_categorical_accuracy: 0.6944\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 222us/step - loss: 0.0740 - categorical_accuracy: 0.9867 - val_loss: 3.4094 - val_categorical_accuracy: 0.6741\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 232us/step - loss: 0.0673 - categorical_accuracy: 0.9876 - val_loss: 3.9138 - val_categorical_accuracy: 0.6391\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 3s 236us/step - loss: 0.0772 - categorical_accuracy: 0.9861 - val_loss: 3.2312 - val_categorical_accuracy: 0.7008\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,950,622\n",
      "Trainable params: 3,950,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 323us/step - loss: 1.5076 - categorical_accuracy: 0.6405 - val_loss: 1.4006 - val_categorical_accuracy: 0.5687\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 3s 283us/step - loss: 0.6542 - categorical_accuracy: 0.7891 - val_loss: 1.2637 - val_categorical_accuracy: 0.6903\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 3s 278us/step - loss: 0.3709 - categorical_accuracy: 0.8837 - val_loss: 1.8541 - val_categorical_accuracy: 0.6078\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 3s 274us/step - loss: 0.2344 - categorical_accuracy: 0.9325 - val_loss: 1.6576 - val_categorical_accuracy: 0.6443\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 3s 285us/step - loss: 0.1766 - categorical_accuracy: 0.9561 - val_loss: 1.9610 - val_categorical_accuracy: 0.6620\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 3s 275us/step - loss: 0.1369 - categorical_accuracy: 0.9674 - val_loss: 2.3903 - val_categorical_accuracy: 0.6955\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 3s 275us/step - loss: 0.1210 - categorical_accuracy: 0.9751 - val_loss: 3.7898 - val_categorical_accuracy: 0.5702\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 3s 285us/step - loss: 0.1134 - categorical_accuracy: 0.9768 - val_loss: 2.4788 - val_categorical_accuracy: 0.6714\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 3s 272us/step - loss: 0.1088 - categorical_accuracy: 0.9778 - val_loss: 2.6363 - val_categorical_accuracy: 0.6699\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 3s 280us/step - loss: 0.1109 - categorical_accuracy: 0.9772 - val_loss: 3.7888 - val_categorical_accuracy: 0.5785\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 3s 293us/step - loss: 0.1141 - categorical_accuracy: 0.9783 - val_loss: 2.7642 - val_categorical_accuracy: 0.7004\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 3s 289us/step - loss: 0.0982 - categorical_accuracy: 0.9835 - val_loss: 3.3671 - val_categorical_accuracy: 0.6300\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 3s 287us/step - loss: 0.0937 - categorical_accuracy: 0.9818 - val_loss: 3.8735 - val_categorical_accuracy: 0.6451\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 3s 293us/step - loss: 0.0956 - categorical_accuracy: 0.9816 - val_loss: 3.7650 - val_categorical_accuracy: 0.6112\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 3s 284us/step - loss: 0.0781 - categorical_accuracy: 0.9860 - val_loss: 3.4702 - val_categorical_accuracy: 0.6729\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 3s 291us/step - loss: 0.0948 - categorical_accuracy: 0.9829 - val_loss: 3.2988 - val_categorical_accuracy: 0.6903\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 3s 294us/step - loss: 0.0932 - categorical_accuracy: 0.9835 - val_loss: 3.3555 - val_categorical_accuracy: 0.6880\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 3s 289us/step - loss: 0.0912 - categorical_accuracy: 0.9832 - val_loss: 3.8642 - val_categorical_accuracy: 0.6342\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 3s 299us/step - loss: 0.0948 - categorical_accuracy: 0.9855 - val_loss: 3.5352 - val_categorical_accuracy: 0.6782\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 3s 301us/step - loss: 0.0880 - categorical_accuracy: 0.9845 - val_loss: 3.5894 - val_categorical_accuracy: 0.6914\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,551,454\n",
      "Trainable params: 2,551,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 1.1846 - categorical_accuracy: 0.5979 - val_loss: 1.5202 - val_categorical_accuracy: 0.5066\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.8102 - categorical_accuracy: 0.7240 - val_loss: 1.0405 - val_categorical_accuracy: 0.6477\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.6617 - categorical_accuracy: 0.7787 - val_loss: 0.9022 - val_categorical_accuracy: 0.7087\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.5653 - categorical_accuracy: 0.8098 - val_loss: 1.0133 - val_categorical_accuracy: 0.6639\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.4786 - categorical_accuracy: 0.8392 - val_loss: 0.9209 - val_categorical_accuracy: 0.7012\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.4210 - categorical_accuracy: 0.8616 - val_loss: 0.8409 - val_categorical_accuracy: 0.7207\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.3655 - categorical_accuracy: 0.8758 - val_loss: 0.9959 - val_categorical_accuracy: 0.7121\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.3114 - categorical_accuracy: 0.8953 - val_loss: 0.9017 - val_categorical_accuracy: 0.7275\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.2609 - categorical_accuracy: 0.9131 - val_loss: 1.1291 - val_categorical_accuracy: 0.6970\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.2247 - categorical_accuracy: 0.9213 - val_loss: 1.7202 - val_categorical_accuracy: 0.5834\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.1993 - categorical_accuracy: 0.9314 - val_loss: 1.0732 - val_categorical_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.1609 - categorical_accuracy: 0.9473 - val_loss: 1.0244 - val_categorical_accuracy: 0.7497\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.1481 - categorical_accuracy: 0.9493 - val_loss: 1.0857 - val_categorical_accuracy: 0.7463\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.1335 - categorical_accuracy: 0.9562 - val_loss: 1.2400 - val_categorical_accuracy: 0.7298\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.1251 - categorical_accuracy: 0.9595 - val_loss: 1.1723 - val_categorical_accuracy: 0.7350\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1045 - categorical_accuracy: 0.9634 - val_loss: 1.2296 - val_categorical_accuracy: 0.7490\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0932 - categorical_accuracy: 0.9671 - val_loss: 1.4104 - val_categorical_accuracy: 0.7241\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0900 - categorical_accuracy: 0.9700 - val_loss: 1.4323 - val_categorical_accuracy: 0.7117\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0899 - categorical_accuracy: 0.9697 - val_loss: 1.6428 - val_categorical_accuracy: 0.7061\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0822 - categorical_accuracy: 0.9736 - val_loss: 1.4925 - val_categorical_accuracy: 0.7403\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,581,054\n",
      "Trainable params: 2,581,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 1.1722 - categorical_accuracy: 0.6062 - val_loss: 1.2299 - val_categorical_accuracy: 0.5852\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.7940 - categorical_accuracy: 0.7301 - val_loss: 0.9528 - val_categorical_accuracy: 0.6823\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.6310 - categorical_accuracy: 0.7891 - val_loss: 1.4494 - val_categorical_accuracy: 0.5661\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.5173 - categorical_accuracy: 0.8250 - val_loss: 0.8183 - val_categorical_accuracy: 0.7396\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.4280 - categorical_accuracy: 0.8590 - val_loss: 1.0142 - val_categorical_accuracy: 0.6891\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 37s 4ms/step - loss: 0.3530 - categorical_accuracy: 0.8809 - val_loss: 0.7618 - val_categorical_accuracy: 0.7580\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.2814 - categorical_accuracy: 0.9075 - val_loss: 0.9242 - val_categorical_accuracy: 0.7324\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.2266 - categorical_accuracy: 0.9260 - val_loss: 0.7995 - val_categorical_accuracy: 0.7840\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 37s 4ms/step - loss: 0.1825 - categorical_accuracy: 0.9371 - val_loss: 1.2637 - val_categorical_accuracy: 0.6948\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1527 - categorical_accuracy: 0.9485 - val_loss: 1.0424 - val_categorical_accuracy: 0.7486\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1327 - categorical_accuracy: 0.9566 - val_loss: 1.0110 - val_categorical_accuracy: 0.7618\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1089 - categorical_accuracy: 0.9641 - val_loss: 1.2548 - val_categorical_accuracy: 0.7317\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1037 - categorical_accuracy: 0.9669 - val_loss: 1.1212 - val_categorical_accuracy: 0.7569\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0932 - categorical_accuracy: 0.9707 - val_loss: 1.2384 - val_categorical_accuracy: 0.7369\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0814 - categorical_accuracy: 0.9752 - val_loss: 1.2205 - val_categorical_accuracy: 0.7493\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0921 - categorical_accuracy: 0.9684 - val_loss: 1.7589 - val_categorical_accuracy: 0.6714\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0785 - categorical_accuracy: 0.9752 - val_loss: 1.3558 - val_categorical_accuracy: 0.7347\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0738 - categorical_accuracy: 0.9768 - val_loss: 1.4018 - val_categorical_accuracy: 0.7309\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0668 - categorical_accuracy: 0.9783 - val_loss: 1.3371 - val_categorical_accuracy: 0.7396\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0640 - categorical_accuracy: 0.9803 - val_loss: 1.3655 - val_categorical_accuracy: 0.7486\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               61824     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,390,046\n",
      "Trainable params: 2,390,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.1601 - categorical_accuracy: 0.6161 - val_loss: 1.1219 - val_categorical_accuracy: 0.6342\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.8024 - categorical_accuracy: 0.7317 - val_loss: 1.1276 - val_categorical_accuracy: 0.6334\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.6781 - categorical_accuracy: 0.7711 - val_loss: 1.2264 - val_categorical_accuracy: 0.5736\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.5811 - categorical_accuracy: 0.8065 - val_loss: 0.9833 - val_categorical_accuracy: 0.6756\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.5046 - categorical_accuracy: 0.8312 - val_loss: 0.9092 - val_categorical_accuracy: 0.7204\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.4469 - categorical_accuracy: 0.8504 - val_loss: 0.7779 - val_categorical_accuracy: 0.7576\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.3875 - categorical_accuracy: 0.8724 - val_loss: 0.8667 - val_categorical_accuracy: 0.7185\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 44s 4ms/step - loss: 0.3414 - categorical_accuracy: 0.8839 - val_loss: 0.8917 - val_categorical_accuracy: 0.7290\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.2950 - categorical_accuracy: 0.9013 - val_loss: 0.9675 - val_categorical_accuracy: 0.7230\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.2537 - categorical_accuracy: 0.9137 - val_loss: 1.0196 - val_categorical_accuracy: 0.7072\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2224 - categorical_accuracy: 0.9249 - val_loss: 0.8735 - val_categorical_accuracy: 0.7561\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.1880 - categorical_accuracy: 0.9375 - val_loss: 1.2780 - val_categorical_accuracy: 0.6827\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.1648 - categorical_accuracy: 0.9428 - val_loss: 0.9422 - val_categorical_accuracy: 0.7595\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.1499 - categorical_accuracy: 0.9524 - val_loss: 1.2343 - val_categorical_accuracy: 0.6955\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.1231 - categorical_accuracy: 0.9578 - val_loss: 1.0893 - val_categorical_accuracy: 0.7381\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.1117 - categorical_accuracy: 0.9625 - val_loss: 1.2121 - val_categorical_accuracy: 0.7253\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0997 - categorical_accuracy: 0.9669 - val_loss: 1.2270 - val_categorical_accuracy: 0.7407\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0968 - categorical_accuracy: 0.9684 - val_loss: 1.2336 - val_categorical_accuracy: 0.7275\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.0852 - categorical_accuracy: 0.9710 - val_loss: 1.2631 - val_categorical_accuracy: 0.7283\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0779 - categorical_accuracy: 0.9739 - val_loss: 1.2826 - val_categorical_accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
