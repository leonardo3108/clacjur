{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_EXCERTO</th>\n",
       "      <th>TEXTO_EXCERTO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995438</td>\n",
       "      <td>Voto:Cuidam os autos de tomada de contas espec...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025603</td>\n",
       "      <td>Voto:Cuidam os autos de Solicitação do Congres...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455375</td>\n",
       "      <td>Relatório:Trata-se de embargos de declaração o...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773747</td>\n",
       "      <td>Voto:8. Em relação a outros processos judiciai...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773403</td>\n",
       "      <td>Voto:11. Relativamente ao ato envolvendo a Sra...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_EXCERTO  \\\n",
       "0  Benefício previdenciário                    54995438   \n",
       "1                  Petróleo                    55025603   \n",
       "2                Dosimetria                    55455375   \n",
       "3          Decisão judicial                    54773747   \n",
       "4                 Nepotismo                    54773403   \n",
       "\n",
       "                                       TEXTO_EXCERTO                ACORDAO  \\\n",
       "0  Voto:Cuidam os autos de tomada de contas espec...  Acórdão 297/2016 - PL   \n",
       "1  Voto:Cuidam os autos de Solicitação do Congres...  Acórdão 366/2016 - PL   \n",
       "2  Relatório:Trata-se de embargos de declaração o...  Acórdão 944/2016 - PL   \n",
       "3  Voto:8. Em relação a outros processos judiciai...   Acórdão 30/2016 - PL   \n",
       "4  Voto:11. Relativamente ao ato envolvendo a Sra...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_excertos.CSV', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCR_AREA\n",
       "Competência do TCU          553\n",
       "Contrato Administrativo     941\n",
       "Convênio                    683\n",
       "Desestatização              139\n",
       "Direito Processual         1811\n",
       "Finanças Públicas           328\n",
       "Gestão Administrativa       338\n",
       "Licitação                  2756\n",
       "Pessoal                    3393\n",
       "Responsabilidade           2343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DESCR_AREA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63925 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "limite_texto = 2000\n",
    "dim_vetor = 50\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TEXTO_EXCERTO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_EXCERTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 2000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos-50.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 63925\n",
      "Encontrados no modelo: 43317 = 67.76222135314822\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model.wv:\n",
    "        embedding_matrix[i] = model.wv[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1117 10:51:56.173063 140664023926592 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1117 10:51:56.232472 140664023926592 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1117 10:51:56.234180 140664023926592 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1117 10:51:56.242867 140664023926592 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1117 10:51:56.243608 140664023926592 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1117 10:51:57.569685 140664023926592 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1117 10:51:57.678362 140664023926592 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 238,346\n",
      "Non-trainable params: 3,196,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 496s 47ms/step - loss: 1.1887 - categorical_accuracy: 0.6107 - val_loss: 1.5734 - val_categorical_accuracy: 0.4275\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 494s 47ms/step - loss: 0.6477 - categorical_accuracy: 0.7839 - val_loss: 1.0583 - val_categorical_accuracy: 0.6658\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 495s 47ms/step - loss: 0.4769 - categorical_accuracy: 0.8357 - val_loss: 0.7587 - val_categorical_accuracy: 0.7610\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 495s 47ms/step - loss: 0.3669 - categorical_accuracy: 0.8740 - val_loss: 0.9401 - val_categorical_accuracy: 0.7076\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 495s 47ms/step - loss: 0.2792 - categorical_accuracy: 0.9056 - val_loss: 1.0349 - val_categorical_accuracy: 0.6850\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 495s 47ms/step - loss: 0.2101 - categorical_accuracy: 0.9275 - val_loss: 0.7906 - val_categorical_accuracy: 0.7697\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 495s 47ms/step - loss: 0.1498 - categorical_accuracy: 0.9510 - val_loss: 1.0730 - val_categorical_accuracy: 0.7087\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 495s 47ms/step - loss: 0.1144 - categorical_accuracy: 0.9655 - val_loss: 0.9197 - val_categorical_accuracy: 0.7731\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 514s 48ms/step - loss: 0.0882 - categorical_accuracy: 0.9724 - val_loss: 1.4481 - val_categorical_accuracy: 0.6692\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 543s 51ms/step - loss: 0.0708 - categorical_accuracy: 0.9805 - val_loss: 1.1466 - val_categorical_accuracy: 0.7539\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 572s 54ms/step - loss: 0.0672 - categorical_accuracy: 0.9823 - val_loss: 1.0856 - val_categorical_accuracy: 0.7670\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 573s 54ms/step - loss: 0.0578 - categorical_accuracy: 0.9837 - val_loss: 1.2501 - val_categorical_accuracy: 0.7369\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 587s 55ms/step - loss: 0.0523 - categorical_accuracy: 0.9860 - val_loss: 1.3440 - val_categorical_accuracy: 0.7411\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 542s 51ms/step - loss: 0.0523 - categorical_accuracy: 0.9860 - val_loss: 1.2650 - val_categorical_accuracy: 0.7486\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 512s 48ms/step - loss: 0.0498 - categorical_accuracy: 0.9868 - val_loss: 1.2704 - val_categorical_accuracy: 0.7478\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 500s 47ms/step - loss: 0.0457 - categorical_accuracy: 0.9888 - val_loss: 1.2878 - val_categorical_accuracy: 0.7606\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 498s 47ms/step - loss: 0.0438 - categorical_accuracy: 0.9891 - val_loss: 1.3969 - val_categorical_accuracy: 0.7490\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 497s 47ms/step - loss: 0.0409 - categorical_accuracy: 0.9889 - val_loss: 1.3372 - val_categorical_accuracy: 0.7561\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 498s 47ms/step - loss: 0.0430 - categorical_accuracy: 0.9885 - val_loss: 1.3764 - val_categorical_accuracy: 0.7527\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 497s 47ms/step - loss: 0.0425 - categorical_accuracy: 0.9888 - val_loss: 1.3151 - val_categorical_accuracy: 0.7603\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1724 - categorical_accuracy: 0.6154 - val_loss: 1.3386 - val_categorical_accuracy: 0.5292\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.6532 - categorical_accuracy: 0.7811 - val_loss: 0.9189 - val_categorical_accuracy: 0.6887\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 538s 51ms/step - loss: 0.4669 - categorical_accuracy: 0.8430 - val_loss: 0.8804 - val_categorical_accuracy: 0.7015\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.3520 - categorical_accuracy: 0.8812 - val_loss: 0.7966 - val_categorical_accuracy: 0.7403\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.2587 - categorical_accuracy: 0.9126 - val_loss: 1.0453 - val_categorical_accuracy: 0.6910\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.1882 - categorical_accuracy: 0.9361 - val_loss: 0.9855 - val_categorical_accuracy: 0.7422\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.1336 - categorical_accuracy: 0.9553 - val_loss: 0.8879 - val_categorical_accuracy: 0.7576\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0855 - categorical_accuracy: 0.9730 - val_loss: 1.0039 - val_categorical_accuracy: 0.7463\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.1625 - categorical_accuracy: 0.9475 - val_loss: 0.9761 - val_categorical_accuracy: 0.7644\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 540s 51ms/step - loss: 0.1038 - categorical_accuracy: 0.9684 - val_loss: 1.0096 - val_categorical_accuracy: 0.7561\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0586 - categorical_accuracy: 0.7966 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 540s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 540s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 540s 51ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               314368    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,513,238\n",
      "Trainable params: 3,513,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 664s 63ms/step - loss: 1.2672 - categorical_accuracy: 0.5850 - val_loss: 1.2962 - val_categorical_accuracy: 0.5551\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.9211 - categorical_accuracy: 0.6916 - val_loss: 1.1158 - val_categorical_accuracy: 0.6229\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 664s 63ms/step - loss: 0.7668 - categorical_accuracy: 0.7501 - val_loss: 1.0579 - val_categorical_accuracy: 0.6383\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.6383 - categorical_accuracy: 0.7897 - val_loss: 0.8996 - val_categorical_accuracy: 0.7219\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.5348 - categorical_accuracy: 0.8209 - val_loss: 1.0068 - val_categorical_accuracy: 0.6831\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.4596 - categorical_accuracy: 0.8461 - val_loss: 0.8875 - val_categorical_accuracy: 0.7185\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.3730 - categorical_accuracy: 0.8738 - val_loss: 0.8803 - val_categorical_accuracy: 0.7381\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 664s 62ms/step - loss: 0.3156 - categorical_accuracy: 0.8956 - val_loss: 0.9381 - val_categorical_accuracy: 0.7226\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 664s 62ms/step - loss: 0.2615 - categorical_accuracy: 0.9130 - val_loss: 0.9065 - val_categorical_accuracy: 0.7286\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 664s 62ms/step - loss: 0.2060 - categorical_accuracy: 0.9336 - val_loss: 0.9244 - val_categorical_accuracy: 0.7279\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 664s 62ms/step - loss: 0.1835 - categorical_accuracy: 0.9413 - val_loss: 0.9862 - val_categorical_accuracy: 0.7392\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.1445 - categorical_accuracy: 0.9539 - val_loss: 1.1082 - val_categorical_accuracy: 0.7140\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.1253 - categorical_accuracy: 0.9584 - val_loss: 1.0544 - val_categorical_accuracy: 0.7437\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.0977 - categorical_accuracy: 0.9679 - val_loss: 1.1603 - val_categorical_accuracy: 0.7294\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 663s 62ms/step - loss: 0.0785 - categorical_accuracy: 0.9762 - val_loss: 1.2055 - val_categorical_accuracy: 0.7290\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 664s 62ms/step - loss: 0.0691 - categorical_accuracy: 0.9800 - val_loss: 1.2055 - val_categorical_accuracy: 0.7418\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 668s 63ms/step - loss: 0.0589 - categorical_accuracy: 0.9821 - val_loss: 1.2440 - val_categorical_accuracy: 0.7411\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 664s 63ms/step - loss: 0.0532 - categorical_accuracy: 0.9843 - val_loss: 1.3048 - val_categorical_accuracy: 0.7362\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.0489 - categorical_accuracy: 0.9862 - val_loss: 1.3429 - val_categorical_accuracy: 0.7399\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 674s 63ms/step - loss: 0.0419 - categorical_accuracy: 0.9881 - val_loss: 1.2777 - val_categorical_accuracy: 0.7478\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               471552    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,672,982\n",
      "Trainable params: 3,672,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 1069s 101ms/step - loss: 1.1831 - categorical_accuracy: 0.6103 - val_loss: 1.0216 - val_categorical_accuracy: 0.6703\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.6487 - categorical_accuracy: 0.7855 - val_loss: 0.9203 - val_categorical_accuracy: 0.7132\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1122s 106ms/step - loss: 0.4597 - categorical_accuracy: 0.8454 - val_loss: 0.8253 - val_categorical_accuracy: 0.7264\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1124s 106ms/step - loss: 0.3546 - categorical_accuracy: 0.8808 - val_loss: 0.8373 - val_categorical_accuracy: 0.7460\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.2634 - categorical_accuracy: 0.9116 - val_loss: 0.9481 - val_categorical_accuracy: 0.7264\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1125s 106ms/step - loss: 0.1922 - categorical_accuracy: 0.9373 - val_loss: 1.2322 - val_categorical_accuracy: 0.6515\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1131s 106ms/step - loss: 0.1366 - categorical_accuracy: 0.9545 - val_loss: 0.9508 - val_categorical_accuracy: 0.7508\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1129s 106ms/step - loss: 0.1007 - categorical_accuracy: 0.9689 - val_loss: 0.9853 - val_categorical_accuracy: 0.7584\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1130s 106ms/step - loss: 0.0825 - categorical_accuracy: 0.9756 - val_loss: 0.9776 - val_categorical_accuracy: 0.7753\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1139s 107ms/step - loss: 0.3015 - categorical_accuracy: 0.9228 - val_loss: 1.0683 - val_categorical_accuracy: 0.7444\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1139s 107ms/step - loss: 0.1145 - categorical_accuracy: 0.9637 - val_loss: 1.0617 - val_categorical_accuracy: 0.7603\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.0792 - categorical_accuracy: 0.9749 - val_loss: 1.1694 - val_categorical_accuracy: 0.7482\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1035s 97ms/step - loss: 0.0716 - categorical_accuracy: 0.9771 - val_loss: 1.0816 - val_categorical_accuracy: 0.7640\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 975s 92ms/step - loss: 0.0488 - categorical_accuracy: 0.9872 - val_loss: 1.2544 - val_categorical_accuracy: 0.7448\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 974s 92ms/step - loss: 0.1901 - categorical_accuracy: 0.9342 - val_loss: 1.2041 - val_categorical_accuracy: 0.7335\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 974s 92ms/step - loss: 0.1895 - categorical_accuracy: 0.9325 - val_loss: 1.2460 - val_categorical_accuracy: 0.7591\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 975s 92ms/step - loss: 0.0527 - categorical_accuracy: 0.9849 - val_loss: 1.2366 - val_categorical_accuracy: 0.7505\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 976s 92ms/step - loss: 0.0566 - categorical_accuracy: 0.9865 - val_loss: 1.2118 - val_categorical_accuracy: 0.7625\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 976s 92ms/step - loss: 0.0507 - categorical_accuracy: 0.9877 - val_loss: 1.3371 - val_categorical_accuracy: 0.7674\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 976s 92ms/step - loss: 0.0502 - categorical_accuracy: 0.9870 - val_loss: 1.2075 - val_categorical_accuracy: 0.7685\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(GRU(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 128)               68736     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,266,326\n",
      "Trainable params: 3,266,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 1.3138 - categorical_accuracy: 0.5663 - val_loss: 1.5275 - val_categorical_accuracy: 0.5250\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.8179 - categorical_accuracy: 0.7260 - val_loss: 1.0089 - val_categorical_accuracy: 0.6590\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.6332 - categorical_accuracy: 0.7889 - val_loss: 1.0489 - val_categorical_accuracy: 0.6255\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.5147 - categorical_accuracy: 0.8321 - val_loss: 0.9064 - val_categorical_accuracy: 0.7121\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.4223 - categorical_accuracy: 0.8611 - val_loss: 0.8328 - val_categorical_accuracy: 0.7392\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.3433 - categorical_accuracy: 0.8899 - val_loss: 0.8307 - val_categorical_accuracy: 0.7362\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.2850 - categorical_accuracy: 0.9059 - val_loss: 0.8953 - val_categorical_accuracy: 0.7414\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.2152 - categorical_accuracy: 0.9306 - val_loss: 0.8304 - val_categorical_accuracy: 0.7580\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.1709 - categorical_accuracy: 0.9479 - val_loss: 0.8896 - val_categorical_accuracy: 0.7426\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.1518 - categorical_accuracy: 0.9525 - val_loss: 1.0083 - val_categorical_accuracy: 0.7162\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.1158 - categorical_accuracy: 0.9623 - val_loss: 1.0018 - val_categorical_accuracy: 0.7411\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0894 - categorical_accuracy: 0.9737 - val_loss: 1.1011 - val_categorical_accuracy: 0.7475\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0855 - categorical_accuracy: 0.9753 - val_loss: 1.0946 - val_categorical_accuracy: 0.7392\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0655 - categorical_accuracy: 0.9805 - val_loss: 1.1435 - val_categorical_accuracy: 0.7448\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0555 - categorical_accuracy: 0.9849 - val_loss: 1.1738 - val_categorical_accuracy: 0.7422\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0480 - categorical_accuracy: 0.9865 - val_loss: 1.2918 - val_categorical_accuracy: 0.7388\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0423 - categorical_accuracy: 0.9881 - val_loss: 1.3685 - val_categorical_accuracy: 0.7283\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0393 - categorical_accuracy: 0.9888 - val_loss: 1.2696 - val_categorical_accuracy: 0.7557\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0406 - categorical_accuracy: 0.9888 - val_loss: 1.4703 - val_categorical_accuracy: 0.7565\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0396 - categorical_accuracy: 0.9894 - val_loss: 1.3044 - val_categorical_accuracy: 0.7535\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                22080     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,219,030\n",
      "Trainable params: 3,219,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 1.5150 - categorical_accuracy: 0.4932 - val_loss: 1.4853 - val_categorical_accuracy: 0.4953\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.9883 - categorical_accuracy: 0.6738 - val_loss: 1.2391 - val_categorical_accuracy: 0.5800\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.7879 - categorical_accuracy: 0.7381 - val_loss: 1.0282 - val_categorical_accuracy: 0.6703\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 553s 52ms/step - loss: 0.6795 - categorical_accuracy: 0.7751 - val_loss: 1.0872 - val_categorical_accuracy: 0.6391\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.5952 - categorical_accuracy: 0.8047 - val_loss: 0.9845 - val_categorical_accuracy: 0.6801\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.5283 - categorical_accuracy: 0.8280 - val_loss: 0.9269 - val_categorical_accuracy: 0.7038\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.4657 - categorical_accuracy: 0.8524 - val_loss: 0.9109 - val_categorical_accuracy: 0.7117\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.4088 - categorical_accuracy: 0.8677 - val_loss: 1.0763 - val_categorical_accuracy: 0.6699\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 553s 52ms/step - loss: 0.3639 - categorical_accuracy: 0.8832 - val_loss: 0.9314 - val_categorical_accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.3374 - categorical_accuracy: 0.8911 - val_loss: 1.0586 - val_categorical_accuracy: 0.6756\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.2806 - categorical_accuracy: 0.9121 - val_loss: 1.0443 - val_categorical_accuracy: 0.7030\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.2412 - categorical_accuracy: 0.9217 - val_loss: 1.0173 - val_categorical_accuracy: 0.7237\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.2063 - categorical_accuracy: 0.9325 - val_loss: 1.0624 - val_categorical_accuracy: 0.7237\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 553s 52ms/step - loss: 0.1752 - categorical_accuracy: 0.9474 - val_loss: 1.1921 - val_categorical_accuracy: 0.7042\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.1465 - categorical_accuracy: 0.9551 - val_loss: 1.1751 - val_categorical_accuracy: 0.6989\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.1261 - categorical_accuracy: 0.9613 - val_loss: 1.2257 - val_categorical_accuracy: 0.6955\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 553s 52ms/step - loss: 0.1049 - categorical_accuracy: 0.9678 - val_loss: 1.3638 - val_categorical_accuracy: 0.6801\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0882 - categorical_accuracy: 0.9750 - val_loss: 1.3584 - val_categorical_accuracy: 0.7038\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0763 - categorical_accuracy: 0.9791 - val_loss: 1.3568 - val_categorical_accuracy: 0.7155\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0670 - categorical_accuracy: 0.9808 - val_loss: 1.4163 - val_categorical_accuracy: 0.7192\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 512)               864768    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,066,198\n",
      "Trainable params: 4,066,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 538s 51ms/step - loss: 1.1404 - categorical_accuracy: 0.6228 - val_loss: 1.3085 - val_categorical_accuracy: 0.5269\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 538s 51ms/step - loss: 0.5759 - categorical_accuracy: 0.8060 - val_loss: 0.8210 - val_categorical_accuracy: 0.7335\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.4092 - categorical_accuracy: 0.8606 - val_loss: 0.7494 - val_categorical_accuracy: 0.7697\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.2927 - categorical_accuracy: 0.9026 - val_loss: 0.7214 - val_categorical_accuracy: 0.7715\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.2056 - categorical_accuracy: 0.9290 - val_loss: 0.8332 - val_categorical_accuracy: 0.7599\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.1396 - categorical_accuracy: 0.9542 - val_loss: 1.0837 - val_categorical_accuracy: 0.7023\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0950 - categorical_accuracy: 0.9708 - val_loss: 1.2599 - val_categorical_accuracy: 0.7147\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 538s 51ms/step - loss: 0.0819 - categorical_accuracy: 0.9757 - val_loss: 1.0754 - val_categorical_accuracy: 0.7565\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0664 - categorical_accuracy: 0.9827 - val_loss: 0.9754 - val_categorical_accuracy: 0.7685\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0618 - categorical_accuracy: 0.9842 - val_loss: 0.9851 - val_categorical_accuracy: 0.7817\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0579 - categorical_accuracy: 0.9867 - val_loss: 1.1950 - val_categorical_accuracy: 0.7731\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0610 - categorical_accuracy: 0.9845 - val_loss: 1.2387 - val_categorical_accuracy: 0.7542\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0510 - categorical_accuracy: 0.9881 - val_loss: 1.1350 - val_categorical_accuracy: 0.7746\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0619 - categorical_accuracy: 0.9853 - val_loss: 1.2693 - val_categorical_accuracy: 0.7734\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 538s 51ms/step - loss: 0.0493 - categorical_accuracy: 0.9896 - val_loss: 1.2351 - val_categorical_accuracy: 0.7719\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0497 - categorical_accuracy: 0.9885 - val_loss: 1.1866 - val_categorical_accuracy: 0.7719\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 540s 51ms/step - loss: 0.0490 - categorical_accuracy: 0.9883 - val_loss: 1.1968 - val_categorical_accuracy: 0.7569\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0455 - categorical_accuracy: 0.9891 - val_loss: 1.5167 - val_categorical_accuracy: 0.7580\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 540s 51ms/step - loss: 0.0453 - categorical_accuracy: 0.9893 - val_loss: 1.1862 - val_categorical_accuracy: 0.7783\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 539s 51ms/step - loss: 0.0426 - categorical_accuracy: 0.9903 - val_loss: 1.2945 - val_categorical_accuracy: 0.7738\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(512))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,466,262\n",
      "Trainable params: 3,466,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 558s 52ms/step - loss: 1.1445 - categorical_accuracy: 0.6195 - val_loss: 1.1129 - val_categorical_accuracy: 0.6123\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.6465 - categorical_accuracy: 0.7807 - val_loss: 0.8378 - val_categorical_accuracy: 0.7365\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.4621 - categorical_accuracy: 0.8442 - val_loss: 1.0820 - val_categorical_accuracy: 0.6560\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.3528 - categorical_accuracy: 0.8807 - val_loss: 0.8451 - val_categorical_accuracy: 0.7422\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.2626 - categorical_accuracy: 0.9092 - val_loss: 0.8772 - val_categorical_accuracy: 0.7557\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.1898 - categorical_accuracy: 0.9359 - val_loss: 0.9268 - val_categorical_accuracy: 0.7460\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.1374 - categorical_accuracy: 0.9534 - val_loss: 1.0976 - val_categorical_accuracy: 0.7595\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.1044 - categorical_accuracy: 0.9660 - val_loss: 1.2964 - val_categorical_accuracy: 0.7219\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0876 - categorical_accuracy: 0.9728 - val_loss: 1.1971 - val_categorical_accuracy: 0.7561\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0806 - categorical_accuracy: 0.9769 - val_loss: 1.2260 - val_categorical_accuracy: 0.7648\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0688 - categorical_accuracy: 0.9811 - val_loss: 1.3194 - val_categorical_accuracy: 0.7591\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0623 - categorical_accuracy: 0.9837 - val_loss: 1.3109 - val_categorical_accuracy: 0.7565\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0540 - categorical_accuracy: 0.9871 - val_loss: 1.5132 - val_categorical_accuracy: 0.7467\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0557 - categorical_accuracy: 0.9848 - val_loss: 1.4477 - val_categorical_accuracy: 0.7539\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0500 - categorical_accuracy: 0.9864 - val_loss: 1.6260 - val_categorical_accuracy: 0.7369\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0497 - categorical_accuracy: 0.9870 - val_loss: 1.4941 - val_categorical_accuracy: 0.7501\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0446 - categorical_accuracy: 0.9875 - val_loss: 1.4376 - val_categorical_accuracy: 0.7629\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0455 - categorical_accuracy: 0.9878 - val_loss: 1.5338 - val_categorical_accuracy: 0.7648\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0421 - categorical_accuracy: 0.9870 - val_loss: 1.6743 - val_categorical_accuracy: 0.7497\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0437 - categorical_accuracy: 0.9882 - val_loss: 1.7496 - val_categorical_accuracy: 0.7384\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,440,630\n",
      "Trainable params: 3,440,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 1.1956 - categorical_accuracy: 0.6055 - val_loss: 1.3316 - val_categorical_accuracy: 0.6101\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.6743 - categorical_accuracy: 0.7756 - val_loss: 1.1117 - val_categorical_accuracy: 0.5732\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.4872 - categorical_accuracy: 0.8336 - val_loss: 1.2937 - val_categorical_accuracy: 0.6248\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.3843 - categorical_accuracy: 0.8698 - val_loss: 1.1312 - val_categorical_accuracy: 0.6357\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.2894 - categorical_accuracy: 0.9014 - val_loss: 0.8099 - val_categorical_accuracy: 0.7734\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.2171 - categorical_accuracy: 0.9256 - val_loss: 0.8465 - val_categorical_accuracy: 0.7644\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.1582 - categorical_accuracy: 0.9470 - val_loss: 0.9271 - val_categorical_accuracy: 0.7648\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.1341 - categorical_accuracy: 0.9579 - val_loss: 1.0366 - val_categorical_accuracy: 0.7651\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0969 - categorical_accuracy: 0.9688 - val_loss: 0.9917 - val_categorical_accuracy: 0.7625\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0778 - categorical_accuracy: 0.9769 - val_loss: 1.0803 - val_categorical_accuracy: 0.7591\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0675 - categorical_accuracy: 0.9801 - val_loss: 1.2569 - val_categorical_accuracy: 0.7550\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0641 - categorical_accuracy: 0.9804 - val_loss: 1.1648 - val_categorical_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0580 - categorical_accuracy: 0.9831 - val_loss: 1.2514 - val_categorical_accuracy: 0.7651\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0577 - categorical_accuracy: 0.9854 - val_loss: 1.2824 - val_categorical_accuracy: 0.7678\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 570s 54ms/step - loss: 0.0483 - categorical_accuracy: 0.9868 - val_loss: 1.3544 - val_categorical_accuracy: 0.7411\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 648s 61ms/step - loss: 0.0489 - categorical_accuracy: 0.9879 - val_loss: 1.3899 - val_categorical_accuracy: 0.7471\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 641s 60ms/step - loss: 0.0488 - categorical_accuracy: 0.9877 - val_loss: 1.4868 - val_categorical_accuracy: 0.7460\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.0503 - categorical_accuracy: 0.9877 - val_loss: 1.4829 - val_categorical_accuracy: 0.7557\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 638s 60ms/step - loss: 0.0367 - categorical_accuracy: 0.9900 - val_loss: 1.6715 - val_categorical_accuracy: 0.7414\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 634s 60ms/step - loss: 0.0464 - categorical_accuracy: 0.9885 - val_loss: 1.4797 - val_categorical_accuracy: 0.7478\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1118 23:00:14.174243 140056940074816 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 723s 68ms/step - loss: 1.3133 - categorical_accuracy: 0.5693 - val_loss: 1.2415 - val_categorical_accuracy: 0.6044\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 697s 66ms/step - loss: 0.8002 - categorical_accuracy: 0.7318 - val_loss: 0.8695 - val_categorical_accuracy: 0.7140\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.6230 - categorical_accuracy: 0.7933 - val_loss: 0.8324 - val_categorical_accuracy: 0.7286\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.5381 - categorical_accuracy: 0.8209 - val_loss: 0.7553 - val_categorical_accuracy: 0.7633\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.4809 - categorical_accuracy: 0.8357 - val_loss: 0.9298 - val_categorical_accuracy: 0.6940\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.4317 - categorical_accuracy: 0.8539 - val_loss: 0.6806 - val_categorical_accuracy: 0.7795\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.3942 - categorical_accuracy: 0.8625 - val_loss: 0.8287 - val_categorical_accuracy: 0.7317\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.3655 - categorical_accuracy: 0.8732 - val_loss: 0.7223 - val_categorical_accuracy: 0.7715\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.3292 - categorical_accuracy: 0.8875 - val_loss: 0.7630 - val_categorical_accuracy: 0.7723\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.3155 - categorical_accuracy: 0.8861 - val_loss: 0.7147 - val_categorical_accuracy: 0.7753\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.2939 - categorical_accuracy: 0.8993 - val_loss: 0.7270 - val_categorical_accuracy: 0.7791\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.2714 - categorical_accuracy: 0.9082 - val_loss: 0.7081 - val_categorical_accuracy: 0.7881\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.2554 - categorical_accuracy: 0.9110 - val_loss: 0.7644 - val_categorical_accuracy: 0.7746\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 641s 60ms/step - loss: 0.2418 - categorical_accuracy: 0.9180 - val_loss: 0.7289 - val_categorical_accuracy: 0.7821\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.2260 - categorical_accuracy: 0.9213 - val_loss: 0.8060 - val_categorical_accuracy: 0.7779\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.2154 - categorical_accuracy: 0.9239 - val_loss: 0.9727 - val_categorical_accuracy: 0.7437\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.2056 - categorical_accuracy: 0.9280 - val_loss: 0.9485 - val_categorical_accuracy: 0.7452\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.1896 - categorical_accuracy: 0.9323 - val_loss: 0.8580 - val_categorical_accuracy: 0.7806\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.1816 - categorical_accuracy: 0.9368 - val_loss: 0.8471 - val_categorical_accuracy: 0.7783\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.1743 - categorical_accuracy: 0.9373 - val_loss: 0.9174 - val_categorical_accuracy: 0.7821\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 1.3585 - categorical_accuracy: 0.5479 - val_loss: 1.2430 - val_categorical_accuracy: 0.5563\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.8358 - categorical_accuracy: 0.7209 - val_loss: 1.0945 - val_categorical_accuracy: 0.6406\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 0.6552 - categorical_accuracy: 0.7783 - val_loss: 0.7876 - val_categorical_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.5708 - categorical_accuracy: 0.8096 - val_loss: 0.7719 - val_categorical_accuracy: 0.7381\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 0.5269 - categorical_accuracy: 0.8211 - val_loss: 0.7509 - val_categorical_accuracy: 0.7478\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.5069 - categorical_accuracy: 0.8225 - val_loss: 0.7333 - val_categorical_accuracy: 0.7546\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.4926 - categorical_accuracy: 0.8319 - val_loss: 0.7349 - val_categorical_accuracy: 0.7591\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.4610 - categorical_accuracy: 0.8432 - val_loss: 0.7119 - val_categorical_accuracy: 0.7621\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.4097 - categorical_accuracy: 0.8632 - val_loss: 0.7393 - val_categorical_accuracy: 0.7550\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3954 - categorical_accuracy: 0.8608 - val_loss: 0.7548 - val_categorical_accuracy: 0.7554\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3926 - categorical_accuracy: 0.8646 - val_loss: 0.6930 - val_categorical_accuracy: 0.7719\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 0.3726 - categorical_accuracy: 0.8730 - val_loss: 0.7396 - val_categorical_accuracy: 0.7584\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3689 - categorical_accuracy: 0.8724 - val_loss: 0.8190 - val_categorical_accuracy: 0.7294\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3569 - categorical_accuracy: 0.8771 - val_loss: 0.7097 - val_categorical_accuracy: 0.7731\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3455 - categorical_accuracy: 0.8852 - val_loss: 0.7224 - val_categorical_accuracy: 0.7715\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3360 - categorical_accuracy: 0.8847 - val_loss: 0.7043 - val_categorical_accuracy: 0.7742\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3319 - categorical_accuracy: 0.8844 - val_loss: 0.7414 - val_categorical_accuracy: 0.7678\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 0.3225 - categorical_accuracy: 0.8875 - val_loss: 0.6894 - val_categorical_accuracy: 0.7825\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3203 - categorical_accuracy: 0.8938 - val_loss: 0.7026 - val_categorical_accuracy: 0.7802\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3094 - categorical_accuracy: 0.8945 - val_loss: 0.7159 - val_categorical_accuracy: 0.7802\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 542s 51ms/step - loss: 1.1731 - categorical_accuracy: 0.6049 - val_loss: 1.0362 - val_categorical_accuracy: 0.6462\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.6309 - categorical_accuracy: 0.7861 - val_loss: 0.8618 - val_categorical_accuracy: 0.7155\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.4562 - categorical_accuracy: 0.8469 - val_loss: 0.8241 - val_categorical_accuracy: 0.7286\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.3290 - categorical_accuracy: 0.8878 - val_loss: 0.7222 - val_categorical_accuracy: 0.7682\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.2409 - categorical_accuracy: 0.9190 - val_loss: 0.8493 - val_categorical_accuracy: 0.7373\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.1589 - categorical_accuracy: 0.9500 - val_loss: 0.8989 - val_categorical_accuracy: 0.7317\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 542s 51ms/step - loss: 0.1046 - categorical_accuracy: 0.9700 - val_loss: 0.9789 - val_categorical_accuracy: 0.7362\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.0780 - categorical_accuracy: 0.9772 - val_loss: 1.0395 - val_categorical_accuracy: 0.7441\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 542s 51ms/step - loss: 0.0602 - categorical_accuracy: 0.9839 - val_loss: 1.0574 - val_categorical_accuracy: 0.7501\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.0504 - categorical_accuracy: 0.9873 - val_loss: 1.0099 - val_categorical_accuracy: 0.7614\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.0471 - categorical_accuracy: 0.9868 - val_loss: 1.0614 - val_categorical_accuracy: 0.7606\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.0450 - categorical_accuracy: 0.9881 - val_loss: 1.2186 - val_categorical_accuracy: 0.7324\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.0662 - categorical_accuracy: 0.9801 - val_loss: 1.1131 - val_categorical_accuracy: 0.7539\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 541s 51ms/step - loss: 0.0450 - categorical_accuracy: 0.9882 - val_loss: 1.1769 - val_categorical_accuracy: 0.7444\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0389 - categorical_accuracy: 0.9903 - val_loss: 1.1932 - val_categorical_accuracy: 0.7550\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 543s 51ms/step - loss: 0.0419 - categorical_accuracy: 0.9892 - val_loss: 1.1597 - val_categorical_accuracy: 0.7554\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 543s 51ms/step - loss: 0.0298 - categorical_accuracy: 0.9928 - val_loss: 1.2267 - val_categorical_accuracy: 0.7546\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0341 - categorical_accuracy: 0.9913 - val_loss: 1.2841 - val_categorical_accuracy: 0.7448\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0310 - categorical_accuracy: 0.9911 - val_loss: 1.3100 - val_categorical_accuracy: 0.7418\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 543s 51ms/step - loss: 0.0387 - categorical_accuracy: 0.9881 - val_loss: 1.2785 - val_categorical_accuracy: 0.7584\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 1.2083 - categorical_accuracy: 0.5990 - val_loss: 2.1070 - val_categorical_accuracy: 0.3459\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.6827 - categorical_accuracy: 0.7703 - val_loss: 1.0949 - val_categorical_accuracy: 0.5875\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.5006 - categorical_accuracy: 0.8324 - val_loss: 0.8813 - val_categorical_accuracy: 0.7158\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.3965 - categorical_accuracy: 0.8677 - val_loss: 0.7636 - val_categorical_accuracy: 0.7524\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.3119 - categorical_accuracy: 0.8958 - val_loss: 0.8569 - val_categorical_accuracy: 0.7542\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.2314 - categorical_accuracy: 0.9243 - val_loss: 0.7733 - val_categorical_accuracy: 0.7648\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.1603 - categorical_accuracy: 0.9501 - val_loss: 0.8371 - val_categorical_accuracy: 0.7723\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.1584 - categorical_accuracy: 0.9482 - val_loss: 0.9010 - val_categorical_accuracy: 0.7520\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.1113 - categorical_accuracy: 0.9655 - val_loss: 1.0194 - val_categorical_accuracy: 0.7512\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0784 - categorical_accuracy: 0.9778 - val_loss: 1.0770 - val_categorical_accuracy: 0.7362\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0781 - categorical_accuracy: 0.9778 - val_loss: 1.0770 - val_categorical_accuracy: 0.7595\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0562 - categorical_accuracy: 0.9847 - val_loss: 1.0741 - val_categorical_accuracy: 0.7636\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0420 - categorical_accuracy: 0.9891 - val_loss: 1.0840 - val_categorical_accuracy: 0.7633\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0526 - categorical_accuracy: 0.9865 - val_loss: 1.1063 - val_categorical_accuracy: 0.7584\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0448 - categorical_accuracy: 0.9905 - val_loss: 1.3351 - val_categorical_accuracy: 0.7354\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0401 - categorical_accuracy: 0.9902 - val_loss: 1.3907 - val_categorical_accuracy: 0.7268\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0370 - categorical_accuracy: 0.9910 - val_loss: 1.2148 - val_categorical_accuracy: 0.7554\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0337 - categorical_accuracy: 0.9928 - val_loss: 1.3263 - val_categorical_accuracy: 0.7490\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0328 - categorical_accuracy: 0.9925 - val_loss: 1.2796 - val_categorical_accuracy: 0.7516\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 0.0241 - categorical_accuracy: 0.9933 - val_loss: 1.2621 - val_categorical_accuracy: 0.7670\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 2000, 256)         235776    \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 32)                27744     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,460,150\n",
      "Trainable params: 3,460,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 1.0759 - categorical_accuracy: 0.6505 - val_loss: 0.9702 - val_categorical_accuracy: 0.6899\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1137s 107ms/step - loss: 0.6218 - categorical_accuracy: 0.7962 - val_loss: 0.8682 - val_categorical_accuracy: 0.7143\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1137s 107ms/step - loss: 0.4611 - categorical_accuracy: 0.8444 - val_loss: 0.7921 - val_categorical_accuracy: 0.7429\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.3631 - categorical_accuracy: 0.8799 - val_loss: 0.7111 - val_categorical_accuracy: 0.7772\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1137s 107ms/step - loss: 0.2828 - categorical_accuracy: 0.9083 - val_loss: 0.7273 - val_categorical_accuracy: 0.7685\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.2026 - categorical_accuracy: 0.9358 - val_loss: 0.7797 - val_categorical_accuracy: 0.7700\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.1618 - categorical_accuracy: 0.9513 - val_loss: 0.8199 - val_categorical_accuracy: 0.7678\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.1188 - categorical_accuracy: 0.9652 - val_loss: 0.8311 - val_categorical_accuracy: 0.7866\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.0898 - categorical_accuracy: 0.9743 - val_loss: 0.9740 - val_categorical_accuracy: 0.7490\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.0668 - categorical_accuracy: 0.9800 - val_loss: 1.0636 - val_categorical_accuracy: 0.7648\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1137s 107ms/step - loss: 0.0605 - categorical_accuracy: 0.9838 - val_loss: 1.0476 - val_categorical_accuracy: 0.7531\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1139s 107ms/step - loss: 0.0471 - categorical_accuracy: 0.9874 - val_loss: 1.0914 - val_categorical_accuracy: 0.7550\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1139s 107ms/step - loss: 0.0473 - categorical_accuracy: 0.9879 - val_loss: 1.0892 - val_categorical_accuracy: 0.7580\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1136s 107ms/step - loss: 0.0406 - categorical_accuracy: 0.9880 - val_loss: 1.2123 - val_categorical_accuracy: 0.7508\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.0392 - categorical_accuracy: 0.9868 - val_loss: 1.2464 - val_categorical_accuracy: 0.7478\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.0349 - categorical_accuracy: 0.9899 - val_loss: 1.2016 - val_categorical_accuracy: 0.7610\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1136s 107ms/step - loss: 0.0320 - categorical_accuracy: 0.9895 - val_loss: 1.3096 - val_categorical_accuracy: 0.7482\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1137s 107ms/step - loss: 0.0299 - categorical_accuracy: 0.9902 - val_loss: 1.2819 - val_categorical_accuracy: 0.7606\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.0301 - categorical_accuracy: 0.9908 - val_loss: 1.2394 - val_categorical_accuracy: 0.7670\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 1138s 107ms/step - loss: 0.0318 - categorical_accuracy: 0.9896 - val_loss: 1.2614 - val_categorical_accuracy: 0.7670\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,440,630\n",
      "Trainable params: 3,440,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.4681 - categorical_accuracy: 0.5177 - val_loss: 1.2581 - val_categorical_accuracy: 0.5807\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 657s 62ms/step - loss: 0.9569 - categorical_accuracy: 0.6874 - val_loss: 0.9626 - val_categorical_accuracy: 0.6914\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.7790 - categorical_accuracy: 0.7466 - val_loss: 0.9790 - val_categorical_accuracy: 0.6628\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.6856 - categorical_accuracy: 0.7746 - val_loss: 0.9363 - val_categorical_accuracy: 0.7140\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.6119 - categorical_accuracy: 0.7986 - val_loss: 0.8022 - val_categorical_accuracy: 0.7414\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 657s 62ms/step - loss: 0.5548 - categorical_accuracy: 0.8153 - val_loss: 0.7683 - val_categorical_accuracy: 0.7667\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.5147 - categorical_accuracy: 0.8305 - val_loss: 0.8214 - val_categorical_accuracy: 0.7497\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.4822 - categorical_accuracy: 0.8384 - val_loss: 0.9105 - val_categorical_accuracy: 0.7343\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.4535 - categorical_accuracy: 0.8500 - val_loss: 0.8835 - val_categorical_accuracy: 0.7418\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.4304 - categorical_accuracy: 0.8583 - val_loss: 0.8147 - val_categorical_accuracy: 0.7588\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 0.4011 - categorical_accuracy: 0.8700 - val_loss: 0.7851 - val_categorical_accuracy: 0.7746\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.3880 - categorical_accuracy: 0.8722 - val_loss: 0.8024 - val_categorical_accuracy: 0.7776\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.3684 - categorical_accuracy: 0.8758 - val_loss: 0.8551 - val_categorical_accuracy: 0.7618\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.3486 - categorical_accuracy: 0.8834 - val_loss: 0.8940 - val_categorical_accuracy: 0.7550\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.3437 - categorical_accuracy: 0.8870 - val_loss: 0.7967 - val_categorical_accuracy: 0.7836\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.3310 - categorical_accuracy: 0.8873 - val_loss: 0.9332 - val_categorical_accuracy: 0.7828\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 657s 62ms/step - loss: 0.3088 - categorical_accuracy: 0.8950 - val_loss: 0.8894 - val_categorical_accuracy: 0.7874\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.3018 - categorical_accuracy: 0.8960 - val_loss: 0.9665 - val_categorical_accuracy: 0.7749\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.2918 - categorical_accuracy: 0.9006 - val_loss: 0.9889 - val_categorical_accuracy: 0.7621\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 657s 62ms/step - loss: 0.2975 - categorical_accuracy: 0.9030 - val_loss: 0.9130 - val_categorical_accuracy: 0.7731\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 668s 63ms/step - loss: 1.3136 - categorical_accuracy: 0.5665 - val_loss: 1.0886 - val_categorical_accuracy: 0.6534\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.8006 - categorical_accuracy: 0.7346 - val_loss: 0.9265 - val_categorical_accuracy: 0.7076\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.6506 - categorical_accuracy: 0.7801 - val_loss: 0.8449 - val_categorical_accuracy: 0.7298\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 666s 63ms/step - loss: 0.5483 - categorical_accuracy: 0.8094 - val_loss: 0.7117 - val_categorical_accuracy: 0.7667\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 666s 63ms/step - loss: 0.4848 - categorical_accuracy: 0.8344 - val_loss: 0.7044 - val_categorical_accuracy: 0.7795\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.4445 - categorical_accuracy: 0.8476 - val_loss: 0.7203 - val_categorical_accuracy: 0.7813\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 666s 63ms/step - loss: 0.4012 - categorical_accuracy: 0.8625 - val_loss: 0.7630 - val_categorical_accuracy: 0.7670\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.3725 - categorical_accuracy: 0.8687 - val_loss: 0.7212 - val_categorical_accuracy: 0.7761\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.3409 - categorical_accuracy: 0.8830 - val_loss: 0.6931 - val_categorical_accuracy: 0.7911\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 666s 63ms/step - loss: 0.3137 - categorical_accuracy: 0.8924 - val_loss: 0.7963 - val_categorical_accuracy: 0.7618\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.2989 - categorical_accuracy: 0.8957 - val_loss: 0.7214 - val_categorical_accuracy: 0.7892\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.2824 - categorical_accuracy: 0.9007 - val_loss: 0.7871 - val_categorical_accuracy: 0.7640\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.2566 - categorical_accuracy: 0.9116 - val_loss: 0.7930 - val_categorical_accuracy: 0.7712\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.2378 - categorical_accuracy: 0.9181 - val_loss: 0.8096 - val_categorical_accuracy: 0.7727\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.2291 - categorical_accuracy: 0.9213 - val_loss: 0.8157 - val_categorical_accuracy: 0.7795\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 666s 63ms/step - loss: 0.2195 - categorical_accuracy: 0.9228 - val_loss: 0.8361 - val_categorical_accuracy: 0.7693\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.2057 - categorical_accuracy: 0.9238 - val_loss: 0.8412 - val_categorical_accuracy: 0.7712\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.1975 - categorical_accuracy: 0.9321 - val_loss: 0.8212 - val_categorical_accuracy: 0.7855\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.1942 - categorical_accuracy: 0.9305 - val_loss: 0.8242 - val_categorical_accuracy: 0.7802\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 665s 63ms/step - loss: 0.1763 - categorical_accuracy: 0.9380 - val_loss: 0.8414 - val_categorical_accuracy: 0.7810\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               471552    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,672,982\n",
      "Trainable params: 3,672,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 1276s 120ms/step - loss: 1.2666 - categorical_accuracy: 0.5802 - val_loss: 1.5014 - val_categorical_accuracy: 0.5284\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1271s 120ms/step - loss: 0.7891 - categorical_accuracy: 0.7352 - val_loss: 1.0148 - val_categorical_accuracy: 0.6857\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1273s 120ms/step - loss: 0.6403 - categorical_accuracy: 0.7854 - val_loss: 0.8248 - val_categorical_accuracy: 0.7275\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1272s 120ms/step - loss: 0.5319 - categorical_accuracy: 0.8193 - val_loss: 0.8508 - val_categorical_accuracy: 0.7147\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1273s 120ms/step - loss: 0.4720 - categorical_accuracy: 0.8378 - val_loss: 0.7787 - val_categorical_accuracy: 0.7478\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1270s 120ms/step - loss: 0.4322 - categorical_accuracy: 0.8519 - val_loss: 0.8334 - val_categorical_accuracy: 0.7237\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1275s 120ms/step - loss: 0.3940 - categorical_accuracy: 0.8627 - val_loss: 0.7297 - val_categorical_accuracy: 0.7678\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.3722 - categorical_accuracy: 0.8750 - val_loss: 0.7439 - val_categorical_accuracy: 0.7655\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1272s 120ms/step - loss: 0.3425 - categorical_accuracy: 0.8809 - val_loss: 0.7829 - val_categorical_accuracy: 0.7557\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.3186 - categorical_accuracy: 0.8933 - val_loss: 0.7480 - val_categorical_accuracy: 0.7700\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.2932 - categorical_accuracy: 0.8943 - val_loss: 0.9409 - val_categorical_accuracy: 0.7121\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1271s 120ms/step - loss: 0.2796 - categorical_accuracy: 0.9021 - val_loss: 0.7513 - val_categorical_accuracy: 0.7753\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.2749 - categorical_accuracy: 0.9021 - val_loss: 0.7938 - val_categorical_accuracy: 0.7704\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1273s 120ms/step - loss: 0.2544 - categorical_accuracy: 0.9108 - val_loss: 0.7872 - val_categorical_accuracy: 0.7708\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.2434 - categorical_accuracy: 0.9163 - val_loss: 0.7527 - val_categorical_accuracy: 0.7825\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1272s 120ms/step - loss: 0.2419 - categorical_accuracy: 0.9151 - val_loss: 0.9322 - val_categorical_accuracy: 0.7448\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.2233 - categorical_accuracy: 0.9217 - val_loss: 0.8317 - val_categorical_accuracy: 0.7697\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.2274 - categorical_accuracy: 0.9201 - val_loss: 1.0546 - val_categorical_accuracy: 0.7339\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1275s 120ms/step - loss: 0.2473 - categorical_accuracy: 0.9134 - val_loss: 0.8818 - val_categorical_accuracy: 0.7651\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 1274s 120ms/step - loss: 0.1878 - categorical_accuracy: 0.9317 - val_loss: 0.8898 - val_categorical_accuracy: 0.7723\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(GRU(256, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 512)               864768    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,066,198\n",
      "Trainable params: 4,066,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 662s 62ms/step - loss: 1.2411 - categorical_accuracy: 0.5889 - val_loss: 1.1782 - val_categorical_accuracy: 0.5939\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 0.7062 - categorical_accuracy: 0.7609 - val_loss: 0.8605 - val_categorical_accuracy: 0.7094\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 0.5346 - categorical_accuracy: 0.7691 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 659s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 701s 66ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 697s 66ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 676s 64ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.0427 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.0373\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(512, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 1024)              3302400   \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 6,508,950\n",
      "Trainable params: 6,508,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 706s 66ms/step - loss: 1.3598 - categorical_accuracy: 0.5544 - val_loss: 1.2007 - val_categorical_accuracy: 0.5709\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.8078 - categorical_accuracy: 0.7269 - val_loss: 1.2410 - val_categorical_accuracy: 0.5548\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.6381 - categorical_accuracy: 0.7860 - val_loss: 1.3333 - val_categorical_accuracy: 0.5939\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.5196 - categorical_accuracy: 0.8307 - val_loss: 0.7439 - val_categorical_accuracy: 0.7441\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.4125 - categorical_accuracy: 0.8598 - val_loss: 0.8908 - val_categorical_accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.3913 - categorical_accuracy: 0.8665 - val_loss: 0.7567 - val_categorical_accuracy: 0.7561\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.3368 - categorical_accuracy: 0.8814 - val_loss: 0.7361 - val_categorical_accuracy: 0.7783\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.2959 - categorical_accuracy: 0.8973 - val_loss: 0.9716 - val_categorical_accuracy: 0.7271\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.2636 - categorical_accuracy: 0.9116 - val_loss: 0.8710 - val_categorical_accuracy: 0.7689\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.2255 - categorical_accuracy: 0.9206 - val_loss: 0.8583 - val_categorical_accuracy: 0.7738\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.2008 - categorical_accuracy: 0.9292 - val_loss: 0.8639 - val_categorical_accuracy: 0.7580\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1775 - categorical_accuracy: 0.9362 - val_loss: 0.9764 - val_categorical_accuracy: 0.7629\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1658 - categorical_accuracy: 0.9431 - val_loss: 0.9460 - val_categorical_accuracy: 0.7700\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1570 - categorical_accuracy: 0.9463 - val_loss: 0.9295 - val_categorical_accuracy: 0.7708\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1467 - categorical_accuracy: 0.9512 - val_loss: 1.1573 - val_categorical_accuracy: 0.7298\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1374 - categorical_accuracy: 0.9522 - val_loss: 1.2796 - val_categorical_accuracy: 0.7125\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1351 - categorical_accuracy: 0.9530 - val_loss: 1.1831 - val_categorical_accuracy: 0.7388\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1412 - categorical_accuracy: 0.9526 - val_loss: 1.0026 - val_categorical_accuracy: 0.7700\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1301 - categorical_accuracy: 0.9539 - val_loss: 1.0177 - val_categorical_accuracy: 0.7715\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 704s 66ms/step - loss: 0.1256 - categorical_accuracy: 0.9561 - val_loss: 1.0856 - val_categorical_accuracy: 0.7542\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(1024, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               1153024   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,354,454\n",
      "Trainable params: 4,354,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 822s 77ms/step - loss: 1.3392 - categorical_accuracy: 0.5648 - val_loss: 1.6619 - val_categorical_accuracy: 0.4829\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.9661 - categorical_accuracy: 0.6795 - val_loss: 1.5405 - val_categorical_accuracy: 0.4930\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 819s 77ms/step - loss: 0.8084 - categorical_accuracy: 0.7304 - val_loss: 1.1793 - val_categorical_accuracy: 0.6026\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.6988 - categorical_accuracy: 0.7662 - val_loss: 0.8786 - val_categorical_accuracy: 0.7268\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.6131 - categorical_accuracy: 0.7966 - val_loss: 0.9153 - val_categorical_accuracy: 0.7132\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.5488 - categorical_accuracy: 0.8193 - val_loss: 0.9458 - val_categorical_accuracy: 0.7098\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 821s 77ms/step - loss: 0.4914 - categorical_accuracy: 0.8352 - val_loss: 0.8241 - val_categorical_accuracy: 0.7373\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 821s 77ms/step - loss: 0.4361 - categorical_accuracy: 0.8537 - val_loss: 0.7976 - val_categorical_accuracy: 0.7508\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.4024 - categorical_accuracy: 0.8619 - val_loss: 0.8402 - val_categorical_accuracy: 0.7493\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 821s 77ms/step - loss: 0.3801 - categorical_accuracy: 0.8718 - val_loss: 0.8220 - val_categorical_accuracy: 0.7422\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 821s 77ms/step - loss: 0.3467 - categorical_accuracy: 0.8846 - val_loss: 0.7936 - val_categorical_accuracy: 0.7565\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.2850 - categorical_accuracy: 0.9027 - val_loss: 0.8197 - val_categorical_accuracy: 0.7640\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.2906 - categorical_accuracy: 0.8980 - val_loss: 0.8160 - val_categorical_accuracy: 0.7629\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 821s 77ms/step - loss: 0.2379 - categorical_accuracy: 0.9225 - val_loss: 0.8330 - val_categorical_accuracy: 0.7738\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.2351 - categorical_accuracy: 0.9194 - val_loss: 0.9377 - val_categorical_accuracy: 0.7520\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 821s 77ms/step - loss: 0.2006 - categorical_accuracy: 0.9312 - val_loss: 0.8867 - val_categorical_accuracy: 0.7595\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.2346 - categorical_accuracy: 0.9186 - val_loss: 0.8941 - val_categorical_accuracy: 0.7651\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.2136 - categorical_accuracy: 0.9264 - val_loss: 0.9617 - val_categorical_accuracy: 0.7516\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.2118 - categorical_accuracy: 0.9285 - val_loss: 0.9507 - val_categorical_accuracy: 0.7572\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 820s 77ms/step - loss: 0.1832 - categorical_accuracy: 0.9368 - val_loss: 0.9950 - val_categorical_accuracy: 0.7493\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(LSTM(512, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1024)              4403200   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 7,609,750\n",
      "Trainable params: 7,609,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 946s 89ms/step - loss: 1.3551 - categorical_accuracy: 0.5589 - val_loss: 1.3461 - val_categorical_accuracy: 0.5597\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.9785 - categorical_accuracy: 0.6816 - val_loss: 1.1574 - val_categorical_accuracy: 0.5747\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 1.0118 - categorical_accuracy: 0.6603 - val_loss: 1.0270 - val_categorical_accuracy: 0.6662\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.6753 - categorical_accuracy: 0.7767 - val_loss: 0.9397 - val_categorical_accuracy: 0.7000\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.5828 - categorical_accuracy: 0.8070 - val_loss: 0.9836 - val_categorical_accuracy: 0.6760\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.5053 - categorical_accuracy: 0.8337 - val_loss: 0.8850 - val_categorical_accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.4433 - categorical_accuracy: 0.8487 - val_loss: 0.8126 - val_categorical_accuracy: 0.7493\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.3858 - categorical_accuracy: 0.8677 - val_loss: 0.8933 - val_categorical_accuracy: 0.7151\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.3428 - categorical_accuracy: 0.8825 - val_loss: 0.8526 - val_categorical_accuracy: 0.7490\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.3118 - categorical_accuracy: 0.8934 - val_loss: 0.8815 - val_categorical_accuracy: 0.7452\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 944s 89ms/step - loss: 0.2616 - categorical_accuracy: 0.9095 - val_loss: 0.9441 - val_categorical_accuracy: 0.7610\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 943s 89ms/step - loss: 0.2375 - categorical_accuracy: 0.9203 - val_loss: 0.8510 - val_categorical_accuracy: 0.7670\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 966s 91ms/step - loss: 0.2021 - categorical_accuracy: 0.9310 - val_loss: 0.9715 - val_categorical_accuracy: 0.7731\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1028s 97ms/step - loss: 0.1820 - categorical_accuracy: 0.9355 - val_loss: 0.9494 - val_categorical_accuracy: 0.7588\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 950s 89ms/step - loss: 0.1720 - categorical_accuracy: 0.9411 - val_loss: 1.0313 - val_categorical_accuracy: 0.7655\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 945s 89ms/step - loss: 0.1457 - categorical_accuracy: 0.9524 - val_loss: 1.0759 - val_categorical_accuracy: 0.7682\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 946s 89ms/step - loss: 0.1361 - categorical_accuracy: 0.9521 - val_loss: 1.1343 - val_categorical_accuracy: 0.7531\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 947s 89ms/step - loss: 0.1212 - categorical_accuracy: 0.9595 - val_loss: 1.2898 - val_categorical_accuracy: 0.7381\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 946s 89ms/step - loss: 0.1134 - categorical_accuracy: 0.9612 - val_loss: 1.2432 - val_categorical_accuracy: 0.7441\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 946s 89ms/step - loss: 0.1098 - categorical_accuracy: 0.9621 - val_loss: 1.1680 - val_categorical_accuracy: 0.7633\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(LSTM(1024, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
