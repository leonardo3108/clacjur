{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD          DESCR_AREA                                           filtrado\n",
       "0  1400    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1  1700   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2  5700    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3   284  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4   298             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22972 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 30000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 22972\n",
      "Encontrados no modelo: 19689 = 85.7086888385861\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13285, 500), (13285, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 22:47:49.547098 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1201 22:47:49.676302 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1201 22:47:49.678113 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1201 22:47:49.687773 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1201 22:47:49.688305 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1201 22:47:50.425559 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1201 22:47:50.462910 140489510582080 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1201 22:47:50.548851 140489510582080 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 29,962\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 244us/step - loss: 1.4022 - categorical_accuracy: 0.5415 - val_loss: 1.5311 - val_categorical_accuracy: 0.3963\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1s 121us/step - loss: 0.9339 - categorical_accuracy: 0.6937 - val_loss: 1.4460 - val_categorical_accuracy: 0.5408\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1s 121us/step - loss: 0.7647 - categorical_accuracy: 0.7491 - val_loss: 1.4314 - val_categorical_accuracy: 0.5137\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1s 110us/step - loss: 0.6522 - categorical_accuracy: 0.7866 - val_loss: 1.5575 - val_categorical_accuracy: 0.5231\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1s 106us/step - loss: 0.5695 - categorical_accuracy: 0.8142 - val_loss: 1.3192 - val_categorical_accuracy: 0.6199\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1s 106us/step - loss: 0.5070 - categorical_accuracy: 0.8314 - val_loss: 1.4425 - val_categorical_accuracy: 0.6187\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1s 106us/step - loss: 0.4435 - categorical_accuracy: 0.8537 - val_loss: 1.6568 - val_categorical_accuracy: 0.5661\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1s 109us/step - loss: 0.3831 - categorical_accuracy: 0.8739 - val_loss: 2.2050 - val_categorical_accuracy: 0.4230\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1s 130us/step - loss: 0.3399 - categorical_accuracy: 0.8861 - val_loss: 1.2020 - val_categorical_accuracy: 0.6515\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1s 117us/step - loss: 0.2969 - categorical_accuracy: 0.9006 - val_loss: 1.1032 - val_categorical_accuracy: 0.6872\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1s 108us/step - loss: 0.2513 - categorical_accuracy: 0.9218 - val_loss: 1.3876 - val_categorical_accuracy: 0.6458\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1s 110us/step - loss: 0.2170 - categorical_accuracy: 0.9311 - val_loss: 1.5514 - val_categorical_accuracy: 0.5947\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1s 109us/step - loss: 0.1879 - categorical_accuracy: 0.9424 - val_loss: 2.1122 - val_categorical_accuracy: 0.5201\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1s 111us/step - loss: 0.1582 - categorical_accuracy: 0.9524 - val_loss: 1.9959 - val_categorical_accuracy: 0.5506\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1s 138us/step - loss: 0.1409 - categorical_accuracy: 0.9581 - val_loss: 1.3519 - val_categorical_accuracy: 0.6775\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 148us/step - loss: 0.1189 - categorical_accuracy: 0.9661 - val_loss: 1.5160 - val_categorical_accuracy: 0.6598\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1s 116us/step - loss: 0.1036 - categorical_accuracy: 0.9708 - val_loss: 2.7901 - val_categorical_accuracy: 0.4881\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1s 113us/step - loss: 0.0952 - categorical_accuracy: 0.9738 - val_loss: 1.6644 - val_categorical_accuracy: 0.6680\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1s 119us/step - loss: 0.0886 - categorical_accuracy: 0.9772 - val_loss: 2.4372 - val_categorical_accuracy: 0.5318\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 1s 118us/step - loss: 0.0807 - categorical_accuracy: 0.9798 - val_loss: 1.9042 - val_categorical_accuracy: 0.6443\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 2,327,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 237us/step - loss: 1.2721 - categorical_accuracy: 0.5795 - val_loss: 1.0830 - val_categorical_accuracy: 0.6537\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 184us/step - loss: 0.7815 - categorical_accuracy: 0.7436 - val_loss: 1.5203 - val_categorical_accuracy: 0.5378\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 184us/step - loss: 0.5879 - categorical_accuracy: 0.8055 - val_loss: 1.1926 - val_categorical_accuracy: 0.6635\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 187us/step - loss: 0.4425 - categorical_accuracy: 0.8571 - val_loss: 1.2802 - val_categorical_accuracy: 0.5977\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 196us/step - loss: 0.3333 - categorical_accuracy: 0.8919 - val_loss: 1.0317 - val_categorical_accuracy: 0.6978\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 193us/step - loss: 0.2368 - categorical_accuracy: 0.9289 - val_loss: 1.0447 - val_categorical_accuracy: 0.7132\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 196us/step - loss: 0.1645 - categorical_accuracy: 0.9533 - val_loss: 1.1306 - val_categorical_accuracy: 0.7166\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 194us/step - loss: 0.1143 - categorical_accuracy: 0.9699 - val_loss: 1.0957 - val_categorical_accuracy: 0.7192\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 195us/step - loss: 0.0810 - categorical_accuracy: 0.9797 - val_loss: 1.9833 - val_categorical_accuracy: 0.6304\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 195us/step - loss: 0.0652 - categorical_accuracy: 0.9841 - val_loss: 1.1593 - val_categorical_accuracy: 0.7237\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 190us/step - loss: 0.0572 - categorical_accuracy: 0.9862 - val_loss: 1.2163 - val_categorical_accuracy: 0.7448\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 199us/step - loss: 0.0496 - categorical_accuracy: 0.9895 - val_loss: 1.4140 - val_categorical_accuracy: 0.7151\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.0470 - categorical_accuracy: 0.9889 - val_loss: 1.6574 - val_categorical_accuracy: 0.6665\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 191us/step - loss: 0.0478 - categorical_accuracy: 0.9910 - val_loss: 1.3878 - val_categorical_accuracy: 0.7301\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 190us/step - loss: 0.0465 - categorical_accuracy: 0.9911 - val_loss: 1.5705 - val_categorical_accuracy: 0.7072\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 214us/step - loss: 0.0474 - categorical_accuracy: 0.9896 - val_loss: 1.4542 - val_categorical_accuracy: 0.7151\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 195us/step - loss: 0.0476 - categorical_accuracy: 0.9919 - val_loss: 1.3247 - val_categorical_accuracy: 0.7377\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 197us/step - loss: 0.0532 - categorical_accuracy: 0.9912 - val_loss: 1.3667 - val_categorical_accuracy: 0.7441\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 192us/step - loss: 0.0465 - categorical_accuracy: 0.9918 - val_loss: 1.4745 - val_categorical_accuracy: 0.7245\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 224us/step - loss: 0.0468 - categorical_accuracy: 0.9917 - val_loss: 1.4172 - val_categorical_accuracy: 0.7275\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 2,327,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 1.1410 - categorical_accuracy: 0.6250 - val_loss: 0.9815 - val_categorical_accuracy: 0.6846\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 191us/step - loss: 0.6575 - categorical_accuracy: 0.7925 - val_loss: 1.0009 - val_categorical_accuracy: 0.7207\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 205us/step - loss: 0.4454 - categorical_accuracy: 0.8593 - val_loss: 1.0191 - val_categorical_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 195us/step - loss: 0.3043 - categorical_accuracy: 0.9035 - val_loss: 1.2110 - val_categorical_accuracy: 0.7268\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 184us/step - loss: 0.2050 - categorical_accuracy: 0.9396 - val_loss: 1.5249 - val_categorical_accuracy: 0.7057\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 188us/step - loss: 0.1605 - categorical_accuracy: 0.9596 - val_loss: 1.4782 - val_categorical_accuracy: 0.7343\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.1317 - categorical_accuracy: 0.9676 - val_loss: 2.0940 - val_categorical_accuracy: 0.7339\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 197us/step - loss: 0.1330 - categorical_accuracy: 0.9735 - val_loss: 2.1057 - val_categorical_accuracy: 0.7207\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 193us/step - loss: 0.1139 - categorical_accuracy: 0.9772 - val_loss: 2.2653 - val_categorical_accuracy: 0.7170\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 192us/step - loss: 0.1123 - categorical_accuracy: 0.9792 - val_loss: 2.5068 - val_categorical_accuracy: 0.7053\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 215us/step - loss: 0.1061 - categorical_accuracy: 0.9821 - val_loss: 2.3525 - val_categorical_accuracy: 0.7260\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 189us/step - loss: 0.1139 - categorical_accuracy: 0.9817 - val_loss: 3.5704 - val_categorical_accuracy: 0.6541\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 190us/step - loss: 0.1012 - categorical_accuracy: 0.9859 - val_loss: 2.4680 - val_categorical_accuracy: 0.7264\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 196us/step - loss: 0.1013 - categorical_accuracy: 0.9862 - val_loss: 2.8692 - val_categorical_accuracy: 0.7140\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.1076 - categorical_accuracy: 0.9847 - val_loss: 2.9881 - val_categorical_accuracy: 0.7117\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 186us/step - loss: 0.1069 - categorical_accuracy: 0.9866 - val_loss: 2.9549 - val_categorical_accuracy: 0.7215\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 189us/step - loss: 0.1163 - categorical_accuracy: 0.9851 - val_loss: 2.7316 - val_categorical_accuracy: 0.7271\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 186us/step - loss: 0.1023 - categorical_accuracy: 0.9880 - val_loss: 3.1656 - val_categorical_accuracy: 0.7030\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 206us/step - loss: 0.1006 - categorical_accuracy: 0.9877 - val_loss: 2.9785 - val_categorical_accuracy: 0.7460\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 189us/step - loss: 0.1042 - categorical_accuracy: 0.9884 - val_loss: 3.0493 - val_categorical_accuracy: 0.7335\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=5e-3),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,356,862\n",
      "Trainable params: 2,356,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 260us/step - loss: 1.2522 - categorical_accuracy: 0.5889 - val_loss: 1.3600 - val_categorical_accuracy: 0.5563\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 229us/step - loss: 0.7413 - categorical_accuracy: 0.7575 - val_loss: 1.0763 - val_categorical_accuracy: 0.6481\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 215us/step - loss: 0.5277 - categorical_accuracy: 0.8304 - val_loss: 1.3965 - val_categorical_accuracy: 0.5717\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 213us/step - loss: 0.3809 - categorical_accuracy: 0.8744 - val_loss: 1.0379 - val_categorical_accuracy: 0.6925\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 229us/step - loss: 0.2658 - categorical_accuracy: 0.9173 - val_loss: 1.2659 - val_categorical_accuracy: 0.6357\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 221us/step - loss: 0.1744 - categorical_accuracy: 0.9498 - val_loss: 1.1202 - val_categorical_accuracy: 0.6763\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 217us/step - loss: 0.1181 - categorical_accuracy: 0.9667 - val_loss: 1.2130 - val_categorical_accuracy: 0.6793\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 226us/step - loss: 0.0791 - categorical_accuracy: 0.9797 - val_loss: 1.2939 - val_categorical_accuracy: 0.6680\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 0.0746 - categorical_accuracy: 0.9845 - val_loss: 1.1412 - val_categorical_accuracy: 0.7313\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 219us/step - loss: 0.0624 - categorical_accuracy: 0.9874 - val_loss: 1.2523 - val_categorical_accuracy: 0.7384\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 231us/step - loss: 0.0617 - categorical_accuracy: 0.9886 - val_loss: 1.2639 - val_categorical_accuracy: 0.7399\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 234us/step - loss: 0.0605 - categorical_accuracy: 0.9898 - val_loss: 1.2792 - val_categorical_accuracy: 0.7324\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 213us/step - loss: 0.0614 - categorical_accuracy: 0.9907 - val_loss: 1.2478 - val_categorical_accuracy: 0.7365\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 218us/step - loss: 0.0576 - categorical_accuracy: 0.9908 - val_loss: 1.2828 - val_categorical_accuracy: 0.7286\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 225us/step - loss: 0.0628 - categorical_accuracy: 0.9910 - val_loss: 1.5182 - val_categorical_accuracy: 0.7328\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 221us/step - loss: 0.0574 - categorical_accuracy: 0.9912 - val_loss: 1.2972 - val_categorical_accuracy: 0.7313\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 220us/step - loss: 0.0577 - categorical_accuracy: 0.9907 - val_loss: 1.3847 - val_categorical_accuracy: 0.7365\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 216us/step - loss: 0.0557 - categorical_accuracy: 0.9920 - val_loss: 1.3936 - val_categorical_accuracy: 0.7256\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 227us/step - loss: 0.0569 - categorical_accuracy: 0.9922 - val_loss: 1.6463 - val_categorical_accuracy: 0.6801\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 217us/step - loss: 0.0550 - categorical_accuracy: 0.9928 - val_loss: 1.6230 - val_categorical_accuracy: 0.7192\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1201 22:50:29.901146 140489510582080 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,125,374\n",
      "Trainable params: 3,125,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 262us/step - loss: 1.2354 - categorical_accuracy: 0.5958 - val_loss: 1.3871 - val_categorical_accuracy: 0.5280\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 228us/step - loss: 0.6841 - categorical_accuracy: 0.7798 - val_loss: 1.2412 - val_categorical_accuracy: 0.6263\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 211us/step - loss: 0.4214 - categorical_accuracy: 0.8678 - val_loss: 1.1747 - val_categorical_accuracy: 0.7091\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 212us/step - loss: 0.2358 - categorical_accuracy: 0.9270 - val_loss: 1.3629 - val_categorical_accuracy: 0.7091\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 227us/step - loss: 0.1436 - categorical_accuracy: 0.9593 - val_loss: 2.0678 - val_categorical_accuracy: 0.6553\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 211us/step - loss: 0.1050 - categorical_accuracy: 0.9737 - val_loss: 2.3988 - val_categorical_accuracy: 0.6677\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 210us/step - loss: 0.0769 - categorical_accuracy: 0.9833 - val_loss: 2.0365 - val_categorical_accuracy: 0.6876\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 221us/step - loss: 0.0653 - categorical_accuracy: 0.9868 - val_loss: 2.5380 - val_categorical_accuracy: 0.6993\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 217us/step - loss: 0.0639 - categorical_accuracy: 0.9877 - val_loss: 2.1050 - val_categorical_accuracy: 0.7083\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 210us/step - loss: 0.0620 - categorical_accuracy: 0.9884 - val_loss: 2.6591 - val_categorical_accuracy: 0.6752\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 211us/step - loss: 0.0530 - categorical_accuracy: 0.9895 - val_loss: 2.4136 - val_categorical_accuracy: 0.7046\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 224us/step - loss: 0.0520 - categorical_accuracy: 0.9907 - val_loss: 2.8866 - val_categorical_accuracy: 0.6903\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 212us/step - loss: 0.0473 - categorical_accuracy: 0.9910 - val_loss: 2.8224 - val_categorical_accuracy: 0.6978\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 217us/step - loss: 0.0438 - categorical_accuracy: 0.9900 - val_loss: 3.0419 - val_categorical_accuracy: 0.6673\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 233us/step - loss: 0.0453 - categorical_accuracy: 0.9908 - val_loss: 2.8612 - val_categorical_accuracy: 0.6696\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 214us/step - loss: 0.0392 - categorical_accuracy: 0.9900 - val_loss: 2.7911 - val_categorical_accuracy: 0.6978\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 213us/step - loss: 0.0388 - categorical_accuracy: 0.9908 - val_loss: 3.0543 - val_categorical_accuracy: 0.6763\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 211us/step - loss: 0.0428 - categorical_accuracy: 0.9901 - val_loss: 2.7825 - val_categorical_accuracy: 0.6842\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 225us/step - loss: 0.0371 - categorical_accuracy: 0.9914 - val_loss: 3.1682 - val_categorical_accuracy: 0.6835\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 215us/step - loss: 0.0372 - categorical_accuracy: 0.9915 - val_loss: 3.4433 - val_categorical_accuracy: 0.6688\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,950,622\n",
      "Trainable params: 3,950,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 329us/step - loss: 1.2327 - categorical_accuracy: 0.6123 - val_loss: 1.1596 - val_categorical_accuracy: 0.6500\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 3s 276us/step - loss: 0.6311 - categorical_accuracy: 0.7957 - val_loss: 1.2541 - val_categorical_accuracy: 0.6297\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 3s 268us/step - loss: 0.3384 - categorical_accuracy: 0.8918 - val_loss: 2.0077 - val_categorical_accuracy: 0.6244\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 3s 285us/step - loss: 0.1733 - categorical_accuracy: 0.9525 - val_loss: 2.0284 - val_categorical_accuracy: 0.5589\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 3s 276us/step - loss: 0.1115 - categorical_accuracy: 0.9699 - val_loss: 1.8741 - val_categorical_accuracy: 0.7034\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 3s 271us/step - loss: 0.0837 - categorical_accuracy: 0.9815 - val_loss: 2.0190 - val_categorical_accuracy: 0.6658\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 3s 284us/step - loss: 0.0666 - categorical_accuracy: 0.9867 - val_loss: 3.1319 - val_categorical_accuracy: 0.6195\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 3s 266us/step - loss: 0.0641 - categorical_accuracy: 0.9871 - val_loss: 2.1309 - val_categorical_accuracy: 0.6982\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 3s 262us/step - loss: 0.0563 - categorical_accuracy: 0.9895 - val_loss: 2.8814 - val_categorical_accuracy: 0.6537\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 3s 285us/step - loss: 0.0484 - categorical_accuracy: 0.9897 - val_loss: 2.4495 - val_categorical_accuracy: 0.6854\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 3s 274us/step - loss: 0.0559 - categorical_accuracy: 0.9884 - val_loss: 2.4653 - val_categorical_accuracy: 0.7046\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 3s 272us/step - loss: 0.0491 - categorical_accuracy: 0.9898 - val_loss: 3.2166 - val_categorical_accuracy: 0.6297\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 3s 284us/step - loss: 0.0422 - categorical_accuracy: 0.9910 - val_loss: 2.9686 - val_categorical_accuracy: 0.6857\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 3s 277us/step - loss: 0.0447 - categorical_accuracy: 0.9897 - val_loss: 3.0236 - val_categorical_accuracy: 0.6760\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 3s 272us/step - loss: 0.0360 - categorical_accuracy: 0.9913 - val_loss: 3.1847 - val_categorical_accuracy: 0.6684\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 3s 283us/step - loss: 0.0394 - categorical_accuracy: 0.9923 - val_loss: 2.9832 - val_categorical_accuracy: 0.6744\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 3s 274us/step - loss: 0.0351 - categorical_accuracy: 0.9919 - val_loss: 3.1823 - val_categorical_accuracy: 0.6613\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 3s 275us/step - loss: 0.0380 - categorical_accuracy: 0.9918 - val_loss: 3.2510 - val_categorical_accuracy: 0.6564\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 3s 281us/step - loss: 0.0370 - categorical_accuracy: 0.9910 - val_loss: 3.2255 - val_categorical_accuracy: 0.6861\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 3s 271us/step - loss: 0.0415 - categorical_accuracy: 0.9911 - val_loss: 3.1981 - val_categorical_accuracy: 0.6801\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,551,454\n",
      "Trainable params: 2,551,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.3050 - categorical_accuracy: 0.5589 - val_loss: 1.3699 - val_categorical_accuracy: 0.5807\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.8678 - categorical_accuracy: 0.7122 - val_loss: 1.4388 - val_categorical_accuracy: 0.4870\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.6956 - categorical_accuracy: 0.7699 - val_loss: 0.9852 - val_categorical_accuracy: 0.6696\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.5649 - categorical_accuracy: 0.8172 - val_loss: 1.0812 - val_categorical_accuracy: 0.6598\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.4617 - categorical_accuracy: 0.8508 - val_loss: 1.1609 - val_categorical_accuracy: 0.6594\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.3867 - categorical_accuracy: 0.8748 - val_loss: 0.9002 - val_categorical_accuracy: 0.7256\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.3093 - categorical_accuracy: 0.8963 - val_loss: 1.1482 - val_categorical_accuracy: 0.6820\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.2513 - categorical_accuracy: 0.9187 - val_loss: 1.1838 - val_categorical_accuracy: 0.6793\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.2069 - categorical_accuracy: 0.9339 - val_loss: 1.0221 - val_categorical_accuracy: 0.7369\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 37s 4ms/step - loss: 0.1582 - categorical_accuracy: 0.9502 - val_loss: 1.2142 - val_categorical_accuracy: 0.7268\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.1274 - categorical_accuracy: 0.9583 - val_loss: 1.2838 - val_categorical_accuracy: 0.7072\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1107 - categorical_accuracy: 0.9635 - val_loss: 1.1415 - val_categorical_accuracy: 0.7542\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.0870 - categorical_accuracy: 0.9718 - val_loss: 1.3916 - val_categorical_accuracy: 0.7189\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.0765 - categorical_accuracy: 0.9763 - val_loss: 1.2928 - val_categorical_accuracy: 0.7546\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.0703 - categorical_accuracy: 0.9787 - val_loss: 1.3453 - val_categorical_accuracy: 0.7441\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 37s 4ms/step - loss: 0.0549 - categorical_accuracy: 0.9829 - val_loss: 1.4194 - val_categorical_accuracy: 0.7381\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0525 - categorical_accuracy: 0.9841 - val_loss: 1.4803 - val_categorical_accuracy: 0.7388\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0519 - categorical_accuracy: 0.9835 - val_loss: 1.4397 - val_categorical_accuracy: 0.7595\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0496 - categorical_accuracy: 0.9849 - val_loss: 1.4603 - val_categorical_accuracy: 0.7478\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0415 - categorical_accuracy: 0.9881 - val_loss: 1.5884 - val_categorical_accuracy: 0.7429\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,581,054\n",
      "Trainable params: 2,581,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 1.3117 - categorical_accuracy: 0.5616 - val_loss: 1.7363 - val_categorical_accuracy: 0.4324\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.8533 - categorical_accuracy: 0.7145 - val_loss: 1.0980 - val_categorical_accuracy: 0.6549\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.6810 - categorical_accuracy: 0.7708 - val_loss: 1.0157 - val_categorical_accuracy: 0.6793\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.5529 - categorical_accuracy: 0.8158 - val_loss: 0.8946 - val_categorical_accuracy: 0.7196\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.4481 - categorical_accuracy: 0.8515 - val_loss: 0.9153 - val_categorical_accuracy: 0.7275\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.3578 - categorical_accuracy: 0.8838 - val_loss: 0.9217 - val_categorical_accuracy: 0.7241\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.2902 - categorical_accuracy: 0.9033 - val_loss: 0.9463 - val_categorical_accuracy: 0.7448\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 37s 4ms/step - loss: 0.2257 - categorical_accuracy: 0.9250 - val_loss: 1.0260 - val_categorical_accuracy: 0.7460\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1746 - categorical_accuracy: 0.9424 - val_loss: 1.1558 - val_categorical_accuracy: 0.7117\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.1373 - categorical_accuracy: 0.9540 - val_loss: 1.1340 - val_categorical_accuracy: 0.7234\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.1102 - categorical_accuracy: 0.9653 - val_loss: 1.2576 - val_categorical_accuracy: 0.7204\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0894 - categorical_accuracy: 0.9725 - val_loss: 1.4093 - val_categorical_accuracy: 0.7008\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0748 - categorical_accuracy: 0.9762 - val_loss: 1.4655 - val_categorical_accuracy: 0.7076\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0680 - categorical_accuracy: 0.9788 - val_loss: 1.6779 - val_categorical_accuracy: 0.6786\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0603 - categorical_accuracy: 0.9805 - val_loss: 1.2775 - val_categorical_accuracy: 0.7365\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0549 - categorical_accuracy: 0.9832 - val_loss: 1.5132 - val_categorical_accuracy: 0.7117\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0525 - categorical_accuracy: 0.9845 - val_loss: 1.5739 - val_categorical_accuracy: 0.7061\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0477 - categorical_accuracy: 0.9846 - val_loss: 1.5462 - val_categorical_accuracy: 0.7204\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0428 - categorical_accuracy: 0.9874 - val_loss: 1.5486 - val_categorical_accuracy: 0.7426\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0438 - categorical_accuracy: 0.9872 - val_loss: 1.5780 - val_categorical_accuracy: 0.7226\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               61824     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,390,046\n",
      "Trainable params: 2,390,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 1.3156 - categorical_accuracy: 0.5573 - val_loss: 1.7517 - val_categorical_accuracy: 0.4400\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.8704 - categorical_accuracy: 0.7125 - val_loss: 1.0996 - val_categorical_accuracy: 0.6537\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.7022 - categorical_accuracy: 0.7673 - val_loss: 0.9105 - val_categorical_accuracy: 0.7072\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.5852 - categorical_accuracy: 0.8049 - val_loss: 0.9895 - val_categorical_accuracy: 0.6850\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.4905 - categorical_accuracy: 0.8407 - val_loss: 1.0082 - val_categorical_accuracy: 0.6963\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.4047 - categorical_accuracy: 0.8676 - val_loss: 1.1237 - val_categorical_accuracy: 0.6673\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.3301 - categorical_accuracy: 0.8944 - val_loss: 1.0156 - val_categorical_accuracy: 0.7132\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.2745 - categorical_accuracy: 0.9128 - val_loss: 1.3111 - val_categorical_accuracy: 0.6571\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.2211 - categorical_accuracy: 0.9309 - val_loss: 1.0522 - val_categorical_accuracy: 0.7448\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.1735 - categorical_accuracy: 0.9436 - val_loss: 1.2213 - val_categorical_accuracy: 0.7128\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.1454 - categorical_accuracy: 0.9542 - val_loss: 1.1465 - val_categorical_accuracy: 0.7320\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1208 - categorical_accuracy: 0.9604 - val_loss: 1.2750 - val_categorical_accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0963 - categorical_accuracy: 0.9702 - val_loss: 1.1768 - val_categorical_accuracy: 0.7486\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0762 - categorical_accuracy: 0.9766 - val_loss: 1.3196 - val_categorical_accuracy: 0.7369\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0776 - categorical_accuracy: 0.9755 - val_loss: 1.3777 - val_categorical_accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0624 - categorical_accuracy: 0.9799 - val_loss: 1.3345 - val_categorical_accuracy: 0.7350\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0554 - categorical_accuracy: 0.9828 - val_loss: 1.3431 - val_categorical_accuracy: 0.7516\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0486 - categorical_accuracy: 0.9851 - val_loss: 2.4106 - val_categorical_accuracy: 0.6184\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0432 - categorical_accuracy: 0.9866 - val_loss: 1.6126 - val_categorical_accuracy: 0.7072\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0388 - categorical_accuracy: 0.9876 - val_loss: 1.5558 - val_categorical_accuracy: 0.7392\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
