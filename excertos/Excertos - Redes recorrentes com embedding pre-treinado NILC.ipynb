{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_EXCERTO</th>\n",
       "      <th>TEXTO_EXCERTO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995438</td>\n",
       "      <td>Voto:Cuidam os autos de tomada de contas espec...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025603</td>\n",
       "      <td>Voto:Cuidam os autos de Solicitação do Congres...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455375</td>\n",
       "      <td>Relatório:Trata-se de embargos de declaração o...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773747</td>\n",
       "      <td>Voto:8. Em relação a outros processos judiciai...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773403</td>\n",
       "      <td>Voto:11. Relativamente ao ato envolvendo a Sra...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_EXCERTO  \\\n",
       "0  Benefício previdenciário                    54995438   \n",
       "1                  Petróleo                    55025603   \n",
       "2                Dosimetria                    55455375   \n",
       "3          Decisão judicial                    54773747   \n",
       "4                 Nepotismo                    54773403   \n",
       "\n",
       "                                       TEXTO_EXCERTO                ACORDAO  \\\n",
       "0  Voto:Cuidam os autos de tomada de contas espec...  Acórdão 297/2016 - PL   \n",
       "1  Voto:Cuidam os autos de Solicitação do Congres...  Acórdão 366/2016 - PL   \n",
       "2  Relatório:Trata-se de embargos de declaração o...  Acórdão 944/2016 - PL   \n",
       "3  Voto:8. Em relação a outros processos judiciai...   Acórdão 30/2016 - PL   \n",
       "4  Voto:11. Relativamente ao ato envolvendo a Sra...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_excertos.CSV', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCR_AREA\n",
       "Competência do TCU          553\n",
       "Contrato Administrativo     941\n",
       "Convênio                    683\n",
       "Desestatização              139\n",
       "Direito Processual         1811\n",
       "Finanças Públicas           328\n",
       "Gestão Administrativa       338\n",
       "Licitação                  2756\n",
       "Pessoal                    3393\n",
       "Responsabilidade           2343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DESCR_AREA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63925 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "limite_texto = 2000\n",
    "dim_vetor = 50\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TEXTO_EXCERTO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_EXCERTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 2000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model-50.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 63925\n",
      "Encontrados no modelo: 42309 = 66.18537348455222\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, 50))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1109 21:38:39.397022 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1109 21:38:39.508047 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1109 21:38:39.510013 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1109 21:38:39.517586 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1109 21:38:39.518235 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1109 21:38:40.462336 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1109 21:38:40.563945 139841005438784 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 238,346\n",
      "Non-trainable params: 3,196,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 1.5679 - categorical_accuracy: 0.4743 - val_loss: 1.6392 - val_categorical_accuracy: 0.4592\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 532s 50ms/step - loss: 1.1560 - categorical_accuracy: 0.6139 - val_loss: 2.0258 - val_categorical_accuracy: 0.4392\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 526s 49ms/step - loss: 0.7645 - categorical_accuracy: 0.7430 - val_loss: 1.0589 - val_categorical_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 523s 49ms/step - loss: 0.6199 - categorical_accuracy: 0.7938 - val_loss: 0.8806 - val_categorical_accuracy: 0.7079\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 578s 54ms/step - loss: 0.5188 - categorical_accuracy: 0.8236 - val_loss: 0.9462 - val_categorical_accuracy: 0.7249\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 586s 55ms/step - loss: 0.4502 - categorical_accuracy: 0.8464 - val_loss: 0.8887 - val_categorical_accuracy: 0.7128\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 586s 55ms/step - loss: 0.3861 - categorical_accuracy: 0.8689 - val_loss: 0.9176 - val_categorical_accuracy: 0.7204\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 585s 55ms/step - loss: 0.3276 - categorical_accuracy: 0.8906 - val_loss: 1.1022 - val_categorical_accuracy: 0.6609\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 583s 55ms/step - loss: 0.2692 - categorical_accuracy: 0.9074 - val_loss: 1.0131 - val_categorical_accuracy: 0.7068\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 581s 55ms/step - loss: 0.2221 - categorical_accuracy: 0.9241 - val_loss: 1.0398 - val_categorical_accuracy: 0.7019\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 574s 54ms/step - loss: 0.1786 - categorical_accuracy: 0.9385 - val_loss: 1.0360 - val_categorical_accuracy: 0.7241\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 577s 54ms/step - loss: 0.1386 - categorical_accuracy: 0.9533 - val_loss: 1.1149 - val_categorical_accuracy: 0.7433\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 581s 55ms/step - loss: 0.1135 - categorical_accuracy: 0.9637 - val_loss: 1.1690 - val_categorical_accuracy: 0.7343\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 585s 55ms/step - loss: 0.0990 - categorical_accuracy: 0.9690 - val_loss: 1.2165 - val_categorical_accuracy: 0.7320\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 589s 55ms/step - loss: 0.0799 - categorical_accuracy: 0.9750 - val_loss: 1.5253 - val_categorical_accuracy: 0.6963\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 589s 55ms/step - loss: 0.0719 - categorical_accuracy: 0.9785 - val_loss: 1.2436 - val_categorical_accuracy: 0.7429\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 586s 55ms/step - loss: 0.0709 - categorical_accuracy: 0.9786 - val_loss: 1.3292 - val_categorical_accuracy: 0.7365\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 585s 55ms/step - loss: 0.0622 - categorical_accuracy: 0.9815 - val_loss: 1.4303 - val_categorical_accuracy: 0.7230\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 583s 55ms/step - loss: 0.0602 - categorical_accuracy: 0.9827 - val_loss: 1.4262 - val_categorical_accuracy: 0.7268\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 581s 55ms/step - loss: 0.0525 - categorical_accuracy: 0.9833 - val_loss: 1.5345 - val_categorical_accuracy: 0.7268\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 597s 56ms/step - loss: 1.5100 - categorical_accuracy: 0.4985 - val_loss: 1.4381 - val_categorical_accuracy: 0.5499\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 597s 56ms/step - loss: 0.8623 - categorical_accuracy: 0.7068 - val_loss: 0.9596 - val_categorical_accuracy: 0.6767\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 598s 56ms/step - loss: 0.6139 - categorical_accuracy: 0.7969 - val_loss: 0.8215 - val_categorical_accuracy: 0.7230\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 598s 56ms/step - loss: 0.4784 - categorical_accuracy: 0.8382 - val_loss: 0.7845 - val_categorical_accuracy: 0.7377\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 604s 57ms/step - loss: 0.3815 - categorical_accuracy: 0.8734 - val_loss: 0.7435 - val_categorical_accuracy: 0.7565\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 605s 57ms/step - loss: 0.2923 - categorical_accuracy: 0.9043 - val_loss: 0.8459 - val_categorical_accuracy: 0.7640\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 603s 57ms/step - loss: 0.2244 - categorical_accuracy: 0.9283 - val_loss: 0.9104 - val_categorical_accuracy: 0.7305\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 605s 57ms/step - loss: 0.1642 - categorical_accuracy: 0.9453 - val_loss: 0.9362 - val_categorical_accuracy: 0.7437\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 605s 57ms/step - loss: 0.1169 - categorical_accuracy: 0.9621 - val_loss: 0.9328 - val_categorical_accuracy: 0.7655\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 537s 51ms/step - loss: 0.0816 - categorical_accuracy: 0.9753 - val_loss: 1.1149 - val_categorical_accuracy: 0.7478\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0665 - categorical_accuracy: 0.9806 - val_loss: 1.0358 - val_categorical_accuracy: 0.7610\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0519 - categorical_accuracy: 0.9859 - val_loss: 1.3980 - val_categorical_accuracy: 0.7230\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0455 - categorical_accuracy: 0.9887 - val_loss: 1.3172 - val_categorical_accuracy: 0.7237\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0412 - categorical_accuracy: 0.9894 - val_loss: 1.1927 - val_categorical_accuracy: 0.7667\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0366 - categorical_accuracy: 0.9907 - val_loss: 1.3834 - val_categorical_accuracy: 0.7275\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0363 - categorical_accuracy: 0.9902 - val_loss: 1.2888 - val_categorical_accuracy: 0.7588\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0336 - categorical_accuracy: 0.9916 - val_loss: 1.2948 - val_categorical_accuracy: 0.7621\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0316 - categorical_accuracy: 0.9926 - val_loss: 1.3749 - val_categorical_accuracy: 0.7493\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0306 - categorical_accuracy: 0.9925 - val_loss: 1.2757 - val_categorical_accuracy: 0.7493\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0309 - categorical_accuracy: 0.9926 - val_loss: 1.3975 - val_categorical_accuracy: 0.7524\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               78592     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,277,462\n",
      "Trainable params: 3,277,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.8022 - categorical_accuracy: 0.3792 - val_loss: 1.8472 - val_categorical_accuracy: 0.3632\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.5877 - categorical_accuracy: 0.4645 - val_loss: 1.7761 - val_categorical_accuracy: 0.3959\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.5543 - categorical_accuracy: 0.4720 - val_loss: 1.8132 - val_categorical_accuracy: 0.4121\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.4108 - categorical_accuracy: 0.5315 - val_loss: 1.8337 - val_categorical_accuracy: 0.3741\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.6617 - categorical_accuracy: 0.4362 - val_loss: 1.8005 - val_categorical_accuracy: 0.3564\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.6285 - categorical_accuracy: 0.4534 - val_loss: 1.9228 - val_categorical_accuracy: 0.3613\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.5788 - categorical_accuracy: 0.4783 - val_loss: 1.9765 - val_categorical_accuracy: 0.3203\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4573 - categorical_accuracy: 0.5150 - val_loss: 1.8132 - val_categorical_accuracy: 0.3805\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4763 - categorical_accuracy: 0.5135 - val_loss: 1.8096 - val_categorical_accuracy: 0.3658\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4249 - categorical_accuracy: 0.5237 - val_loss: 1.7169 - val_categorical_accuracy: 0.4117\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4478 - categorical_accuracy: 0.5151 - val_loss: 1.7129 - val_categorical_accuracy: 0.4204\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4187 - categorical_accuracy: 0.5275 - val_loss: 1.8052 - val_categorical_accuracy: 0.3722\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.5296 - categorical_accuracy: 0.4949 - val_loss: 1.7845 - val_categorical_accuracy: 0.3922\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.5257 - categorical_accuracy: 0.4883 - val_loss: 1.7780 - val_categorical_accuracy: 0.3907\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4926 - categorical_accuracy: 0.5079 - val_loss: 1.7293 - val_categorical_accuracy: 0.4193\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4080 - categorical_accuracy: 0.5330 - val_loss: 1.8659 - val_categorical_accuracy: 0.3967\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4108 - categorical_accuracy: 0.5320 - val_loss: 1.8455 - val_categorical_accuracy: 0.4012\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.5337 - categorical_accuracy: 0.4825 - val_loss: 1.8201 - val_categorical_accuracy: 0.3873\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4767 - categorical_accuracy: 0.5027 - val_loss: 1.9619 - val_categorical_accuracy: 0.3752\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4093 - categorical_accuracy: 0.5280 - val_loss: 1.9824 - val_categorical_accuracy: 0.3365\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(SimpleRNN(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               314368    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,513,238\n",
      "Trainable params: 3,513,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 1.6297 - categorical_accuracy: 0.4571 - val_loss: 1.6669 - val_categorical_accuracy: 0.3948\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 1.4385 - categorical_accuracy: 0.5368 - val_loss: 1.6570 - val_categorical_accuracy: 0.4373\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 1.1224 - categorical_accuracy: 0.6362 - val_loss: 1.4561 - val_categorical_accuracy: 0.5119\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 0.9601 - categorical_accuracy: 0.6831 - val_loss: 1.1652 - val_categorical_accuracy: 0.6349\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.8488 - categorical_accuracy: 0.7224 - val_loss: 1.2021 - val_categorical_accuracy: 0.6176\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.7417 - categorical_accuracy: 0.7585 - val_loss: 1.0781 - val_categorical_accuracy: 0.6613\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.6610 - categorical_accuracy: 0.7877 - val_loss: 0.9819 - val_categorical_accuracy: 0.6940\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.5761 - categorical_accuracy: 0.8174 - val_loss: 1.0031 - val_categorical_accuracy: 0.6959\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 0.4847 - categorical_accuracy: 0.8499 - val_loss: 0.9278 - val_categorical_accuracy: 0.7151\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.4261 - categorical_accuracy: 0.8655 - val_loss: 0.9526 - val_categorical_accuracy: 0.6940\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.3656 - categorical_accuracy: 0.8820 - val_loss: 0.8433 - val_categorical_accuracy: 0.7418\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 0.3106 - categorical_accuracy: 0.9046 - val_loss: 0.9070 - val_categorical_accuracy: 0.7354\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.2516 - categorical_accuracy: 0.9238 - val_loss: 0.9668 - val_categorical_accuracy: 0.7414\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.2093 - categorical_accuracy: 0.9373 - val_loss: 1.0798 - val_categorical_accuracy: 0.7151\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1667 - categorical_accuracy: 0.9513 - val_loss: 1.0509 - val_categorical_accuracy: 0.7317\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1311 - categorical_accuracy: 0.9610 - val_loss: 1.1532 - val_categorical_accuracy: 0.7369\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1030 - categorical_accuracy: 0.9674 - val_loss: 1.1818 - val_categorical_accuracy: 0.7373\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.0824 - categorical_accuracy: 0.9746 - val_loss: 1.3457 - val_categorical_accuracy: 0.7091\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.0658 - categorical_accuracy: 0.9812 - val_loss: 1.2166 - val_categorical_accuracy: 0.7411\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.0530 - categorical_accuracy: 0.9847 - val_loss: 1.4176 - val_categorical_accuracy: 0.7482\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               157184    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,358,614\n",
      "Trainable params: 3,358,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.8694 - categorical_accuracy: 0.3506 - val_loss: 2.0536 - val_categorical_accuracy: 0.1607\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.7790 - categorical_accuracy: 0.3896 - val_loss: 1.9545 - val_categorical_accuracy: 0.3150\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5758 - categorical_accuracy: 0.4721 - val_loss: 1.8297 - val_categorical_accuracy: 0.3816\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4784 - categorical_accuracy: 0.5028 - val_loss: 1.7845 - val_categorical_accuracy: 0.4065\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4736 - categorical_accuracy: 0.4992 - val_loss: 1.8624 - val_categorical_accuracy: 0.3824\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5342 - categorical_accuracy: 0.4769 - val_loss: 1.8850 - val_categorical_accuracy: 0.3225\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.6580 - categorical_accuracy: 0.4352 - val_loss: 1.9869 - val_categorical_accuracy: 0.3214\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.6053 - categorical_accuracy: 0.4566 - val_loss: 2.0468 - val_categorical_accuracy: 0.3335\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5335 - categorical_accuracy: 0.4836 - val_loss: 1.8619 - val_categorical_accuracy: 0.4524\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4696 - categorical_accuracy: 0.5116 - val_loss: 1.6681 - val_categorical_accuracy: 0.4539\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 317s 30ms/step - loss: 1.5552 - categorical_accuracy: 0.4728 - val_loss: 1.8863 - val_categorical_accuracy: 0.3824\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4978 - categorical_accuracy: 0.4945 - val_loss: 1.8832 - val_categorical_accuracy: 0.3734\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4853 - categorical_accuracy: 0.5007 - val_loss: 2.2548 - val_categorical_accuracy: 0.2766\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4441 - categorical_accuracy: 0.5155 - val_loss: 2.3684 - val_categorical_accuracy: 0.2680\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.3376 - categorical_accuracy: 0.5570 - val_loss: 1.9888 - val_categorical_accuracy: 0.3143\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.3971 - categorical_accuracy: 0.5296 - val_loss: 1.8770 - val_categorical_accuracy: 0.3718\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5183 - categorical_accuracy: 0.4820 - val_loss: 1.9783 - val_categorical_accuracy: 0.2951\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5257 - categorical_accuracy: 0.4782 - val_loss: 2.2992 - val_categorical_accuracy: 0.1810\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4012 - categorical_accuracy: 0.5394 - val_loss: 2.0670 - val_categorical_accuracy: 0.3387\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4014 - categorical_accuracy: 0.5290 - val_loss: 2.0221 - val_categorical_accuracy: 0.3971\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(SimpleRNN(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               471552    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,672,982\n",
      "Trainable params: 3,672,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 960s 90ms/step - loss: 1.5467 - categorical_accuracy: 0.4857 - val_loss: 1.3788 - val_categorical_accuracy: 0.5250\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 960s 90ms/step - loss: 0.8882 - categorical_accuracy: 0.7022 - val_loss: 1.1880 - val_categorical_accuracy: 0.5713\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 960s 90ms/step - loss: 0.6350 - categorical_accuracy: 0.7921 - val_loss: 0.9020 - val_categorical_accuracy: 0.6936\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 962s 91ms/step - loss: 0.4898 - categorical_accuracy: 0.8359 - val_loss: 0.7742 - val_categorical_accuracy: 0.7448\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1120s 105ms/step - loss: 0.3825 - categorical_accuracy: 0.8712 - val_loss: 0.9894 - val_categorical_accuracy: 0.7087\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1109s 104ms/step - loss: 0.2990 - categorical_accuracy: 0.9024 - val_loss: 0.8409 - val_categorical_accuracy: 0.7557\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1108s 104ms/step - loss: 0.2360 - categorical_accuracy: 0.9220 - val_loss: 0.8116 - val_categorical_accuracy: 0.7670\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1113s 105ms/step - loss: 0.1768 - categorical_accuracy: 0.9434 - val_loss: 0.9662 - val_categorical_accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1112s 105ms/step - loss: 0.1279 - categorical_accuracy: 0.9597 - val_loss: 0.9090 - val_categorical_accuracy: 0.7629\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1109s 104ms/step - loss: 0.0897 - categorical_accuracy: 0.9741 - val_loss: 1.0145 - val_categorical_accuracy: 0.7689\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1125s 106ms/step - loss: 0.0676 - categorical_accuracy: 0.9796 - val_loss: 1.6035 - val_categorical_accuracy: 0.6586\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1115s 105ms/step - loss: 0.0556 - categorical_accuracy: 0.9843 - val_loss: 1.1299 - val_categorical_accuracy: 0.7561\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1106s 104ms/step - loss: 0.0466 - categorical_accuracy: 0.9880 - val_loss: 1.1907 - val_categorical_accuracy: 0.7618\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1105s 104ms/step - loss: 0.0407 - categorical_accuracy: 0.9892 - val_loss: 1.3658 - val_categorical_accuracy: 0.7335\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1116s 105ms/step - loss: 0.0395 - categorical_accuracy: 0.9897 - val_loss: 1.5310 - val_categorical_accuracy: 0.7046\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1016s 96ms/step - loss: 0.0392 - categorical_accuracy: 0.9909 - val_loss: 1.3348 - val_categorical_accuracy: 0.7520\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 968s 91ms/step - loss: 0.0331 - categorical_accuracy: 0.9917 - val_loss: 1.2675 - val_categorical_accuracy: 0.7569\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 963s 91ms/step - loss: 0.0282 - categorical_accuracy: 0.9931 - val_loss: 1.4432 - val_categorical_accuracy: 0.7309\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 961s 90ms/step - loss: 0.0308 - categorical_accuracy: 0.9921 - val_loss: 1.4256 - val_categorical_accuracy: 0.7396\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 962s 90ms/step - loss: 0.0269 - categorical_accuracy: 0.9928 - val_loss: 1.3407 - val_categorical_accuracy: 0.7580\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(GRU(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1111 10:31:41.187237 140316744189760 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1111 10:31:41.314905 140316744189760 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               628736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,830,166\n",
      "Trainable params: 3,830,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 1299s 122ms/step - loss: 1.6197 - categorical_accuracy: 0.4676 - val_loss: 1.6418 - val_categorical_accuracy: 0.4603\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1284s 121ms/step - loss: 1.2963 - categorical_accuracy: 0.5903 - val_loss: 1.2863 - val_categorical_accuracy: 0.5781\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1272s 120ms/step - loss: 1.0950 - categorical_accuracy: 0.6479 - val_loss: 1.5062 - val_categorical_accuracy: 0.4693\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.9532 - categorical_accuracy: 0.6923 - val_loss: 1.2663 - val_categorical_accuracy: 0.5864\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.8377 - categorical_accuracy: 0.7316 - val_loss: 1.3789 - val_categorical_accuracy: 0.5344\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1268s 119ms/step - loss: 0.7468 - categorical_accuracy: 0.7583 - val_loss: 1.1232 - val_categorical_accuracy: 0.6282\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.6775 - categorical_accuracy: 0.7845 - val_loss: 1.2356 - val_categorical_accuracy: 0.6440\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1267s 119ms/step - loss: 0.6032 - categorical_accuracy: 0.8093 - val_loss: 1.1911 - val_categorical_accuracy: 0.6278\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1270s 119ms/step - loss: 0.5199 - categorical_accuracy: 0.8390 - val_loss: 0.9886 - val_categorical_accuracy: 0.7015\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1270s 120ms/step - loss: 0.4536 - categorical_accuracy: 0.8617 - val_loss: 0.8854 - val_categorical_accuracy: 0.7354\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1268s 119ms/step - loss: 0.3855 - categorical_accuracy: 0.8797 - val_loss: 0.9314 - val_categorical_accuracy: 0.7384\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1271s 120ms/step - loss: 0.3389 - categorical_accuracy: 0.8942 - val_loss: 0.9423 - val_categorical_accuracy: 0.7520\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1271s 120ms/step - loss: 0.2771 - categorical_accuracy: 0.9154 - val_loss: 0.9706 - val_categorical_accuracy: 0.7460\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1271s 120ms/step - loss: 0.2278 - categorical_accuracy: 0.9298 - val_loss: 1.0698 - val_categorical_accuracy: 0.7377\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.1829 - categorical_accuracy: 0.9427 - val_loss: 1.1441 - val_categorical_accuracy: 0.7185\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.1504 - categorical_accuracy: 0.9530 - val_loss: 1.3062 - val_categorical_accuracy: 0.6869\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1270s 120ms/step - loss: 0.1162 - categorical_accuracy: 0.9647 - val_loss: 1.1157 - val_categorical_accuracy: 0.7241\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1273s 120ms/step - loss: 0.0921 - categorical_accuracy: 0.9733 - val_loss: 1.2401 - val_categorical_accuracy: 0.7381\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1271s 120ms/step - loss: 0.0764 - categorical_accuracy: 0.9769 - val_loss: 1.2146 - val_categorical_accuracy: 0.7411\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.0596 - categorical_accuracy: 0.9820 - val_loss: 1.6630 - val_categorical_accuracy: 0.7057\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               68736     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,266,326\n",
      "Trainable params: 3,266,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 1.6034 - categorical_accuracy: 0.4658 - val_loss: 2.5983 - val_categorical_accuracy: 0.3192\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 1.0397 - categorical_accuracy: 0.6543 - val_loss: 1.4482 - val_categorical_accuracy: 0.5551\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.7640 - categorical_accuracy: 0.7408 - val_loss: 0.9939 - val_categorical_accuracy: 0.6707\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.6010 - categorical_accuracy: 0.7990 - val_loss: 0.8951 - val_categorical_accuracy: 0.7057\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.4773 - categorical_accuracy: 0.8395 - val_loss: 0.7632 - val_categorical_accuracy: 0.7554\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.3923 - categorical_accuracy: 0.8739 - val_loss: 0.7861 - val_categorical_accuracy: 0.7599\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.3181 - categorical_accuracy: 0.8966 - val_loss: 0.7803 - val_categorical_accuracy: 0.7550\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.2614 - categorical_accuracy: 0.9149 - val_loss: 0.8082 - val_categorical_accuracy: 0.7629\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.1997 - categorical_accuracy: 0.9348 - val_loss: 0.9035 - val_categorical_accuracy: 0.7381\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.1475 - categorical_accuracy: 0.9548 - val_loss: 0.9238 - val_categorical_accuracy: 0.7535\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.1068 - categorical_accuracy: 0.9660 - val_loss: 1.0372 - val_categorical_accuracy: 0.7365\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.0739 - categorical_accuracy: 0.9763 - val_loss: 1.0755 - val_categorical_accuracy: 0.7512\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0592 - categorical_accuracy: 0.9826 - val_loss: 1.1135 - val_categorical_accuracy: 0.7584\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.0428 - categorical_accuracy: 0.9877 - val_loss: 1.2588 - val_categorical_accuracy: 0.7347\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0398 - categorical_accuracy: 0.9892 - val_loss: 1.2526 - val_categorical_accuracy: 0.7441\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0364 - categorical_accuracy: 0.9907 - val_loss: 1.3089 - val_categorical_accuracy: 0.7381\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0413 - categorical_accuracy: 0.9895 - val_loss: 1.2695 - val_categorical_accuracy: 0.7422\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0298 - categorical_accuracy: 0.9921 - val_loss: 1.3351 - val_categorical_accuracy: 0.7422\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0287 - categorical_accuracy: 0.9921 - val_loss: 1.3438 - val_categorical_accuracy: 0.7414\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0263 - categorical_accuracy: 0.9922 - val_loss: 1.2006 - val_categorical_accuracy: 0.7633\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                22080     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,219,030\n",
      "Trainable params: 3,219,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 1.6525 - categorical_accuracy: 0.4384 - val_loss: 2.1563 - val_categorical_accuracy: 0.3681\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 1.1358 - categorical_accuracy: 0.6306 - val_loss: 1.4984 - val_categorical_accuracy: 0.5171\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.8929 - categorical_accuracy: 0.6934 - val_loss: 1.1013 - val_categorical_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.7244 - categorical_accuracy: 0.7565 - val_loss: 0.9468 - val_categorical_accuracy: 0.6967\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.6055 - categorical_accuracy: 0.8004 - val_loss: 0.8940 - val_categorical_accuracy: 0.7211\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.5104 - categorical_accuracy: 0.8368 - val_loss: 0.8519 - val_categorical_accuracy: 0.7433\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.4289 - categorical_accuracy: 0.8633 - val_loss: 0.9383 - val_categorical_accuracy: 0.7189\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.3526 - categorical_accuracy: 0.8890 - val_loss: 0.8891 - val_categorical_accuracy: 0.7441\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.2892 - categorical_accuracy: 0.9138 - val_loss: 0.8807 - val_categorical_accuracy: 0.7456\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.2326 - categorical_accuracy: 0.9313 - val_loss: 0.9328 - val_categorical_accuracy: 0.7433\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.1842 - categorical_accuracy: 0.9457 - val_loss: 0.9454 - val_categorical_accuracy: 0.7478\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.1420 - categorical_accuracy: 0.9600 - val_loss: 1.1919 - val_categorical_accuracy: 0.6978\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.1083 - categorical_accuracy: 0.9700 - val_loss: 1.1337 - val_categorical_accuracy: 0.7301\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0836 - categorical_accuracy: 0.9767 - val_loss: 1.1558 - val_categorical_accuracy: 0.7407\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0648 - categorical_accuracy: 0.9822 - val_loss: 1.2343 - val_categorical_accuracy: 0.7354\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0520 - categorical_accuracy: 0.9857 - val_loss: 1.3480 - val_categorical_accuracy: 0.7354\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0448 - categorical_accuracy: 0.9885 - val_loss: 1.3368 - val_categorical_accuracy: 0.7309\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0374 - categorical_accuracy: 0.9902 - val_loss: 1.4929 - val_categorical_accuracy: 0.7038\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 552s 52ms/step - loss: 0.0338 - categorical_accuracy: 0.9912 - val_loss: 1.4611 - val_categorical_accuracy: 0.7170\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0314 - categorical_accuracy: 0.9912 - val_loss: 1.4187 - val_categorical_accuracy: 0.7234\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 512)               864768    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,066,198\n",
      "Trainable params: 4,066,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 1.6841 - categorical_accuracy: 0.4659 - val_loss: 1.2552 - val_categorical_accuracy: 0.5947\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.8227 - categorical_accuracy: 0.7266 - val_loss: 1.0896 - val_categorical_accuracy: 0.6394\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.5702 - categorical_accuracy: 0.8118 - val_loss: 0.9075 - val_categorical_accuracy: 0.6842\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.4387 - categorical_accuracy: 0.8522 - val_loss: 0.7865 - val_categorical_accuracy: 0.7426\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.3352 - categorical_accuracy: 0.8887 - val_loss: 0.8078 - val_categorical_accuracy: 0.7723\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.5285 - categorical_accuracy: 0.8327 - val_loss: 1.0262 - val_categorical_accuracy: 0.6831\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.2774 - categorical_accuracy: 0.9087 - val_loss: 0.8457 - val_categorical_accuracy: 0.7501\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.1765 - categorical_accuracy: 0.9424 - val_loss: 0.8726 - val_categorical_accuracy: 0.7505\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.1245 - categorical_accuracy: 0.9606 - val_loss: 1.0891 - val_categorical_accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.0881 - categorical_accuracy: 0.9731 - val_loss: 1.1023 - val_categorical_accuracy: 0.7429\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.0685 - categorical_accuracy: 0.9811 - val_loss: 1.1665 - val_categorical_accuracy: 0.7557\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.0604 - categorical_accuracy: 0.9833 - val_loss: 1.1195 - val_categorical_accuracy: 0.7606\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.0536 - categorical_accuracy: 0.9851 - val_loss: 1.1309 - val_categorical_accuracy: 0.7640\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0477 - categorical_accuracy: 0.9880 - val_loss: 1.3742 - val_categorical_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.0446 - categorical_accuracy: 0.9881 - val_loss: 1.3569 - val_categorical_accuracy: 0.7588\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0417 - categorical_accuracy: 0.9894 - val_loss: 1.4128 - val_categorical_accuracy: 0.7444\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0385 - categorical_accuracy: 0.9907 - val_loss: 1.3302 - val_categorical_accuracy: 0.7542\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0419 - categorical_accuracy: 0.9903 - val_loss: 1.4240 - val_categorical_accuracy: 0.7362\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0375 - categorical_accuracy: 0.9917 - val_loss: 1.3662 - val_categorical_accuracy: 0.7505\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 549s 52ms/step - loss: 0.0357 - categorical_accuracy: 0.9914 - val_loss: 1.3927 - val_categorical_accuracy: 0.7546\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(512))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,466,262\n",
      "Trainable params: 3,466,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 1.5363 - categorical_accuracy: 0.4850 - val_loss: 1.7790 - val_categorical_accuracy: 0.5047\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.8849 - categorical_accuracy: 0.7088 - val_loss: 1.3166 - val_categorical_accuracy: 0.5295\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.6151 - categorical_accuracy: 0.7939 - val_loss: 0.9736 - val_categorical_accuracy: 0.6613\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.4722 - categorical_accuracy: 0.8417 - val_loss: 0.8939 - val_categorical_accuracy: 0.7283\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.3681 - categorical_accuracy: 0.8782 - val_loss: 0.8587 - val_categorical_accuracy: 0.7290\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.2812 - categorical_accuracy: 0.9077 - val_loss: 1.0796 - val_categorical_accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.2043 - categorical_accuracy: 0.9340 - val_loss: 0.9500 - val_categorical_accuracy: 0.7396\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.1455 - categorical_accuracy: 0.9538 - val_loss: 1.0182 - val_categorical_accuracy: 0.7497\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0974 - categorical_accuracy: 0.9698 - val_loss: 1.1977 - val_categorical_accuracy: 0.7554\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0767 - categorical_accuracy: 0.9770 - val_loss: 1.2177 - val_categorical_accuracy: 0.7689\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0643 - categorical_accuracy: 0.9817 - val_loss: 1.3093 - val_categorical_accuracy: 0.7591\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 547s 51ms/step - loss: 0.0538 - categorical_accuracy: 0.9848 - val_loss: 1.2878 - val_categorical_accuracy: 0.7644\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 547s 51ms/step - loss: 0.0449 - categorical_accuracy: 0.9880 - val_loss: 1.4156 - val_categorical_accuracy: 0.7599\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0456 - categorical_accuracy: 0.9892 - val_loss: 1.4493 - val_categorical_accuracy: 0.7460\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0418 - categorical_accuracy: 0.9901 - val_loss: 1.4276 - val_categorical_accuracy: 0.7565\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0379 - categorical_accuracy: 0.9913 - val_loss: 1.4927 - val_categorical_accuracy: 0.7524\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0370 - categorical_accuracy: 0.9910 - val_loss: 1.4560 - val_categorical_accuracy: 0.7493\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 548s 52ms/step - loss: 0.0339 - categorical_accuracy: 0.9915 - val_loss: 1.5560 - val_categorical_accuracy: 0.7452\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0349 - categorical_accuracy: 0.9920 - val_loss: 1.6689 - val_categorical_accuracy: 0.7339\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 546s 51ms/step - loss: 0.0287 - categorical_accuracy: 0.9926 - val_loss: 1.6233 - val_categorical_accuracy: 0.7343\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,449,174\n",
      "Trainable params: 3,449,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 1.5458 - categorical_accuracy: 0.4850 - val_loss: 1.4242 - val_categorical_accuracy: 0.5265\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 1.0631 - categorical_accuracy: 0.6480 - val_loss: 1.0291 - val_categorical_accuracy: 0.6616\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.6689 - categorical_accuracy: 0.7778 - val_loss: 1.1104 - val_categorical_accuracy: 0.6172\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.5119 - categorical_accuracy: 0.8316 - val_loss: 0.8133 - val_categorical_accuracy: 0.7377\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.3963 - categorical_accuracy: 0.8670 - val_loss: 1.0149 - val_categorical_accuracy: 0.6775\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.3087 - categorical_accuracy: 0.8982 - val_loss: 0.9803 - val_categorical_accuracy: 0.7079\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.2316 - categorical_accuracy: 0.9202 - val_loss: 0.9259 - val_categorical_accuracy: 0.7388\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.1640 - categorical_accuracy: 0.9467 - val_loss: 0.9629 - val_categorical_accuracy: 0.7550\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.1185 - categorical_accuracy: 0.9642 - val_loss: 1.0425 - val_categorical_accuracy: 0.7535\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0868 - categorical_accuracy: 0.9743 - val_loss: 1.1630 - val_categorical_accuracy: 0.7505\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0678 - categorical_accuracy: 0.9805 - val_loss: 1.1821 - val_categorical_accuracy: 0.7584\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0562 - categorical_accuracy: 0.9849 - val_loss: 1.5091 - val_categorical_accuracy: 0.7245\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0516 - categorical_accuracy: 0.9851 - val_loss: 1.4264 - val_categorical_accuracy: 0.7595\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0462 - categorical_accuracy: 0.9883 - val_loss: 1.4600 - val_categorical_accuracy: 0.7531\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0413 - categorical_accuracy: 0.9905 - val_loss: 1.4950 - val_categorical_accuracy: 0.7388\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0382 - categorical_accuracy: 0.9915 - val_loss: 1.4990 - val_categorical_accuracy: 0.7486\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 545s 51ms/step - loss: 0.0376 - categorical_accuracy: 0.9904 - val_loss: 1.4073 - val_categorical_accuracy: 0.7486\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0356 - categorical_accuracy: 0.9912 - val_loss: 1.3985 - val_categorical_accuracy: 0.7550\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0328 - categorical_accuracy: 0.9920 - val_loss: 1.9460 - val_categorical_accuracy: 0.6921\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 544s 51ms/step - loss: 0.0329 - categorical_accuracy: 0.9913 - val_loss: 1.6313 - val_categorical_accuracy: 0.7241\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,440,630\n",
      "Trainable params: 3,440,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 1.5851 - categorical_accuracy: 0.4690 - val_loss: 1.6176 - val_categorical_accuracy: 0.4780\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.9024 - categorical_accuracy: 0.6923 - val_loss: 1.0262 - val_categorical_accuracy: 0.6522\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.6470 - categorical_accuracy: 0.7847 - val_loss: 1.0240 - val_categorical_accuracy: 0.6805\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.4927 - categorical_accuracy: 0.8377 - val_loss: 0.9080 - val_categorical_accuracy: 0.7008\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.3823 - categorical_accuracy: 0.8718 - val_loss: 0.9002 - val_categorical_accuracy: 0.7170\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.2939 - categorical_accuracy: 0.9043 - val_loss: 0.7940 - val_categorical_accuracy: 0.7742\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.2234 - categorical_accuracy: 0.9280 - val_loss: 0.8147 - val_categorical_accuracy: 0.7663\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.1556 - categorical_accuracy: 0.9497 - val_loss: 0.9226 - val_categorical_accuracy: 0.7700\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.1098 - categorical_accuracy: 0.9644 - val_loss: 1.3402 - val_categorical_accuracy: 0.6884\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0795 - categorical_accuracy: 0.9763 - val_loss: 1.1770 - val_categorical_accuracy: 0.7508\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0648 - categorical_accuracy: 0.9806 - val_loss: 1.2593 - val_categorical_accuracy: 0.7497\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0554 - categorical_accuracy: 0.9861 - val_loss: 1.1915 - val_categorical_accuracy: 0.7539\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0440 - categorical_accuracy: 0.9873 - val_loss: 1.4005 - val_categorical_accuracy: 0.7373\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0423 - categorical_accuracy: 0.9885 - val_loss: 1.4164 - val_categorical_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0402 - categorical_accuracy: 0.9906 - val_loss: 1.3961 - val_categorical_accuracy: 0.7486\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0380 - categorical_accuracy: 0.9908 - val_loss: 1.5017 - val_categorical_accuracy: 0.7407\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0355 - categorical_accuracy: 0.9902 - val_loss: 1.5284 - val_categorical_accuracy: 0.7501\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 551s 52ms/step - loss: 0.0342 - categorical_accuracy: 0.9914 - val_loss: 1.6299 - val_categorical_accuracy: 0.7339\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0345 - categorical_accuracy: 0.9915 - val_loss: 1.5056 - val_categorical_accuracy: 0.7490\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 550s 52ms/step - loss: 0.0298 - categorical_accuracy: 0.9923 - val_loss: 1.6799 - val_categorical_accuracy: 0.7399\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1112 11:54:13.561027 140316744189760 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 645s 61ms/step - loss: 1.6276 - categorical_accuracy: 0.4529 - val_loss: 1.5301 - val_categorical_accuracy: 0.4900\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 1.0676 - categorical_accuracy: 0.6519 - val_loss: 1.0917 - val_categorical_accuracy: 0.6394\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.7954 - categorical_accuracy: 0.7371 - val_loss: 1.0580 - val_categorical_accuracy: 0.6458\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.7097 - categorical_accuracy: 0.7613 - val_loss: 0.8724 - val_categorical_accuracy: 0.7143\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.6446 - categorical_accuracy: 0.7853 - val_loss: 0.8304 - val_categorical_accuracy: 0.7207\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.5896 - categorical_accuracy: 0.8039 - val_loss: 0.9846 - val_categorical_accuracy: 0.6334\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.5095 - categorical_accuracy: 0.8315 - val_loss: 0.9060 - val_categorical_accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 643s 60ms/step - loss: 0.4452 - categorical_accuracy: 0.8506 - val_loss: 0.7960 - val_categorical_accuracy: 0.7384\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 644s 61ms/step - loss: 0.3974 - categorical_accuracy: 0.8679 - val_loss: 0.7449 - val_categorical_accuracy: 0.7546\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 642s 60ms/step - loss: 0.3513 - categorical_accuracy: 0.8830 - val_loss: 0.6997 - val_categorical_accuracy: 0.7753\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.3108 - categorical_accuracy: 0.8988 - val_loss: 0.7927 - val_categorical_accuracy: 0.7497\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.2783 - categorical_accuracy: 0.9048 - val_loss: 0.7751 - val_categorical_accuracy: 0.7614\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.2456 - categorical_accuracy: 0.9182 - val_loss: 0.8231 - val_categorical_accuracy: 0.7595\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.2108 - categorical_accuracy: 0.9298 - val_loss: 0.8625 - val_categorical_accuracy: 0.7606\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.1910 - categorical_accuracy: 0.9353 - val_loss: 0.8402 - val_categorical_accuracy: 0.7614\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.1680 - categorical_accuracy: 0.9419 - val_loss: 0.8622 - val_categorical_accuracy: 0.7674\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.1300 - categorical_accuracy: 0.9572 - val_loss: 0.8714 - val_categorical_accuracy: 0.7700\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.1322 - categorical_accuracy: 0.9551 - val_loss: 0.8693 - val_categorical_accuracy: 0.7821\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.1225 - categorical_accuracy: 0.9585 - val_loss: 0.9380 - val_categorical_accuracy: 0.7689\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 643s 61ms/step - loss: 0.1162 - categorical_accuracy: 0.9606 - val_loss: 0.9870 - val_categorical_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 638s 60ms/step - loss: 1.7145 - categorical_accuracy: 0.4172 - val_loss: 1.6609 - val_categorical_accuracy: 0.4219\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 1.1842 - categorical_accuracy: 0.6155 - val_loss: 1.1963 - val_categorical_accuracy: 0.5864\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 0.9259 - categorical_accuracy: 0.6923 - val_loss: 1.0908 - val_categorical_accuracy: 0.6346\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 0.7916 - categorical_accuracy: 0.7381 - val_loss: 1.0321 - val_categorical_accuracy: 0.6616\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.7246 - categorical_accuracy: 0.7623 - val_loss: 0.9822 - val_categorical_accuracy: 0.6733\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.6428 - categorical_accuracy: 0.7878 - val_loss: 0.8843 - val_categorical_accuracy: 0.7061\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 0.5459 - categorical_accuracy: 0.8172 - val_loss: 0.7489 - val_categorical_accuracy: 0.7524\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.4759 - categorical_accuracy: 0.8415 - val_loss: 0.7863 - val_categorical_accuracy: 0.7486\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.4199 - categorical_accuracy: 0.8627 - val_loss: 0.8343 - val_categorical_accuracy: 0.7324\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 0.5288 - categorical_accuracy: 0.8296 - val_loss: 0.7454 - val_categorical_accuracy: 0.7591\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 0.4555 - categorical_accuracy: 0.8527 - val_loss: 0.7926 - val_categorical_accuracy: 0.7486\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.4415 - categorical_accuracy: 0.8577 - val_loss: 0.7680 - val_categorical_accuracy: 0.7576\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.4059 - categorical_accuracy: 0.8655 - val_loss: 0.7761 - val_categorical_accuracy: 0.7572\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 636s 60ms/step - loss: 0.3727 - categorical_accuracy: 0.8775 - val_loss: 0.7606 - val_categorical_accuracy: 0.7618\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.3639 - categorical_accuracy: 0.8823 - val_loss: 0.7531 - val_categorical_accuracy: 0.7659\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.3477 - categorical_accuracy: 0.8851 - val_loss: 0.7541 - val_categorical_accuracy: 0.7644\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.3309 - categorical_accuracy: 0.8904 - val_loss: 0.7799 - val_categorical_accuracy: 0.7685\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.3168 - categorical_accuracy: 0.8970 - val_loss: 0.7745 - val_categorical_accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.3048 - categorical_accuracy: 0.9038 - val_loss: 0.7921 - val_categorical_accuracy: 0.7697\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 637s 60ms/step - loss: 0.2872 - categorical_accuracy: 0.9063 - val_loss: 0.7965 - val_categorical_accuracy: 0.7685\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 561s 53ms/step - loss: 1.4895 - categorical_accuracy: 0.4989 - val_loss: 1.2339 - val_categorical_accuracy: 0.6214\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.8223 - categorical_accuracy: 0.7224 - val_loss: 1.0568 - val_categorical_accuracy: 0.6650\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.5672 - categorical_accuracy: 0.8138 - val_loss: 0.9360 - val_categorical_accuracy: 0.6782\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 560s 53ms/step - loss: 0.3955 - categorical_accuracy: 0.8705 - val_loss: 0.8907 - val_categorical_accuracy: 0.7128\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.2621 - categorical_accuracy: 0.9192 - val_loss: 0.9055 - val_categorical_accuracy: 0.7241\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 560s 53ms/step - loss: 0.1539 - categorical_accuracy: 0.9514 - val_loss: 0.8987 - val_categorical_accuracy: 0.7452\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.0896 - categorical_accuracy: 0.9741 - val_loss: 1.0650 - val_categorical_accuracy: 0.7298\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.0599 - categorical_accuracy: 0.9837 - val_loss: 1.1129 - val_categorical_accuracy: 0.7463\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.0523 - categorical_accuracy: 0.9868 - val_loss: 1.1375 - val_categorical_accuracy: 0.7463\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.0306 - categorical_accuracy: 0.9924 - val_loss: 1.1928 - val_categorical_accuracy: 0.7524\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.0294 - categorical_accuracy: 0.9928 - val_loss: 1.1403 - val_categorical_accuracy: 0.7482\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 559s 53ms/step - loss: 0.0264 - categorical_accuracy: 0.9928 - val_loss: 1.1361 - val_categorical_accuracy: 0.7580\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 565s 53ms/step - loss: 0.0258 - categorical_accuracy: 0.9935 - val_loss: 1.1535 - val_categorical_accuracy: 0.7497\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 616s 58ms/step - loss: 0.0344 - categorical_accuracy: 0.9915 - val_loss: 1.3192 - val_categorical_accuracy: 0.7422\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 627s 59ms/step - loss: 0.0257 - categorical_accuracy: 0.9930 - val_loss: 1.1723 - val_categorical_accuracy: 0.7482\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 627s 59ms/step - loss: 0.0231 - categorical_accuracy: 0.9933 - val_loss: 1.3740 - val_categorical_accuracy: 0.7042\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 625s 59ms/step - loss: 0.0206 - categorical_accuracy: 0.9937 - val_loss: 1.3957 - val_categorical_accuracy: 0.7155\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 622s 58ms/step - loss: 0.0239 - categorical_accuracy: 0.9928 - val_loss: 1.2827 - val_categorical_accuracy: 0.7373\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 622s 59ms/step - loss: 0.0199 - categorical_accuracy: 0.9939 - val_loss: 1.3336 - val_categorical_accuracy: 0.7264\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 628s 59ms/step - loss: 0.0197 - categorical_accuracy: 0.9940 - val_loss: 1.3009 - val_categorical_accuracy: 0.7377\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 557s 52ms/step - loss: 1.6728 - categorical_accuracy: 0.4335 - val_loss: 1.6345 - val_categorical_accuracy: 0.4185\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 1.1424 - categorical_accuracy: 0.6219 - val_loss: 1.3226 - val_categorical_accuracy: 0.5386\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.9003 - categorical_accuracy: 0.6974 - val_loss: 1.1214 - val_categorical_accuracy: 0.6067\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.7246 - categorical_accuracy: 0.7583 - val_loss: 1.1456 - val_categorical_accuracy: 0.6011\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.6583 - categorical_accuracy: 0.7822 - val_loss: 0.9769 - val_categorical_accuracy: 0.6812\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.5745 - categorical_accuracy: 0.8124 - val_loss: 0.9240 - val_categorical_accuracy: 0.7023\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.5459 - categorical_accuracy: 0.8198 - val_loss: 0.9577 - val_categorical_accuracy: 0.6775\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.4867 - categorical_accuracy: 0.8405 - val_loss: 0.8749 - val_categorical_accuracy: 0.7429\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.4343 - categorical_accuracy: 0.8561 - val_loss: 1.0173 - val_categorical_accuracy: 0.6553\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.3788 - categorical_accuracy: 0.8734 - val_loss: 0.9338 - val_categorical_accuracy: 0.7185\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.3335 - categorical_accuracy: 0.8879 - val_loss: 0.8577 - val_categorical_accuracy: 0.7354\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.2855 - categorical_accuracy: 0.9024 - val_loss: 0.8654 - val_categorical_accuracy: 0.7505\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 554s 52ms/step - loss: 0.2371 - categorical_accuracy: 0.9203 - val_loss: 0.8360 - val_categorical_accuracy: 0.7478\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.1959 - categorical_accuracy: 0.9355 - val_loss: 0.9151 - val_categorical_accuracy: 0.7524\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.1545 - categorical_accuracy: 0.9512 - val_loss: 1.0304 - val_categorical_accuracy: 0.7452\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.1161 - categorical_accuracy: 0.9633 - val_loss: 1.1453 - val_categorical_accuracy: 0.7384\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0847 - categorical_accuracy: 0.9733 - val_loss: 1.1139 - val_categorical_accuracy: 0.7441\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0651 - categorical_accuracy: 0.9800 - val_loss: 1.2265 - val_categorical_accuracy: 0.7347\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 0.0563 - categorical_accuracy: 0.9836 - val_loss: 1.2753 - val_categorical_accuracy: 0.7414\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 556s 52ms/step - loss: 0.0445 - categorical_accuracy: 0.9883 - val_loss: 1.4700 - val_categorical_accuracy: 0.7147\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 2000, 256)         235776    \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 32)                27744     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,460,150\n",
      "Trainable params: 3,460,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 1131s 106ms/step - loss: 1.4902 - categorical_accuracy: 0.4984 - val_loss: 1.8489 - val_categorical_accuracy: 0.4569\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1130s 106ms/step - loss: 0.8476 - categorical_accuracy: 0.7124 - val_loss: 1.6847 - val_categorical_accuracy: 0.4163\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1130s 106ms/step - loss: 0.6232 - categorical_accuracy: 0.7942 - val_loss: 0.8314 - val_categorical_accuracy: 0.7204\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1130s 106ms/step - loss: 0.4839 - categorical_accuracy: 0.8389 - val_loss: 0.8479 - val_categorical_accuracy: 0.7207\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.3772 - categorical_accuracy: 0.8785 - val_loss: 0.7765 - val_categorical_accuracy: 0.7456\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.2923 - categorical_accuracy: 0.9095 - val_loss: 0.7665 - val_categorical_accuracy: 0.7723\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.2229 - categorical_accuracy: 0.9294 - val_loss: 0.8132 - val_categorical_accuracy: 0.7636\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.1663 - categorical_accuracy: 0.9477 - val_loss: 0.9792 - val_categorical_accuracy: 0.7343\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.1243 - categorical_accuracy: 0.9622 - val_loss: 0.9285 - val_categorical_accuracy: 0.7610\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.1077 - categorical_accuracy: 0.9697 - val_loss: 1.0878 - val_categorical_accuracy: 0.7350\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.1135 - categorical_accuracy: 0.9668 - val_loss: 1.0608 - val_categorical_accuracy: 0.7452\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.0695 - categorical_accuracy: 0.9794 - val_loss: 1.1138 - val_categorical_accuracy: 0.7497\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.0494 - categorical_accuracy: 0.9850 - val_loss: 1.1048 - val_categorical_accuracy: 0.7471\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.0367 - categorical_accuracy: 0.9900 - val_loss: 1.1965 - val_categorical_accuracy: 0.7505\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.0327 - categorical_accuracy: 0.9906 - val_loss: 1.2221 - val_categorical_accuracy: 0.7516\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1127s 106ms/step - loss: 0.0285 - categorical_accuracy: 0.9912 - val_loss: 1.2592 - val_categorical_accuracy: 0.7433\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.0248 - categorical_accuracy: 0.9923 - val_loss: 1.2701 - val_categorical_accuracy: 0.7524\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1163s 109ms/step - loss: 0.0224 - categorical_accuracy: 0.9926 - val_loss: 1.3310 - val_categorical_accuracy: 0.7392\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.0190 - categorical_accuracy: 0.9925 - val_loss: 1.3839 - val_categorical_accuracy: 0.7475\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 1128s 106ms/step - loss: 0.0167 - categorical_accuracy: 0.9941 - val_loss: 1.3906 - val_categorical_accuracy: 0.7452\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,466,262\n",
      "Trainable params: 3,466,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 1.7659 - categorical_accuracy: 0.3979 - val_loss: 1.7258 - val_categorical_accuracy: 0.4005\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 1.3599 - categorical_accuracy: 0.5626 - val_loss: 1.4791 - val_categorical_accuracy: 0.5506\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 1.0008 - categorical_accuracy: 0.6680 - val_loss: 1.0198 - val_categorical_accuracy: 0.6677\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.8089 - categorical_accuracy: 0.7301 - val_loss: 0.9883 - val_categorical_accuracy: 0.6906\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.6878 - categorical_accuracy: 0.7744 - val_loss: 0.9659 - val_categorical_accuracy: 0.6993\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.5942 - categorical_accuracy: 0.8026 - val_loss: 0.8479 - val_categorical_accuracy: 0.7170\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.5170 - categorical_accuracy: 0.8301 - val_loss: 0.8344 - val_categorical_accuracy: 0.7219\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.4664 - categorical_accuracy: 0.8454 - val_loss: 0.7924 - val_categorical_accuracy: 0.7403\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.4167 - categorical_accuracy: 0.8637 - val_loss: 0.8366 - val_categorical_accuracy: 0.7456\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 654s 61ms/step - loss: 0.3695 - categorical_accuracy: 0.8804 - val_loss: 0.8485 - val_categorical_accuracy: 0.7429\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3380 - categorical_accuracy: 0.8907 - val_loss: 0.8067 - val_categorical_accuracy: 0.7606\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3045 - categorical_accuracy: 0.9029 - val_loss: 0.8940 - val_categorical_accuracy: 0.7580\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.2603 - categorical_accuracy: 0.9182 - val_loss: 0.8823 - val_categorical_accuracy: 0.7689\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.2339 - categorical_accuracy: 0.9260 - val_loss: 0.9055 - val_categorical_accuracy: 0.7636\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.2160 - categorical_accuracy: 0.9315 - val_loss: 0.9135 - val_categorical_accuracy: 0.7746\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.2083 - categorical_accuracy: 0.9362 - val_loss: 1.0246 - val_categorical_accuracy: 0.7651\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.1860 - categorical_accuracy: 0.9425 - val_loss: 1.0297 - val_categorical_accuracy: 0.7505\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 653s 61ms/step - loss: 0.1736 - categorical_accuracy: 0.9446 - val_loss: 1.0736 - val_categorical_accuracy: 0.7633\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.1603 - categorical_accuracy: 0.9499 - val_loss: 1.1561 - val_categorical_accuracy: 0.7546\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 654s 61ms/step - loss: 0.1463 - categorical_accuracy: 0.9530 - val_loss: 1.1730 - val_categorical_accuracy: 0.7599\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 1.6689 - categorical_accuracy: 0.4357 - val_loss: 1.4953 - val_categorical_accuracy: 0.4806\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 654s 61ms/step - loss: 1.0669 - categorical_accuracy: 0.6465 - val_loss: 1.0863 - val_categorical_accuracy: 0.6432\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 654s 61ms/step - loss: 0.7600 - categorical_accuracy: 0.7459 - val_loss: 0.9135 - val_categorical_accuracy: 0.6951\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 660s 62ms/step - loss: 0.6180 - categorical_accuracy: 0.7953 - val_loss: 0.8213 - val_categorical_accuracy: 0.7264\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 658s 62ms/step - loss: 0.5268 - categorical_accuracy: 0.8243 - val_loss: 0.8984 - val_categorical_accuracy: 0.6872\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 0.4623 - categorical_accuracy: 0.8452 - val_loss: 0.7082 - val_categorical_accuracy: 0.7640\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3997 - categorical_accuracy: 0.8642 - val_loss: 0.7342 - val_categorical_accuracy: 0.7700\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3548 - categorical_accuracy: 0.8842 - val_loss: 0.7874 - val_categorical_accuracy: 0.7407\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.4803 - categorical_accuracy: 0.8507 - val_loss: 0.9159 - val_categorical_accuracy: 0.6959\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.6256 - categorical_accuracy: 0.7917 - val_loss: 0.7668 - val_categorical_accuracy: 0.7610\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 655s 62ms/step - loss: 0.4486 - categorical_accuracy: 0.8521 - val_loss: 0.7471 - val_categorical_accuracy: 0.7629\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.4184 - categorical_accuracy: 0.8663 - val_loss: 0.7518 - val_categorical_accuracy: 0.7663\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3887 - categorical_accuracy: 0.8724 - val_loss: 0.7496 - val_categorical_accuracy: 0.7689\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3660 - categorical_accuracy: 0.8812 - val_loss: 0.7504 - val_categorical_accuracy: 0.7693\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3550 - categorical_accuracy: 0.8848 - val_loss: 0.7721 - val_categorical_accuracy: 0.7618\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3329 - categorical_accuracy: 0.8923 - val_loss: 0.7635 - val_categorical_accuracy: 0.7670\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.3244 - categorical_accuracy: 0.8964 - val_loss: 0.7355 - val_categorical_accuracy: 0.7749\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.2988 - categorical_accuracy: 0.9044 - val_loss: 0.7485 - val_categorical_accuracy: 0.7715\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.2908 - categorical_accuracy: 0.9078 - val_loss: 0.7552 - val_categorical_accuracy: 0.7731\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 654s 62ms/step - loss: 0.2823 - categorical_accuracy: 0.9116 - val_loss: 0.7542 - val_categorical_accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               471552    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,672,982\n",
      "Trainable params: 3,672,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 1275s 120ms/step - loss: 1.6524 - categorical_accuracy: 0.4453 - val_loss: 1.7721 - val_categorical_accuracy: 0.4008\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 1272s 120ms/step - loss: 1.0856 - categorical_accuracy: 0.6421 - val_loss: 1.1439 - val_categorical_accuracy: 0.6361\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 1268s 119ms/step - loss: 0.8081 - categorical_accuracy: 0.7316 - val_loss: 1.0756 - val_categorical_accuracy: 0.6560\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 1269s 119ms/step - loss: 0.6582 - categorical_accuracy: 0.7792 - val_loss: 0.8320 - val_categorical_accuracy: 0.7181\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1301s 122ms/step - loss: 0.5499 - categorical_accuracy: 0.8157 - val_loss: 0.7439 - val_categorical_accuracy: 0.7467\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1339s 126ms/step - loss: 0.4802 - categorical_accuracy: 0.8433 - val_loss: 0.7801 - val_categorical_accuracy: 0.7444\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1338s 126ms/step - loss: 0.4164 - categorical_accuracy: 0.8624 - val_loss: 0.8836 - val_categorical_accuracy: 0.7061\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1318s 124ms/step - loss: 0.3775 - categorical_accuracy: 0.8747 - val_loss: 0.7575 - val_categorical_accuracy: 0.7591\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1289s 121ms/step - loss: 0.3343 - categorical_accuracy: 0.8916 - val_loss: 0.7809 - val_categorical_accuracy: 0.7580\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1286s 121ms/step - loss: 0.2972 - categorical_accuracy: 0.9021 - val_loss: 0.7623 - val_categorical_accuracy: 0.7610\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1286s 121ms/step - loss: 0.2696 - categorical_accuracy: 0.9123 - val_loss: 0.8653 - val_categorical_accuracy: 0.7539\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1289s 121ms/step - loss: 0.2396 - categorical_accuracy: 0.9233 - val_loss: 0.8276 - val_categorical_accuracy: 0.7565\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1288s 121ms/step - loss: 0.2130 - categorical_accuracy: 0.9330 - val_loss: 0.7953 - val_categorical_accuracy: 0.7753\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1286s 121ms/step - loss: 0.1886 - categorical_accuracy: 0.9394 - val_loss: 0.8297 - val_categorical_accuracy: 0.7719\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1288s 121ms/step - loss: 0.1713 - categorical_accuracy: 0.9459 - val_loss: 0.9009 - val_categorical_accuracy: 0.7599\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1287s 121ms/step - loss: 0.1543 - categorical_accuracy: 0.9509 - val_loss: 0.9815 - val_categorical_accuracy: 0.7539\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 1286s 121ms/step - loss: 0.1360 - categorical_accuracy: 0.9560 - val_loss: 0.9449 - val_categorical_accuracy: 0.7640\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 1286s 121ms/step - loss: 0.1184 - categorical_accuracy: 0.9605 - val_loss: 1.0011 - val_categorical_accuracy: 0.7595\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 1289s 121ms/step - loss: 0.1164 - categorical_accuracy: 0.9616 - val_loss: 1.0685 - val_categorical_accuracy: 0.7561\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 1286s 121ms/step - loss: 0.1042 - categorical_accuracy: 0.9656 - val_loss: 0.9823 - val_categorical_accuracy: 0.7682\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(GRU(256, dropout=0.1, recurrent_dropout=0.4)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 512)               864768    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,066,198\n",
      "Trainable params: 4,066,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 1.6559 - categorical_accuracy: 0.4474 - val_loss: 1.4306 - val_categorical_accuracy: 0.5344\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 1.1013 - categorical_accuracy: 0.6434 - val_loss: 1.3003 - val_categorical_accuracy: 0.5924\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 687s 65ms/step - loss: 0.7510 - categorical_accuracy: 0.7519 - val_loss: 0.9189 - val_categorical_accuracy: 0.6733\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.5965 - categorical_accuracy: 0.8008 - val_loss: 0.7875 - val_categorical_accuracy: 0.7475\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.5057 - categorical_accuracy: 0.8344 - val_loss: 0.7944 - val_categorical_accuracy: 0.7388\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.4417 - categorical_accuracy: 0.8523 - val_loss: 0.7767 - val_categorical_accuracy: 0.7441\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 687s 65ms/step - loss: 0.3819 - categorical_accuracy: 0.8735 - val_loss: 0.7099 - val_categorical_accuracy: 0.7746\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 687s 65ms/step - loss: 0.3367 - categorical_accuracy: 0.8858 - val_loss: 0.8912 - val_categorical_accuracy: 0.7253\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.3009 - categorical_accuracy: 0.8988 - val_loss: 0.7971 - val_categorical_accuracy: 0.7516\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.2540 - categorical_accuracy: 0.9151 - val_loss: 0.7809 - val_categorical_accuracy: 0.7700\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.2270 - categorical_accuracy: 0.9237 - val_loss: 0.9110 - val_categorical_accuracy: 0.7535\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.2542 - categorical_accuracy: 0.9202 - val_loss: 0.9109 - val_categorical_accuracy: 0.7418\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.1709 - categorical_accuracy: 0.9412 - val_loss: 0.8668 - val_categorical_accuracy: 0.7746\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.1489 - categorical_accuracy: 0.9514 - val_loss: 0.9264 - val_categorical_accuracy: 0.7625\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.1359 - categorical_accuracy: 0.9553 - val_loss: 0.8366 - val_categorical_accuracy: 0.7806\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1234 - categorical_accuracy: 0.9590 - val_loss: 1.1611 - val_categorical_accuracy: 0.7286\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.1047 - categorical_accuracy: 0.9644 - val_loss: 1.0041 - val_categorical_accuracy: 0.7821\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.0935 - categorical_accuracy: 0.9708 - val_loss: 1.0194 - val_categorical_accuracy: 0.7651\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.0841 - categorical_accuracy: 0.9713 - val_loss: 1.0170 - val_categorical_accuracy: 0.7663\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 688s 65ms/step - loss: 0.2831 - categorical_accuracy: 0.9136 - val_loss: 2.4271 - val_categorical_accuracy: 0.4042\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(512, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 1024)              3302400   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 6,508,950\n",
      "Trainable params: 6,508,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 719s 68ms/step - loss: 1.9008 - categorical_accuracy: 0.3542 - val_loss: 2.0284 - val_categorical_accuracy: 0.2902\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 715s 67ms/step - loss: 1.9664 - categorical_accuracy: 0.3107 - val_loss: 2.8366 - val_categorical_accuracy: 0.2172\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 715s 67ms/step - loss: 1.2685 - categorical_accuracy: 0.5831 - val_loss: 1.2312 - val_categorical_accuracy: 0.5702\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 715s 67ms/step - loss: 0.9181 - categorical_accuracy: 0.6938 - val_loss: 1.5486 - val_categorical_accuracy: 0.5254\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.7610 - categorical_accuracy: 0.7450 - val_loss: 0.9454 - val_categorical_accuracy: 0.6910\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.6025 - categorical_accuracy: 0.7966 - val_loss: 0.8453 - val_categorical_accuracy: 0.7158\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.5004 - categorical_accuracy: 0.8288 - val_loss: 0.9207 - val_categorical_accuracy: 0.6726\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.4378 - categorical_accuracy: 0.8521 - val_loss: 0.7604 - val_categorical_accuracy: 0.7426\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 715s 67ms/step - loss: 0.3754 - categorical_accuracy: 0.8744 - val_loss: 0.8036 - val_categorical_accuracy: 0.7520\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.3281 - categorical_accuracy: 0.8870 - val_loss: 1.0263 - val_categorical_accuracy: 0.6914\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.2771 - categorical_accuracy: 0.9069 - val_loss: 0.7216 - val_categorical_accuracy: 0.7858\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 715s 67ms/step - loss: 0.2315 - categorical_accuracy: 0.9221 - val_loss: 0.8431 - val_categorical_accuracy: 0.7719\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.2087 - categorical_accuracy: 0.9303 - val_loss: 0.9085 - val_categorical_accuracy: 0.7539\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 719s 68ms/step - loss: 0.1795 - categorical_accuracy: 0.9403 - val_loss: 0.8429 - val_categorical_accuracy: 0.7776\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 772s 73ms/step - loss: 0.1537 - categorical_accuracy: 0.9489 - val_loss: 0.9004 - val_categorical_accuracy: 0.7731\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.1393 - categorical_accuracy: 0.9528 - val_loss: 0.9553 - val_categorical_accuracy: 0.7761\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 715s 67ms/step - loss: 0.1202 - categorical_accuracy: 0.9592 - val_loss: 1.1092 - val_categorical_accuracy: 0.7493\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.1125 - categorical_accuracy: 0.9627 - val_loss: 1.0289 - val_categorical_accuracy: 0.7633\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.0983 - categorical_accuracy: 0.9666 - val_loss: 0.9993 - val_categorical_accuracy: 0.7708\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 716s 67ms/step - loss: 0.0907 - categorical_accuracy: 0.9716 - val_loss: 1.1406 - val_categorical_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(1024, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
