{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_EXCERTO</th>\n",
       "      <th>TEXTO_EXCERTO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995438</td>\n",
       "      <td>Voto:Cuidam os autos de tomada de contas espec...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025603</td>\n",
       "      <td>Voto:Cuidam os autos de Solicitação do Congres...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455375</td>\n",
       "      <td>Relatório:Trata-se de embargos de declaração o...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773747</td>\n",
       "      <td>Voto:8. Em relação a outros processos judiciai...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773403</td>\n",
       "      <td>Voto:11. Relativamente ao ato envolvendo a Sra...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_EXCERTO  \\\n",
       "0  Benefício previdenciário                    54995438   \n",
       "1                  Petróleo                    55025603   \n",
       "2                Dosimetria                    55455375   \n",
       "3          Decisão judicial                    54773747   \n",
       "4                 Nepotismo                    54773403   \n",
       "\n",
       "                                       TEXTO_EXCERTO                ACORDAO  \\\n",
       "0  Voto:Cuidam os autos de tomada de contas espec...  Acórdão 297/2016 - PL   \n",
       "1  Voto:Cuidam os autos de Solicitação do Congres...  Acórdão 366/2016 - PL   \n",
       "2  Relatório:Trata-se de embargos de declaração o...  Acórdão 944/2016 - PL   \n",
       "3  Voto:8. Em relação a outros processos judiciai...   Acórdão 30/2016 - PL   \n",
       "4  Voto:11. Relativamente ao ato envolvendo a Sra...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_excertos.CSV', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCR_AREA\n",
       "Competência do TCU          553\n",
       "Contrato Administrativo     941\n",
       "Convênio                    683\n",
       "Desestatização              139\n",
       "Direito Processual         1811\n",
       "Finanças Públicas           328\n",
       "Gestão Administrativa       338\n",
       "Licitação                  2756\n",
       "Pessoal                    3393\n",
       "Responsabilidade           2343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DESCR_AREA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63925 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "limite_texto = 2000\n",
    "dim_vetor = 50\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TEXTO_EXCERTO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_EXCERTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 2000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model-50.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 63925\n",
      "Encontrados no modelo: 42309 = 66.18537348455222\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, 50))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1109 21:38:39.397022 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1109 21:38:39.508047 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1109 21:38:39.510013 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1109 21:38:39.517586 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1109 21:38:39.518235 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1109 21:38:40.462336 139841005438784 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1109 21:38:40.563945 139841005438784 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 238,346\n",
      "Non-trainable params: 3,196,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 555s 52ms/step - loss: 1.5679 - categorical_accuracy: 0.4743 - val_loss: 1.6392 - val_categorical_accuracy: 0.4592\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 532s 50ms/step - loss: 1.1560 - categorical_accuracy: 0.6139 - val_loss: 2.0258 - val_categorical_accuracy: 0.4392\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 526s 49ms/step - loss: 0.7645 - categorical_accuracy: 0.7430 - val_loss: 1.0589 - val_categorical_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 523s 49ms/step - loss: 0.6199 - categorical_accuracy: 0.7938 - val_loss: 0.8806 - val_categorical_accuracy: 0.7079\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 578s 54ms/step - loss: 0.5188 - categorical_accuracy: 0.8236 - val_loss: 0.9462 - val_categorical_accuracy: 0.7249\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 586s 55ms/step - loss: 0.4502 - categorical_accuracy: 0.8464 - val_loss: 0.8887 - val_categorical_accuracy: 0.7128\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 586s 55ms/step - loss: 0.3861 - categorical_accuracy: 0.8689 - val_loss: 0.9176 - val_categorical_accuracy: 0.7204\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 585s 55ms/step - loss: 0.3276 - categorical_accuracy: 0.8906 - val_loss: 1.1022 - val_categorical_accuracy: 0.6609\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 583s 55ms/step - loss: 0.2692 - categorical_accuracy: 0.9074 - val_loss: 1.0131 - val_categorical_accuracy: 0.7068\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 581s 55ms/step - loss: 0.2221 - categorical_accuracy: 0.9241 - val_loss: 1.0398 - val_categorical_accuracy: 0.7019\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 574s 54ms/step - loss: 0.1786 - categorical_accuracy: 0.9385 - val_loss: 1.0360 - val_categorical_accuracy: 0.7241\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 577s 54ms/step - loss: 0.1386 - categorical_accuracy: 0.9533 - val_loss: 1.1149 - val_categorical_accuracy: 0.7433\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 581s 55ms/step - loss: 0.1135 - categorical_accuracy: 0.9637 - val_loss: 1.1690 - val_categorical_accuracy: 0.7343\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 585s 55ms/step - loss: 0.0990 - categorical_accuracy: 0.9690 - val_loss: 1.2165 - val_categorical_accuracy: 0.7320\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 589s 55ms/step - loss: 0.0799 - categorical_accuracy: 0.9750 - val_loss: 1.5253 - val_categorical_accuracy: 0.6963\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 589s 55ms/step - loss: 0.0719 - categorical_accuracy: 0.9785 - val_loss: 1.2436 - val_categorical_accuracy: 0.7429\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 586s 55ms/step - loss: 0.0709 - categorical_accuracy: 0.9786 - val_loss: 1.3292 - val_categorical_accuracy: 0.7365\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 585s 55ms/step - loss: 0.0622 - categorical_accuracy: 0.9815 - val_loss: 1.4303 - val_categorical_accuracy: 0.7230\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 583s 55ms/step - loss: 0.0602 - categorical_accuracy: 0.9827 - val_loss: 1.4262 - val_categorical_accuracy: 0.7268\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 581s 55ms/step - loss: 0.0525 - categorical_accuracy: 0.9833 - val_loss: 1.5345 - val_categorical_accuracy: 0.7268\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,434,646\n",
      "Trainable params: 3,434,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 597s 56ms/step - loss: 1.5100 - categorical_accuracy: 0.4985 - val_loss: 1.4381 - val_categorical_accuracy: 0.5499\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 597s 56ms/step - loss: 0.8623 - categorical_accuracy: 0.7068 - val_loss: 0.9596 - val_categorical_accuracy: 0.6767\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 598s 56ms/step - loss: 0.6139 - categorical_accuracy: 0.7969 - val_loss: 0.8215 - val_categorical_accuracy: 0.7230\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 598s 56ms/step - loss: 0.4784 - categorical_accuracy: 0.8382 - val_loss: 0.7845 - val_categorical_accuracy: 0.7377\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 604s 57ms/step - loss: 0.3815 - categorical_accuracy: 0.8734 - val_loss: 0.7435 - val_categorical_accuracy: 0.7565\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 605s 57ms/step - loss: 0.2923 - categorical_accuracy: 0.9043 - val_loss: 0.8459 - val_categorical_accuracy: 0.7640\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 603s 57ms/step - loss: 0.2244 - categorical_accuracy: 0.9283 - val_loss: 0.9104 - val_categorical_accuracy: 0.7305\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 605s 57ms/step - loss: 0.1642 - categorical_accuracy: 0.9453 - val_loss: 0.9362 - val_categorical_accuracy: 0.7437\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 605s 57ms/step - loss: 0.1169 - categorical_accuracy: 0.9621 - val_loss: 0.9328 - val_categorical_accuracy: 0.7655\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 537s 51ms/step - loss: 0.0816 - categorical_accuracy: 0.9753 - val_loss: 1.1149 - val_categorical_accuracy: 0.7478\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0665 - categorical_accuracy: 0.9806 - val_loss: 1.0358 - val_categorical_accuracy: 0.7610\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0519 - categorical_accuracy: 0.9859 - val_loss: 1.3980 - val_categorical_accuracy: 0.7230\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0455 - categorical_accuracy: 0.9887 - val_loss: 1.3172 - val_categorical_accuracy: 0.7237\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0412 - categorical_accuracy: 0.9894 - val_loss: 1.1927 - val_categorical_accuracy: 0.7667\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0366 - categorical_accuracy: 0.9907 - val_loss: 1.3834 - val_categorical_accuracy: 0.7275\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0363 - categorical_accuracy: 0.9902 - val_loss: 1.2888 - val_categorical_accuracy: 0.7588\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0336 - categorical_accuracy: 0.9916 - val_loss: 1.2948 - val_categorical_accuracy: 0.7621\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0316 - categorical_accuracy: 0.9926 - val_loss: 1.3749 - val_categorical_accuracy: 0.7493\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 531s 50ms/step - loss: 0.0306 - categorical_accuracy: 0.9925 - val_loss: 1.2757 - val_categorical_accuracy: 0.7493\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 530s 50ms/step - loss: 0.0309 - categorical_accuracy: 0.9926 - val_loss: 1.3975 - val_categorical_accuracy: 0.7524\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               78592     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,277,462\n",
      "Trainable params: 3,277,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.8022 - categorical_accuracy: 0.3792 - val_loss: 1.8472 - val_categorical_accuracy: 0.3632\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.5877 - categorical_accuracy: 0.4645 - val_loss: 1.7761 - val_categorical_accuracy: 0.3959\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.5543 - categorical_accuracy: 0.4720 - val_loss: 1.8132 - val_categorical_accuracy: 0.4121\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.4108 - categorical_accuracy: 0.5315 - val_loss: 1.8337 - val_categorical_accuracy: 0.3741\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.6617 - categorical_accuracy: 0.4362 - val_loss: 1.8005 - val_categorical_accuracy: 0.3564\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 207s 19ms/step - loss: 1.6285 - categorical_accuracy: 0.4534 - val_loss: 1.9228 - val_categorical_accuracy: 0.3613\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.5788 - categorical_accuracy: 0.4783 - val_loss: 1.9765 - val_categorical_accuracy: 0.3203\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4573 - categorical_accuracy: 0.5150 - val_loss: 1.8132 - val_categorical_accuracy: 0.3805\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4763 - categorical_accuracy: 0.5135 - val_loss: 1.8096 - val_categorical_accuracy: 0.3658\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4249 - categorical_accuracy: 0.5237 - val_loss: 1.7169 - val_categorical_accuracy: 0.4117\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4478 - categorical_accuracy: 0.5151 - val_loss: 1.7129 - val_categorical_accuracy: 0.4204\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4187 - categorical_accuracy: 0.5275 - val_loss: 1.8052 - val_categorical_accuracy: 0.3722\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.5296 - categorical_accuracy: 0.4949 - val_loss: 1.7845 - val_categorical_accuracy: 0.3922\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.5257 - categorical_accuracy: 0.4883 - val_loss: 1.7780 - val_categorical_accuracy: 0.3907\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4926 - categorical_accuracy: 0.5079 - val_loss: 1.7293 - val_categorical_accuracy: 0.4193\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4080 - categorical_accuracy: 0.5330 - val_loss: 1.8659 - val_categorical_accuracy: 0.3967\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4108 - categorical_accuracy: 0.5320 - val_loss: 1.8455 - val_categorical_accuracy: 0.4012\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.5337 - categorical_accuracy: 0.4825 - val_loss: 1.8201 - val_categorical_accuracy: 0.3873\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 207s 20ms/step - loss: 1.4767 - categorical_accuracy: 0.5027 - val_loss: 1.9619 - val_categorical_accuracy: 0.3752\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 208s 20ms/step - loss: 1.4093 - categorical_accuracy: 0.5280 - val_loss: 1.9824 - val_categorical_accuracy: 0.3365\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(SimpleRNN(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               314368    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,513,238\n",
      "Trainable params: 3,513,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 1.6297 - categorical_accuracy: 0.4571 - val_loss: 1.6669 - val_categorical_accuracy: 0.3948\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 1.4385 - categorical_accuracy: 0.5368 - val_loss: 1.6570 - val_categorical_accuracy: 0.4373\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 1.1224 - categorical_accuracy: 0.6362 - val_loss: 1.4561 - val_categorical_accuracy: 0.5119\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 0.9601 - categorical_accuracy: 0.6831 - val_loss: 1.1652 - val_categorical_accuracy: 0.6349\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.8488 - categorical_accuracy: 0.7224 - val_loss: 1.2021 - val_categorical_accuracy: 0.6176\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.7417 - categorical_accuracy: 0.7585 - val_loss: 1.0781 - val_categorical_accuracy: 0.6613\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.6610 - categorical_accuracy: 0.7877 - val_loss: 0.9819 - val_categorical_accuracy: 0.6940\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.5761 - categorical_accuracy: 0.8174 - val_loss: 1.0031 - val_categorical_accuracy: 0.6959\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 0.4847 - categorical_accuracy: 0.8499 - val_loss: 0.9278 - val_categorical_accuracy: 0.7151\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.4261 - categorical_accuracy: 0.8655 - val_loss: 0.9526 - val_categorical_accuracy: 0.6940\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.3656 - categorical_accuracy: 0.8820 - val_loss: 0.8433 - val_categorical_accuracy: 0.7418\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 690s 65ms/step - loss: 0.3106 - categorical_accuracy: 0.9046 - val_loss: 0.9070 - val_categorical_accuracy: 0.7354\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.2516 - categorical_accuracy: 0.9238 - val_loss: 0.9668 - val_categorical_accuracy: 0.7414\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.2093 - categorical_accuracy: 0.9373 - val_loss: 1.0798 - val_categorical_accuracy: 0.7151\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1667 - categorical_accuracy: 0.9513 - val_loss: 1.0509 - val_categorical_accuracy: 0.7317\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1311 - categorical_accuracy: 0.9610 - val_loss: 1.1532 - val_categorical_accuracy: 0.7369\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.1030 - categorical_accuracy: 0.9674 - val_loss: 1.1818 - val_categorical_accuracy: 0.7373\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.0824 - categorical_accuracy: 0.9746 - val_loss: 1.3457 - val_categorical_accuracy: 0.7091\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.0658 - categorical_accuracy: 0.9812 - val_loss: 1.2166 - val_categorical_accuracy: 0.7411\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 689s 65ms/step - loss: 0.0530 - categorical_accuracy: 0.9847 - val_loss: 1.4176 - val_categorical_accuracy: 0.7482\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               157184    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,358,614\n",
      "Trainable params: 3,358,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.8694 - categorical_accuracy: 0.3506 - val_loss: 2.0536 - val_categorical_accuracy: 0.1607\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.7790 - categorical_accuracy: 0.3896 - val_loss: 1.9545 - val_categorical_accuracy: 0.3150\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5758 - categorical_accuracy: 0.4721 - val_loss: 1.8297 - val_categorical_accuracy: 0.3816\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4784 - categorical_accuracy: 0.5028 - val_loss: 1.7845 - val_categorical_accuracy: 0.4065\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4736 - categorical_accuracy: 0.4992 - val_loss: 1.8624 - val_categorical_accuracy: 0.3824\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5342 - categorical_accuracy: 0.4769 - val_loss: 1.8850 - val_categorical_accuracy: 0.3225\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.6580 - categorical_accuracy: 0.4352 - val_loss: 1.9869 - val_categorical_accuracy: 0.3214\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.6053 - categorical_accuracy: 0.4566 - val_loss: 2.0468 - val_categorical_accuracy: 0.3335\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5335 - categorical_accuracy: 0.4836 - val_loss: 1.8619 - val_categorical_accuracy: 0.4524\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4696 - categorical_accuracy: 0.5116 - val_loss: 1.6681 - val_categorical_accuracy: 0.4539\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 317s 30ms/step - loss: 1.5552 - categorical_accuracy: 0.4728 - val_loss: 1.8863 - val_categorical_accuracy: 0.3824\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4978 - categorical_accuracy: 0.4945 - val_loss: 1.8832 - val_categorical_accuracy: 0.3734\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4853 - categorical_accuracy: 0.5007 - val_loss: 2.2548 - val_categorical_accuracy: 0.2766\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4441 - categorical_accuracy: 0.5155 - val_loss: 2.3684 - val_categorical_accuracy: 0.2680\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.3376 - categorical_accuracy: 0.5570 - val_loss: 1.9888 - val_categorical_accuracy: 0.3143\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.3971 - categorical_accuracy: 0.5296 - val_loss: 1.8770 - val_categorical_accuracy: 0.3718\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5183 - categorical_accuracy: 0.4820 - val_loss: 1.9783 - val_categorical_accuracy: 0.2951\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.5257 - categorical_accuracy: 0.4782 - val_loss: 2.2992 - val_categorical_accuracy: 0.1810\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4012 - categorical_accuracy: 0.5394 - val_loss: 2.0670 - val_categorical_accuracy: 0.3387\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 318s 30ms/step - loss: 1.4014 - categorical_accuracy: 0.5290 - val_loss: 2.0221 - val_categorical_accuracy: 0.3971\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(SimpleRNN(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               471552    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,672,982\n",
      "Trainable params: 3,672,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 960s 90ms/step - loss: 1.5467 - categorical_accuracy: 0.4857 - val_loss: 1.3788 - val_categorical_accuracy: 0.5250\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 960s 90ms/step - loss: 0.8882 - categorical_accuracy: 0.7022 - val_loss: 1.1880 - val_categorical_accuracy: 0.5713\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 960s 90ms/step - loss: 0.6350 - categorical_accuracy: 0.7921 - val_loss: 0.9020 - val_categorical_accuracy: 0.6936\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 962s 91ms/step - loss: 0.4898 - categorical_accuracy: 0.8359 - val_loss: 0.7742 - val_categorical_accuracy: 0.7448\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 1120s 105ms/step - loss: 0.3825 - categorical_accuracy: 0.8712 - val_loss: 0.9894 - val_categorical_accuracy: 0.7087\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 1109s 104ms/step - loss: 0.2990 - categorical_accuracy: 0.9024 - val_loss: 0.8409 - val_categorical_accuracy: 0.7557\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 1108s 104ms/step - loss: 0.2360 - categorical_accuracy: 0.9220 - val_loss: 0.8116 - val_categorical_accuracy: 0.7670\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 1113s 105ms/step - loss: 0.1768 - categorical_accuracy: 0.9434 - val_loss: 0.9662 - val_categorical_accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 1112s 105ms/step - loss: 0.1279 - categorical_accuracy: 0.9597 - val_loss: 0.9090 - val_categorical_accuracy: 0.7629\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 1109s 104ms/step - loss: 0.0897 - categorical_accuracy: 0.9741 - val_loss: 1.0145 - val_categorical_accuracy: 0.7689\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 1125s 106ms/step - loss: 0.0676 - categorical_accuracy: 0.9796 - val_loss: 1.6035 - val_categorical_accuracy: 0.6586\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 1115s 105ms/step - loss: 0.0556 - categorical_accuracy: 0.9843 - val_loss: 1.1299 - val_categorical_accuracy: 0.7561\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 1106s 104ms/step - loss: 0.0466 - categorical_accuracy: 0.9880 - val_loss: 1.1907 - val_categorical_accuracy: 0.7618\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 1105s 104ms/step - loss: 0.0407 - categorical_accuracy: 0.9892 - val_loss: 1.3658 - val_categorical_accuracy: 0.7335\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 1116s 105ms/step - loss: 0.0395 - categorical_accuracy: 0.9897 - val_loss: 1.5310 - val_categorical_accuracy: 0.7046\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 1016s 96ms/step - loss: 0.0392 - categorical_accuracy: 0.9909 - val_loss: 1.3348 - val_categorical_accuracy: 0.7520\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 968s 91ms/step - loss: 0.0331 - categorical_accuracy: 0.9917 - val_loss: 1.2675 - val_categorical_accuracy: 0.7569\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 963s 91ms/step - loss: 0.0282 - categorical_accuracy: 0.9931 - val_loss: 1.4432 - val_categorical_accuracy: 0.7309\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 961s 90ms/step - loss: 0.0308 - categorical_accuracy: 0.9921 - val_loss: 1.4256 - val_categorical_accuracy: 0.7396\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 962s 90ms/step - loss: 0.0269 - categorical_accuracy: 0.9928 - val_loss: 1.3407 - val_categorical_accuracy: 0.7580\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(GRU(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1111 10:31:41.187237 140316744189760 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1111 10:31:41.314905 140316744189760 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               628736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,830,166\n",
      "Trainable params: 3,830,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "  864/10628 [=>............................] - ETA: 19:08 - loss: 1.9855 - categorical_accuracy: 0.3021"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(512))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=64, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Bidirectional(GRU(256, dropout=0.1, recurrent_dropout=0.4)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
