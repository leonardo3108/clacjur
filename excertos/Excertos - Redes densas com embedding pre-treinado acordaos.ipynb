{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_EXCERTO</th>\n",
       "      <th>TEXTO_EXCERTO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995438</td>\n",
       "      <td>Voto:Cuidam os autos de tomada de contas espec...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025603</td>\n",
       "      <td>Voto:Cuidam os autos de Solicitação do Congres...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455375</td>\n",
       "      <td>Relatório:Trata-se de embargos de declaração o...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773747</td>\n",
       "      <td>Voto:8. Em relação a outros processos judiciai...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773403</td>\n",
       "      <td>Voto:11. Relativamente ao ato envolvendo a Sra...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_EXCERTO  \\\n",
       "0  Benefício previdenciário                    54995438   \n",
       "1                  Petróleo                    55025603   \n",
       "2                Dosimetria                    55455375   \n",
       "3          Decisão judicial                    54773747   \n",
       "4                 Nepotismo                    54773403   \n",
       "\n",
       "                                       TEXTO_EXCERTO                ACORDAO  \\\n",
       "0  Voto:Cuidam os autos de tomada de contas espec...  Acórdão 297/2016 - PL   \n",
       "1  Voto:Cuidam os autos de Solicitação do Congres...  Acórdão 366/2016 - PL   \n",
       "2  Relatório:Trata-se de embargos de declaração o...  Acórdão 944/2016 - PL   \n",
       "3  Voto:8. Em relação a outros processos judiciai...   Acórdão 30/2016 - PL   \n",
       "4  Voto:11. Relativamente ao ato envolvendo a Sra...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_excertos.CSV', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCR_AREA\n",
       "Competência do TCU          553\n",
       "Contrato Administrativo     941\n",
       "Convênio                    683\n",
       "Desestatização              139\n",
       "Direito Processual         1811\n",
       "Finanças Públicas           328\n",
       "Gestão Administrativa       338\n",
       "Licitação                  2756\n",
       "Pessoal                    3393\n",
       "Responsabilidade           2343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DESCR_AREA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63925 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "limite_texto = 2000\n",
    "dim_vetor = 50\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TEXTO_EXCERTO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_EXCERTO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 2000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos-50.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 63925\n",
      "Encontrados no modelo: 43317 = 67.76222135314822\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model.wv:\n",
    "        embedding_matrix[i] = model.wv[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding com pesos fixos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1117 00:17:51.941356 140000866477888 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding = Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1117 00:17:52.125793 140000866477888 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1117 00:17:52.127617 140000866477888 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1117 00:17:52.134553 140000866477888 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1117 00:17:52.135160 140000866477888 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1117 00:17:52.862109 140000866477888 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1117 00:17:52.862626 140000866477888 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1117 00:17:52.890430 140000866477888 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1117 00:17:52.913043 140000866477888 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              102401024 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 106,127,254\n",
      "Trainable params: 102,930,954\n",
      "Non-trainable params: 3,196,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1117 00:17:53.013916 140000866477888 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 10.6104 - categorical_accuracy: 0.3196 - val_loss: 12.3811 - val_categorical_accuracy: 0.2258\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 8.7665 - categorical_accuracy: 0.4399 - val_loss: 11.4844 - val_categorical_accuracy: 0.2826\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 7.9682 - categorical_accuracy: 0.4812 - val_loss: 11.0354 - val_categorical_accuracy: 0.2921\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 7.2036 - categorical_accuracy: 0.5191 - val_loss: 7.5173 - val_categorical_accuracy: 0.4904\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 6.4057 - categorical_accuracy: 0.5533 - val_loss: 6.7656 - val_categorical_accuracy: 0.5107\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 4.5257 - categorical_accuracy: 0.5704 - val_loss: 4.8297 - val_categorical_accuracy: 0.5137\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 2.5929 - categorical_accuracy: 0.5685 - val_loss: 3.6703 - val_categorical_accuracy: 0.5356\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.9929 - categorical_accuracy: 0.5836 - val_loss: 2.3523 - val_categorical_accuracy: 0.4671\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.6050 - categorical_accuracy: 0.6004 - val_loss: 1.9568 - val_categorical_accuracy: 0.4339\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.4310 - categorical_accuracy: 0.6209 - val_loss: 1.6232 - val_categorical_accuracy: 0.5318\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.3220 - categorical_accuracy: 0.6307 - val_loss: 1.9797 - val_categorical_accuracy: 0.4467\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.2497 - categorical_accuracy: 0.6474 - val_loss: 1.6961 - val_categorical_accuracy: 0.4829\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.1969 - categorical_accuracy: 0.6618 - val_loss: 1.5341 - val_categorical_accuracy: 0.5077\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.1705 - categorical_accuracy: 0.6620 - val_loss: 1.5180 - val_categorical_accuracy: 0.4833\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.1075 - categorical_accuracy: 0.6837 - val_loss: 1.5629 - val_categorical_accuracy: 0.4825\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.0470 - categorical_accuracy: 0.6941 - val_loss: 1.5703 - val_categorical_accuracy: 0.4791\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 1.0289 - categorical_accuracy: 0.7019 - val_loss: 1.6502 - val_categorical_accuracy: 0.4889\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.9558 - categorical_accuracy: 0.7138 - val_loss: 1.4517 - val_categorical_accuracy: 0.4949\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.9631 - categorical_accuracy: 0.7194 - val_loss: 1.4751 - val_categorical_accuracy: 0.5194\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.9414 - categorical_accuracy: 0.7299 - val_loss: 1.4966 - val_categorical_accuracy: 0.5036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 5.2506 - categorical_accuracy: 0.4085 - val_loss: 1.6466 - val_categorical_accuracy: 0.4046\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 1.5094 - categorical_accuracy: 0.5586 - val_loss: 1.4162 - val_categorical_accuracy: 0.5055\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 1.2129 - categorical_accuracy: 0.6371 - val_loss: 1.5414 - val_categorical_accuracy: 0.5247\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 1.0359 - categorical_accuracy: 0.6899 - val_loss: 1.5297 - val_categorical_accuracy: 0.5092\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.8719 - categorical_accuracy: 0.7328 - val_loss: 1.3021 - val_categorical_accuracy: 0.5661\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.7316 - categorical_accuracy: 0.7815 - val_loss: 1.3950 - val_categorical_accuracy: 0.5600\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.6494 - categorical_accuracy: 0.8140 - val_loss: 1.4358 - val_categorical_accuracy: 0.5995\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.5371 - categorical_accuracy: 0.8444 - val_loss: 1.4385 - val_categorical_accuracy: 0.5916\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.4966 - categorical_accuracy: 0.8617 - val_loss: 1.5672 - val_categorical_accuracy: 0.5627\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.4488 - categorical_accuracy: 0.8817 - val_loss: 1.4958 - val_categorical_accuracy: 0.5717\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.4036 - categorical_accuracy: 0.8913 - val_loss: 1.5289 - val_categorical_accuracy: 0.6014\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.3589 - categorical_accuracy: 0.9073 - val_loss: 1.4504 - val_categorical_accuracy: 0.5947\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.3357 - categorical_accuracy: 0.9145 - val_loss: 1.7396 - val_categorical_accuracy: 0.5860\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.3178 - categorical_accuracy: 0.9203 - val_loss: 1.7668 - val_categorical_accuracy: 0.5980\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.3006 - categorical_accuracy: 0.9289 - val_loss: 1.8231 - val_categorical_accuracy: 0.5574\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2816 - categorical_accuracy: 0.9348 - val_loss: 1.9300 - val_categorical_accuracy: 0.5743\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2832 - categorical_accuracy: 0.9373 - val_loss: 1.8606 - val_categorical_accuracy: 0.5879\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2693 - categorical_accuracy: 0.9374 - val_loss: 1.8135 - val_categorical_accuracy: 0.6014\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2616 - categorical_accuracy: 0.9414 - val_loss: 1.7573 - val_categorical_accuracy: 0.5717\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2515 - categorical_accuracy: 0.9430 - val_loss: 1.8737 - val_categorical_accuracy: 0.5642\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 3.9157 - categorical_accuracy: 0.4060 - val_loss: 1.6383 - val_categorical_accuracy: 0.4881\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 1.5258 - categorical_accuracy: 0.5427 - val_loss: 1.8379 - val_categorical_accuracy: 0.4366\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 1.3096 - categorical_accuracy: 0.6056 - val_loss: 1.5748 - val_categorical_accuracy: 0.5344\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 1.1571 - categorical_accuracy: 0.6393 - val_loss: 1.7844 - val_categorical_accuracy: 0.4595\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 1.0337 - categorical_accuracy: 0.6664 - val_loss: 1.5174 - val_categorical_accuracy: 0.5009\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.9619 - categorical_accuracy: 0.6948 - val_loss: 1.4747 - val_categorical_accuracy: 0.5356\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.9198 - categorical_accuracy: 0.7158 - val_loss: 1.4410 - val_categorical_accuracy: 0.5265\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.8390 - categorical_accuracy: 0.7255 - val_loss: 1.5399 - val_categorical_accuracy: 0.5551\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.7826 - categorical_accuracy: 0.7526 - val_loss: 1.5332 - val_categorical_accuracy: 0.5604\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.7330 - categorical_accuracy: 0.7653 - val_loss: 1.5688 - val_categorical_accuracy: 0.5589\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.7061 - categorical_accuracy: 0.7805 - val_loss: 1.5188 - val_categorical_accuracy: 0.5585\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.6884 - categorical_accuracy: 0.7902 - val_loss: 1.5619 - val_categorical_accuracy: 0.5341\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.6398 - categorical_accuracy: 0.8015 - val_loss: 1.6822 - val_categorical_accuracy: 0.5664\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.6226 - categorical_accuracy: 0.8078 - val_loss: 1.7313 - val_categorical_accuracy: 0.5386\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.6024 - categorical_accuracy: 0.8127 - val_loss: 1.5722 - val_categorical_accuracy: 0.5209\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.5738 - categorical_accuracy: 0.8204 - val_loss: 1.6577 - val_categorical_accuracy: 0.5348\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.5724 - categorical_accuracy: 0.8233 - val_loss: 1.6693 - val_categorical_accuracy: 0.5886\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.5500 - categorical_accuracy: 0.8264 - val_loss: 1.7460 - val_categorical_accuracy: 0.5348\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.5085 - categorical_accuracy: 0.8375 - val_loss: 1.7159 - val_categorical_accuracy: 0.5487\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.5314 - categorical_accuracy: 0.8350 - val_loss: 1.8730 - val_categorical_accuracy: 0.5318\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding com pesos ajustáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1117 10:14:36.655619 140013061760832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1117 10:14:36.723059 140013061760832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1117 10:14:36.724688 140013061760832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1117 10:14:36.731681 140013061760832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1117 10:14:36.733530 140013061760832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1117 10:14:37.445541 140013061760832 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1117 10:14:37.446123 140013061760832 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1117 10:14:37.473656 140013061760832 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1117 10:14:37.495372 140013061760832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1117 10:14:37.582883 140013061760832 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 50)          3196300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              102401024 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 106,127,254\n",
      "Trainable params: 106,127,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 45s 4ms/step - loss: 10.1661 - categorical_accuracy: 0.3421 - val_loss: 12.6117 - val_categorical_accuracy: 0.2081\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 8.6718 - categorical_accuracy: 0.4451 - val_loss: 11.3233 - val_categorical_accuracy: 0.2736\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 8.0111 - categorical_accuracy: 0.4773 - val_loss: 10.9278 - val_categorical_accuracy: 0.3146\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 7.4091 - categorical_accuracy: 0.5185 - val_loss: 8.4051 - val_categorical_accuracy: 0.4528\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 6.9113 - categorical_accuracy: 0.5453 - val_loss: 8.8516 - val_categorical_accuracy: 0.4279\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 6.3555 - categorical_accuracy: 0.5773 - val_loss: 7.3535 - val_categorical_accuracy: 0.5186\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 5.9794 - categorical_accuracy: 0.5954 - val_loss: 7.7929 - val_categorical_accuracy: 0.4727\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 5.5492 - categorical_accuracy: 0.6066 - val_loss: 7.9776 - val_categorical_accuracy: 0.4697\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 4.4308 - categorical_accuracy: 0.6026 - val_loss: 6.5086 - val_categorical_accuracy: 0.4584\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 3.1713 - categorical_accuracy: 0.5678 - val_loss: 4.6756 - val_categorical_accuracy: 0.5469\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 2.7697 - categorical_accuracy: 0.5836 - val_loss: 4.3494 - val_categorical_accuracy: 0.4896\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 2.5233 - categorical_accuracy: 0.5868 - val_loss: 4.2761 - val_categorical_accuracy: 0.4716\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 2.3270 - categorical_accuracy: 0.5992 - val_loss: 4.5743 - val_categorical_accuracy: 0.4411\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 2.1489 - categorical_accuracy: 0.6016 - val_loss: 4.5404 - val_categorical_accuracy: 0.4234\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 2.0433 - categorical_accuracy: 0.6129 - val_loss: 4.1766 - val_categorical_accuracy: 0.4358\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 2.0064 - categorical_accuracy: 0.6190 - val_loss: 4.0047 - val_categorical_accuracy: 0.4957\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.8856 - categorical_accuracy: 0.6298 - val_loss: 4.0174 - val_categorical_accuracy: 0.5679\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.9888 - categorical_accuracy: 0.6273 - val_loss: 4.1281 - val_categorical_accuracy: 0.4392\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.8571 - categorical_accuracy: 0.6361 - val_loss: 3.9782 - val_categorical_accuracy: 0.4844\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.8330 - categorical_accuracy: 0.6359 - val_loss: 3.9498 - val_categorical_accuracy: 0.4641\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 6.9221 - categorical_accuracy: 0.3678 - val_loss: 3.2957 - val_categorical_accuracy: 0.3271\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.7262 - categorical_accuracy: 0.5305 - val_loss: 1.6838 - val_categorical_accuracy: 0.4174\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.3036 - categorical_accuracy: 0.6047 - val_loss: 1.7041 - val_categorical_accuracy: 0.4163\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 1.1045 - categorical_accuracy: 0.6588 - val_loss: 1.5067 - val_categorical_accuracy: 0.5081\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.9246 - categorical_accuracy: 0.7083 - val_loss: 1.4935 - val_categorical_accuracy: 0.5363\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.8328 - categorical_accuracy: 0.7446 - val_loss: 1.5014 - val_categorical_accuracy: 0.5265\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.7320 - categorical_accuracy: 0.7866 - val_loss: 1.5373 - val_categorical_accuracy: 0.5231\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.6153 - categorical_accuracy: 0.8180 - val_loss: 1.5784 - val_categorical_accuracy: 0.5438\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.5721 - categorical_accuracy: 0.8355 - val_loss: 1.5117 - val_categorical_accuracy: 0.5962\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.4953 - categorical_accuracy: 0.8600 - val_loss: 1.5059 - val_categorical_accuracy: 0.5717\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.4489 - categorical_accuracy: 0.8819 - val_loss: 1.7634 - val_categorical_accuracy: 0.5593\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.4556 - categorical_accuracy: 0.8949 - val_loss: 1.9743 - val_categorical_accuracy: 0.5679\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3979 - categorical_accuracy: 0.9075 - val_loss: 1.9813 - val_categorical_accuracy: 0.5687\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.3636 - categorical_accuracy: 0.9159 - val_loss: 1.7861 - val_categorical_accuracy: 0.5615\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3406 - categorical_accuracy: 0.9230 - val_loss: 1.8408 - val_categorical_accuracy: 0.5770\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3143 - categorical_accuracy: 0.9288 - val_loss: 1.8663 - val_categorical_accuracy: 0.5819\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3006 - categorical_accuracy: 0.9335 - val_loss: 2.3841 - val_categorical_accuracy: 0.5645\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.2819 - categorical_accuracy: 0.9364 - val_loss: 2.1631 - val_categorical_accuracy: 0.5649\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.2667 - categorical_accuracy: 0.9460 - val_loss: 2.2933 - val_categorical_accuracy: 0.5807\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.2725 - categorical_accuracy: 0.9459 - val_loss: 2.2612 - val_categorical_accuracy: 0.5743\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 24s 2ms/step - loss: 3.4576 - categorical_accuracy: 0.4319 - val_loss: 3.3102 - val_categorical_accuracy: 0.4430\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.7714 - categorical_accuracy: 0.5438 - val_loss: 2.4365 - val_categorical_accuracy: 0.4588\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.5024 - categorical_accuracy: 0.5978 - val_loss: 2.5750 - val_categorical_accuracy: 0.4005\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.3180 - categorical_accuracy: 0.6360 - val_loss: 2.4205 - val_categorical_accuracy: 0.4189\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.1830 - categorical_accuracy: 0.6635 - val_loss: 1.9996 - val_categorical_accuracy: 0.5017\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.0874 - categorical_accuracy: 0.6877 - val_loss: 2.4545 - val_categorical_accuracy: 0.4885\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.0287 - categorical_accuracy: 0.7041 - val_loss: 2.0571 - val_categorical_accuracy: 0.5506\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.9630 - categorical_accuracy: 0.7215 - val_loss: 2.1192 - val_categorical_accuracy: 0.5691\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.9319 - categorical_accuracy: 0.7308 - val_loss: 2.6043 - val_categorical_accuracy: 0.5608\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.8970 - categorical_accuracy: 0.7468 - val_loss: 2.4430 - val_categorical_accuracy: 0.5819\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.8598 - categorical_accuracy: 0.7643 - val_loss: 2.4642 - val_categorical_accuracy: 0.5751\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.8402 - categorical_accuracy: 0.7706 - val_loss: 2.3531 - val_categorical_accuracy: 0.5581\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.8083 - categorical_accuracy: 0.7740 - val_loss: 2.5524 - val_categorical_accuracy: 0.5589\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.7767 - categorical_accuracy: 0.7818 - val_loss: 2.7101 - val_categorical_accuracy: 0.5393\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.7602 - categorical_accuracy: 0.7870 - val_loss: 2.5753 - val_categorical_accuracy: 0.5438\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.7682 - categorical_accuracy: 0.7947 - val_loss: 2.8136 - val_categorical_accuracy: 0.5344\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.7445 - categorical_accuracy: 0.7989 - val_loss: 2.6560 - val_categorical_accuracy: 0.5578\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.7339 - categorical_accuracy: 0.8043 - val_loss: 2.7418 - val_categorical_accuracy: 0.5273\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.6976 - categorical_accuracy: 0.8104 - val_loss: 2.9167 - val_categorical_accuracy: 0.5341\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 0.7109 - categorical_accuracy: 0.8097 - val_loss: 2.8907 - val_categorical_accuracy: 0.5359\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
