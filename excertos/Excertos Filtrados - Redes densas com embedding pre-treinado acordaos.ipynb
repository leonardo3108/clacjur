{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD          DESCR_AREA                                           filtrado\n",
       "0  1400    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1  1700   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2  5700    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3   284  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4   298             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22972 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 30000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado'].astype(str))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'].astype(str))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 22972\n",
      "Encontrados no modelo: 18860 = 82.09994776249347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 106,807,774\n",
      "Trainable params: 104,510,474\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 11.5143 - categorical_accuracy: 0.2796 - val_loss: 9.7941 - val_categorical_accuracy: 0.3756\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 4.1393 - categorical_accuracy: 0.5454 - val_loss: 1.4298 - val_categorical_accuracy: 0.4979\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.8638 - categorical_accuracy: 0.7301 - val_loss: 1.2751 - val_categorical_accuracy: 0.5977\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.4051 - categorical_accuracy: 0.8830 - val_loss: 1.3307 - val_categorical_accuracy: 0.6379\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.1840 - categorical_accuracy: 0.9558 - val_loss: 1.9316 - val_categorical_accuracy: 0.5766\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.1399 - categorical_accuracy: 0.9706 - val_loss: 2.0567 - val_categorical_accuracy: 0.6338\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.1122 - categorical_accuracy: 0.9823 - val_loss: 2.7979 - val_categorical_accuracy: 0.6063\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.1077 - categorical_accuracy: 0.9815 - val_loss: 2.3208 - val_categorical_accuracy: 0.6526\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0938 - categorical_accuracy: 0.9869 - val_loss: 2.7893 - val_categorical_accuracy: 0.6240\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.0948 - categorical_accuracy: 0.9869 - val_loss: 2.8739 - val_categorical_accuracy: 0.6342\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0985 - categorical_accuracy: 0.9880 - val_loss: 3.0799 - val_categorical_accuracy: 0.6221\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0955 - categorical_accuracy: 0.9876 - val_loss: 2.9031 - val_categorical_accuracy: 0.6511\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0879 - categorical_accuracy: 0.9903 - val_loss: 2.9206 - val_categorical_accuracy: 0.6206\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0924 - categorical_accuracy: 0.9907 - val_loss: 2.9944 - val_categorical_accuracy: 0.6402\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0850 - categorical_accuracy: 0.9918 - val_loss: 2.7514 - val_categorical_accuracy: 0.6432\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0796 - categorical_accuracy: 0.9927 - val_loss: 3.0870 - val_categorical_accuracy: 0.6289\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0811 - categorical_accuracy: 0.9920 - val_loss: 3.2610 - val_categorical_accuracy: 0.6259\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0827 - categorical_accuracy: 0.9918 - val_loss: 3.6215 - val_categorical_accuracy: 0.6172\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0788 - categorical_accuracy: 0.9926 - val_loss: 3.5446 - val_categorical_accuracy: 0.6428\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0844 - categorical_accuracy: 0.9923 - val_loss: 3.4168 - val_categorical_accuracy: 0.6383\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1127 12:55:11.844475 139825073694528 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1127 12:55:11.920909 139825073694528 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1127 12:55:11.923742 139825073694528 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1127 12:55:11.930594 139825073694528 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1127 12:55:11.931100 139825073694528 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1127 12:55:12.629595 139825073694528 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1127 12:55:12.673872 139825073694528 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1127 12:55:12.759150 139825073694528 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 106,807,774\n",
      "Trainable params: 106,807,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 45s 4ms/step - loss: 8.8001 - categorical_accuracy: 0.3199 - val_loss: 1.9123 - val_categorical_accuracy: 0.5247\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.9883 - categorical_accuracy: 0.6935 - val_loss: 1.4218 - val_categorical_accuracy: 0.5273\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 0.4502 - categorical_accuracy: 0.8723 - val_loss: 1.3675 - val_categorical_accuracy: 0.6093\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2160 - categorical_accuracy: 0.9490 - val_loss: 1.5561 - val_categorical_accuracy: 0.6504\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.1354 - categorical_accuracy: 0.9750 - val_loss: 3.2995 - val_categorical_accuracy: 0.5213\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.1105 - categorical_accuracy: 0.9821 - val_loss: 2.2193 - val_categorical_accuracy: 0.6323\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.1078 - categorical_accuracy: 0.9839 - val_loss: 2.2559 - val_categorical_accuracy: 0.6259\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0956 - categorical_accuracy: 0.9882 - val_loss: 2.4798 - val_categorical_accuracy: 0.6436\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0891 - categorical_accuracy: 0.9887 - val_loss: 2.5747 - val_categorical_accuracy: 0.6387\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0858 - categorical_accuracy: 0.9896 - val_loss: 2.7828 - val_categorical_accuracy: 0.6263\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0865 - categorical_accuracy: 0.9900 - val_loss: 2.7721 - val_categorical_accuracy: 0.6432\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0914 - categorical_accuracy: 0.9895 - val_loss: 2.9692 - val_categorical_accuracy: 0.6391\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0879 - categorical_accuracy: 0.9896 - val_loss: 3.1765 - val_categorical_accuracy: 0.6169\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0822 - categorical_accuracy: 0.9916 - val_loss: 3.2778 - val_categorical_accuracy: 0.6146\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0794 - categorical_accuracy: 0.9917 - val_loss: 2.8669 - val_categorical_accuracy: 0.6571\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0821 - categorical_accuracy: 0.9917 - val_loss: 3.1215 - val_categorical_accuracy: 0.6184\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0777 - categorical_accuracy: 0.9932 - val_loss: 3.2696 - val_categorical_accuracy: 0.6263\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 0.0789 - categorical_accuracy: 0.9924 - val_loss: 3.5935 - val_categorical_accuracy: 0.6011\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.0732 - categorical_accuracy: 0.9935 - val_loss: 3.2404 - val_categorical_accuracy: 0.6323\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 0.0721 - categorical_accuracy: 0.9942 - val_loss: 3.0994 - val_categorical_accuracy: 0.6504\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              51201024  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 54,028,254\n",
      "Trainable params: 54,028,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 24s 2ms/step - loss: 2.5381 - categorical_accuracy: 0.5428 - val_loss: 1.3694 - val_categorical_accuracy: 0.6150\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.7735 - categorical_accuracy: 0.7610 - val_loss: 1.3898 - val_categorical_accuracy: 0.5630\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.4383 - categorical_accuracy: 0.8776 - val_loss: 1.4028 - val_categorical_accuracy: 0.6191\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.2677 - categorical_accuracy: 0.9340 - val_loss: 1.6178 - val_categorical_accuracy: 0.6357\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.2034 - categorical_accuracy: 0.9572 - val_loss: 1.7038 - val_categorical_accuracy: 0.6259\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1481 - categorical_accuracy: 0.9703 - val_loss: 1.8275 - val_categorical_accuracy: 0.6315\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1475 - categorical_accuracy: 0.9754 - val_loss: 1.9381 - val_categorical_accuracy: 0.6394\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1282 - categorical_accuracy: 0.9769 - val_loss: 2.0219 - val_categorical_accuracy: 0.6522\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1194 - categorical_accuracy: 0.9802 - val_loss: 2.1603 - val_categorical_accuracy: 0.6458\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1072 - categorical_accuracy: 0.9824 - val_loss: 2.3791 - val_categorical_accuracy: 0.6534\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1149 - categorical_accuracy: 0.9843 - val_loss: 2.2507 - val_categorical_accuracy: 0.6221\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1076 - categorical_accuracy: 0.9846 - val_loss: 2.5723 - val_categorical_accuracy: 0.6383\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1021 - categorical_accuracy: 0.9865 - val_loss: 2.6229 - val_categorical_accuracy: 0.6368\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1082 - categorical_accuracy: 0.9853 - val_loss: 2.7732 - val_categorical_accuracy: 0.6101\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0883 - categorical_accuracy: 0.9877 - val_loss: 2.5339 - val_categorical_accuracy: 0.6647\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0901 - categorical_accuracy: 0.9896 - val_loss: 2.5819 - val_categorical_accuracy: 0.6504\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0862 - categorical_accuracy: 0.9903 - val_loss: 2.6696 - val_categorical_accuracy: 0.6598\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0860 - categorical_accuracy: 0.9899 - val_loss: 2.6502 - val_categorical_accuracy: 0.6549\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0787 - categorical_accuracy: 0.9909 - val_loss: 2.8042 - val_categorical_accuracy: 0.6684\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0897 - categorical_accuracy: 0.9894 - val_loss: 2.8830 - val_categorical_accuracy: 0.6515\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              51201024  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 53,763,294\n",
      "Trainable params: 53,763,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 2.3950 - categorical_accuracy: 0.5451 - val_loss: 1.3017 - val_categorical_accuracy: 0.5288\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.8551 - categorical_accuracy: 0.7236 - val_loss: 1.0820 - val_categorical_accuracy: 0.6688\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.4892 - categorical_accuracy: 0.8489 - val_loss: 1.1681 - val_categorical_accuracy: 0.6485\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.3003 - categorical_accuracy: 0.9151 - val_loss: 1.4329 - val_categorical_accuracy: 0.6485\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.2042 - categorical_accuracy: 0.9498 - val_loss: 1.8553 - val_categorical_accuracy: 0.6458\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1492 - categorical_accuracy: 0.9658 - val_loss: 2.2814 - val_categorical_accuracy: 0.6346\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1295 - categorical_accuracy: 0.9753 - val_loss: 2.0845 - val_categorical_accuracy: 0.6583\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1065 - categorical_accuracy: 0.9816 - val_loss: 2.5975 - val_categorical_accuracy: 0.6278\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0949 - categorical_accuracy: 0.9858 - val_loss: 2.4166 - val_categorical_accuracy: 0.6537\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0882 - categorical_accuracy: 0.9868 - val_loss: 2.4318 - val_categorical_accuracy: 0.6628\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0892 - categorical_accuracy: 0.9881 - val_loss: 2.6711 - val_categorical_accuracy: 0.6436\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0949 - categorical_accuracy: 0.9879 - val_loss: 2.7120 - val_categorical_accuracy: 0.6613\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0867 - categorical_accuracy: 0.9886 - val_loss: 2.8945 - val_categorical_accuracy: 0.6473\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0853 - categorical_accuracy: 0.9893 - val_loss: 2.9965 - val_categorical_accuracy: 0.6489\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0809 - categorical_accuracy: 0.9895 - val_loss: 2.8158 - val_categorical_accuracy: 0.6387\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0928 - categorical_accuracy: 0.9890 - val_loss: 2.9827 - val_categorical_accuracy: 0.6477\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0838 - categorical_accuracy: 0.9911 - val_loss: 2.7689 - val_categorical_accuracy: 0.6579\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0700 - categorical_accuracy: 0.9937 - val_loss: 2.9370 - val_categorical_accuracy: 0.6699\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0755 - categorical_accuracy: 0.9918 - val_loss: 3.0669 - val_categorical_accuracy: 0.6609\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0808 - categorical_accuracy: 0.9901 - val_loss: 3.0762 - val_categorical_accuracy: 0.6722\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               25600512  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 28,031,710\n",
      "Trainable params: 28,031,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 13s 1ms/step - loss: 1.6852 - categorical_accuracy: 0.5574 - val_loss: 1.3327 - val_categorical_accuracy: 0.5687\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.8099 - categorical_accuracy: 0.7480 - val_loss: 1.1921 - val_categorical_accuracy: 0.6383\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.5394 - categorical_accuracy: 0.8459 - val_loss: 1.2432 - val_categorical_accuracy: 0.6421\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.3733 - categorical_accuracy: 0.9006 - val_loss: 1.5644 - val_categorical_accuracy: 0.6112\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.2893 - categorical_accuracy: 0.9231 - val_loss: 1.5726 - val_categorical_accuracy: 0.6289\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.2451 - categorical_accuracy: 0.9385 - val_loss: 1.8392 - val_categorical_accuracy: 0.6142\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 0.2258 - categorical_accuracy: 0.9467 - val_loss: 1.5730 - val_categorical_accuracy: 0.6466\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2008 - categorical_accuracy: 0.9562 - val_loss: 1.8511 - val_categorical_accuracy: 0.6568\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1755 - categorical_accuracy: 0.9629 - val_loss: 1.7520 - val_categorical_accuracy: 0.6549\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1724 - categorical_accuracy: 0.9658 - val_loss: 1.8950 - val_categorical_accuracy: 0.6564\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1606 - categorical_accuracy: 0.9695 - val_loss: 2.0637 - val_categorical_accuracy: 0.6308\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1578 - categorical_accuracy: 0.9696 - val_loss: 2.0005 - val_categorical_accuracy: 0.6549\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1316 - categorical_accuracy: 0.9744 - val_loss: 1.9966 - val_categorical_accuracy: 0.6568\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1193 - categorical_accuracy: 0.9769 - val_loss: 2.0369 - val_categorical_accuracy: 0.6458\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1117 - categorical_accuracy: 0.9796 - val_loss: 2.0135 - val_categorical_accuracy: 0.6440\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1134 - categorical_accuracy: 0.9792 - val_loss: 2.2548 - val_categorical_accuracy: 0.6609\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1219 - categorical_accuracy: 0.9801 - val_loss: 2.2556 - val_categorical_accuracy: 0.6379\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1096 - categorical_accuracy: 0.9815 - val_loss: 2.3659 - val_categorical_accuracy: 0.6673\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1127 - categorical_accuracy: 0.9817 - val_loss: 2.4565 - val_categorical_accuracy: 0.6443\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1148 - categorical_accuracy: 0.9812 - val_loss: 2.1817 - val_categorical_accuracy: 0.6639\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               12800256  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,131,742\n",
      "Trainable params: 15,131,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 8s 708us/step - loss: 1.5393 - categorical_accuracy: 0.5538 - val_loss: 1.5002 - val_categorical_accuracy: 0.5728\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 7s 631us/step - loss: 0.9236 - categorical_accuracy: 0.7127 - val_loss: 1.5604 - val_categorical_accuracy: 0.5796\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 7s 631us/step - loss: 0.6752 - categorical_accuracy: 0.7929 - val_loss: 1.4351 - val_categorical_accuracy: 0.6199\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 7s 631us/step - loss: 0.4927 - categorical_accuracy: 0.8520 - val_loss: 1.3633 - val_categorical_accuracy: 0.6218\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.3935 - categorical_accuracy: 0.8846 - val_loss: 1.7656 - val_categorical_accuracy: 0.5894\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.3393 - categorical_accuracy: 0.9073 - val_loss: 1.6059 - val_categorical_accuracy: 0.6511\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 7s 635us/step - loss: 0.2899 - categorical_accuracy: 0.9182 - val_loss: 1.5999 - val_categorical_accuracy: 0.6368\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.2706 - categorical_accuracy: 0.9281 - val_loss: 1.8806 - val_categorical_accuracy: 0.5939\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.2353 - categorical_accuracy: 0.9387 - val_loss: 1.7772 - val_categorical_accuracy: 0.6105\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 7s 630us/step - loss: 0.2324 - categorical_accuracy: 0.9383 - val_loss: 1.7533 - val_categorical_accuracy: 0.6481\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.2007 - categorical_accuracy: 0.9462 - val_loss: 1.8388 - val_categorical_accuracy: 0.6477\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.1945 - categorical_accuracy: 0.9495 - val_loss: 1.7900 - val_categorical_accuracy: 0.6568\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 7s 631us/step - loss: 0.1908 - categorical_accuracy: 0.9499 - val_loss: 2.0164 - val_categorical_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.1822 - categorical_accuracy: 0.9534 - val_loss: 1.6656 - val_categorical_accuracy: 0.6379\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 7s 633us/step - loss: 0.1618 - categorical_accuracy: 0.9577 - val_loss: 1.9493 - val_categorical_accuracy: 0.6240\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.1610 - categorical_accuracy: 0.9578 - val_loss: 1.8975 - val_categorical_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.1539 - categorical_accuracy: 0.9576 - val_loss: 1.8590 - val_categorical_accuracy: 0.6613\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.1406 - categorical_accuracy: 0.9654 - val_loss: 1.9732 - val_categorical_accuracy: 0.6522\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.1539 - categorical_accuracy: 0.9626 - val_loss: 1.9162 - val_categorical_accuracy: 0.6616\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 7s 633us/step - loss: 0.1505 - categorical_accuracy: 0.9651 - val_loss: 2.0664 - val_categorical_accuracy: 0.6357\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
