{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD          DESCR_AREA                                           filtrado\n",
       "0  1400    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1  1700   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2  5700    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3   284  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4   298             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22972 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 30000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13285, 500), (13285, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 21:05:06.648590 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1201 21:05:06.660828 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1201 21:05:06.663952 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1201 21:05:06.690944 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1201 21:05:06.735423 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1201 21:05:06.742250 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 2,327,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1201 21:05:06.916845 139885603206976 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1201 21:05:07.045047 139885603206976 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 4s 396us/step - loss: 1.2927 - categorical_accuracy: 0.5590 - val_loss: 1.1505 - val_categorical_accuracy: 0.6364\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 187us/step - loss: 0.7256 - categorical_accuracy: 0.7567 - val_loss: 0.8979 - val_categorical_accuracy: 0.7143\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 178us/step - loss: 0.4931 - categorical_accuracy: 0.8411 - val_loss: 0.9329 - val_categorical_accuracy: 0.7140\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 175us/step - loss: 0.3486 - categorical_accuracy: 0.8904 - val_loss: 0.9202 - val_categorical_accuracy: 0.7369\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 175us/step - loss: 0.2455 - categorical_accuracy: 0.9280 - val_loss: 0.9368 - val_categorical_accuracy: 0.7339\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 190us/step - loss: 0.1665 - categorical_accuracy: 0.9514 - val_loss: 1.1738 - val_categorical_accuracy: 0.7132\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 185us/step - loss: 0.1114 - categorical_accuracy: 0.9701 - val_loss: 1.0945 - val_categorical_accuracy: 0.7444\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 177us/step - loss: 0.0753 - categorical_accuracy: 0.9812 - val_loss: 1.4158 - val_categorical_accuracy: 0.6861\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 183us/step - loss: 0.0558 - categorical_accuracy: 0.9874 - val_loss: 1.2635 - val_categorical_accuracy: 0.7422\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 191us/step - loss: 0.0437 - categorical_accuracy: 0.9906 - val_loss: 1.4745 - val_categorical_accuracy: 0.7030\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.0425 - categorical_accuracy: 0.9912 - val_loss: 1.4740 - val_categorical_accuracy: 0.7347\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 182us/step - loss: 0.0367 - categorical_accuracy: 0.9923 - val_loss: 1.4189 - val_categorical_accuracy: 0.7482\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 183us/step - loss: 0.0368 - categorical_accuracy: 0.9924 - val_loss: 1.5913 - val_categorical_accuracy: 0.7219\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 187us/step - loss: 0.0345 - categorical_accuracy: 0.9924 - val_loss: 1.7346 - val_categorical_accuracy: 0.7098\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 203us/step - loss: 0.0350 - categorical_accuracy: 0.9937 - val_loss: 1.5795 - val_categorical_accuracy: 0.7373\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 187us/step - loss: 0.0367 - categorical_accuracy: 0.9935 - val_loss: 1.5232 - val_categorical_accuracy: 0.7347\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 194us/step - loss: 0.0370 - categorical_accuracy: 0.9939 - val_loss: 1.5999 - val_categorical_accuracy: 0.7305\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 207us/step - loss: 0.0346 - categorical_accuracy: 0.9943 - val_loss: 1.6160 - val_categorical_accuracy: 0.7264\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 170us/step - loss: 0.0368 - categorical_accuracy: 0.9934 - val_loss: 1.7212 - val_categorical_accuracy: 0.7136\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 181us/step - loss: 0.0322 - categorical_accuracy: 0.9938 - val_loss: 1.6655 - val_categorical_accuracy: 0.7388\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,327,262\n",
      "Trainable params: 2,327,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 2s 230us/step - loss: 0.9541 - categorical_accuracy: 0.6840 - val_loss: 1.3138 - val_categorical_accuracy: 0.5868\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 189us/step - loss: 0.5363 - categorical_accuracy: 0.8358 - val_loss: 1.2408 - val_categorical_accuracy: 0.6737\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 166us/step - loss: 0.3494 - categorical_accuracy: 0.8896 - val_loss: 1.0115 - val_categorical_accuracy: 0.7298\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 168us/step - loss: 0.2305 - categorical_accuracy: 0.9320 - val_loss: 1.1971 - val_categorical_accuracy: 0.7448\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 183us/step - loss: 0.1584 - categorical_accuracy: 0.9596 - val_loss: 1.5886 - val_categorical_accuracy: 0.7061\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 172us/step - loss: 0.1464 - categorical_accuracy: 0.9673 - val_loss: 1.6181 - val_categorical_accuracy: 0.7290\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 170us/step - loss: 0.1218 - categorical_accuracy: 0.9760 - val_loss: 1.9730 - val_categorical_accuracy: 0.7140\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 174us/step - loss: 0.1043 - categorical_accuracy: 0.9805 - val_loss: 2.5089 - val_categorical_accuracy: 0.7030\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 177us/step - loss: 0.1152 - categorical_accuracy: 0.9821 - val_loss: 2.2054 - val_categorical_accuracy: 0.7365\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 181us/step - loss: 0.1179 - categorical_accuracy: 0.9802 - val_loss: 2.1861 - val_categorical_accuracy: 0.7460\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 175us/step - loss: 0.1105 - categorical_accuracy: 0.9848 - val_loss: 2.7376 - val_categorical_accuracy: 0.7177\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 177us/step - loss: 0.1142 - categorical_accuracy: 0.9849 - val_loss: 2.5988 - val_categorical_accuracy: 0.7332\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 176us/step - loss: 0.1134 - categorical_accuracy: 0.9855 - val_loss: 2.7221 - val_categorical_accuracy: 0.7237\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 184us/step - loss: 0.1037 - categorical_accuracy: 0.9863 - val_loss: 3.1257 - val_categorical_accuracy: 0.7072\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 175us/step - loss: 0.1071 - categorical_accuracy: 0.9864 - val_loss: 3.0391 - val_categorical_accuracy: 0.7140\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 180us/step - loss: 0.0988 - categorical_accuracy: 0.9881 - val_loss: 3.5078 - val_categorical_accuracy: 0.6910\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 172us/step - loss: 0.1022 - categorical_accuracy: 0.9886 - val_loss: 3.6317 - val_categorical_accuracy: 0.6831\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 188us/step - loss: 0.1012 - categorical_accuracy: 0.9895 - val_loss: 3.6101 - val_categorical_accuracy: 0.6967\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 170us/step - loss: 0.1065 - categorical_accuracy: 0.9893 - val_loss: 3.9043 - val_categorical_accuracy: 0.6805\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 176us/step - loss: 0.1151 - categorical_accuracy: 0.9873 - val_loss: 3.4867 - val_categorical_accuracy: 0.7087\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=5e-3),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,356,862\n",
      "Trainable params: 2,356,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 254us/step - loss: 1.2684 - categorical_accuracy: 0.5679 - val_loss: 1.2654 - val_categorical_accuracy: 0.6184\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 209us/step - loss: 0.7202 - categorical_accuracy: 0.7664 - val_loss: 1.0731 - val_categorical_accuracy: 0.6744\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 199us/step - loss: 0.5009 - categorical_accuracy: 0.8422 - val_loss: 0.9071 - val_categorical_accuracy: 0.7369\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.3642 - categorical_accuracy: 0.8879 - val_loss: 1.0607 - val_categorical_accuracy: 0.7230\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 3s 242us/step - loss: 0.2648 - categorical_accuracy: 0.9182 - val_loss: 1.0322 - val_categorical_accuracy: 0.7343\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 218us/step - loss: 0.1875 - categorical_accuracy: 0.9447 - val_loss: 1.2749 - val_categorical_accuracy: 0.6782\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 219us/step - loss: 0.1284 - categorical_accuracy: 0.9645 - val_loss: 1.1730 - val_categorical_accuracy: 0.7347\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 230us/step - loss: 0.0895 - categorical_accuracy: 0.9772 - val_loss: 1.2754 - val_categorical_accuracy: 0.7354\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 228us/step - loss: 0.0626 - categorical_accuracy: 0.9857 - val_loss: 1.5976 - val_categorical_accuracy: 0.6854\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 210us/step - loss: 0.0515 - categorical_accuracy: 0.9900 - val_loss: 1.6253 - val_categorical_accuracy: 0.6827\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 224us/step - loss: 0.0437 - categorical_accuracy: 0.9917 - val_loss: 1.6085 - val_categorical_accuracy: 0.6974\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 225us/step - loss: 0.0458 - categorical_accuracy: 0.9907 - val_loss: 1.7338 - val_categorical_accuracy: 0.6903\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 203us/step - loss: 0.0419 - categorical_accuracy: 0.9924 - val_loss: 1.6974 - val_categorical_accuracy: 0.7015\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.0411 - categorical_accuracy: 0.9923 - val_loss: 1.6106 - val_categorical_accuracy: 0.7147\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 212us/step - loss: 0.0390 - categorical_accuracy: 0.9935 - val_loss: 1.5307 - val_categorical_accuracy: 0.7298\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 204us/step - loss: 0.0406 - categorical_accuracy: 0.9931 - val_loss: 1.6099 - val_categorical_accuracy: 0.7215\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 202us/step - loss: 0.0378 - categorical_accuracy: 0.9934 - val_loss: 1.6483 - val_categorical_accuracy: 0.7317\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 214us/step - loss: 0.0409 - categorical_accuracy: 0.9931 - val_loss: 1.8955 - val_categorical_accuracy: 0.7015\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 230us/step - loss: 0.0397 - categorical_accuracy: 0.9932 - val_loss: 1.9919 - val_categorical_accuracy: 0.6763\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 204us/step - loss: 0.0402 - categorical_accuracy: 0.9939 - val_loss: 1.9828 - val_categorical_accuracy: 0.6869\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1201 21:07:13.883694 139885603206976 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,125,374\n",
      "Trainable params: 3,125,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 247us/step - loss: 1.1260 - categorical_accuracy: 0.6169 - val_loss: 0.9511 - val_categorical_accuracy: 0.7064\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 2s 214us/step - loss: 0.5756 - categorical_accuracy: 0.8164 - val_loss: 0.9161 - val_categorical_accuracy: 0.7298\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 2s 205us/step - loss: 0.3549 - categorical_accuracy: 0.8876 - val_loss: 0.9141 - val_categorical_accuracy: 0.7614\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 2s 201us/step - loss: 0.2041 - categorical_accuracy: 0.9392 - val_loss: 1.1605 - val_categorical_accuracy: 0.7298\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 2s 213us/step - loss: 0.1161 - categorical_accuracy: 0.9689 - val_loss: 1.2842 - val_categorical_accuracy: 0.7392\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 2s 209us/step - loss: 0.0722 - categorical_accuracy: 0.9829 - val_loss: 1.4009 - val_categorical_accuracy: 0.7618\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 2s 200us/step - loss: 0.0541 - categorical_accuracy: 0.9896 - val_loss: 1.8022 - val_categorical_accuracy: 0.7053\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 2s 204us/step - loss: 0.0534 - categorical_accuracy: 0.9914 - val_loss: 1.6040 - val_categorical_accuracy: 0.7429\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 0.0443 - categorical_accuracy: 0.9920 - val_loss: 1.7714 - val_categorical_accuracy: 0.7606\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 2s 212us/step - loss: 0.0432 - categorical_accuracy: 0.9928 - val_loss: 2.1477 - val_categorical_accuracy: 0.7140\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 2s 217us/step - loss: 0.0371 - categorical_accuracy: 0.9925 - val_loss: 2.0490 - val_categorical_accuracy: 0.7125\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 0.0354 - categorical_accuracy: 0.9939 - val_loss: 2.2975 - val_categorical_accuracy: 0.6906\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 0.0332 - categorical_accuracy: 0.9936 - val_loss: 1.9395 - val_categorical_accuracy: 0.7358\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 2s 211us/step - loss: 0.0280 - categorical_accuracy: 0.9940 - val_loss: 1.9337 - val_categorical_accuracy: 0.7418\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 2s 208us/step - loss: 0.0293 - categorical_accuracy: 0.9934 - val_loss: 2.0677 - val_categorical_accuracy: 0.7392\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 2s 223us/step - loss: 0.0260 - categorical_accuracy: 0.9950 - val_loss: 2.1797 - val_categorical_accuracy: 0.7290\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 2s 210us/step - loss: 0.0229 - categorical_accuracy: 0.9941 - val_loss: 2.2870 - val_categorical_accuracy: 0.7268\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 2s 204us/step - loss: 0.0269 - categorical_accuracy: 0.9932 - val_loss: 2.3014 - val_categorical_accuracy: 0.7253\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 2s 221us/step - loss: 0.0234 - categorical_accuracy: 0.9934 - val_loss: 2.2731 - val_categorical_accuracy: 0.7245\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 2s 211us/step - loss: 0.0201 - categorical_accuracy: 0.9945 - val_loss: 2.1652 - val_categorical_accuracy: 0.7475\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,950,622\n",
      "Trainable params: 3,950,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 3s 305us/step - loss: 1.0725 - categorical_accuracy: 0.6341 - val_loss: 1.1159 - val_categorical_accuracy: 0.6304\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 3s 267us/step - loss: 0.5685 - categorical_accuracy: 0.8164 - val_loss: 0.9394 - val_categorical_accuracy: 0.7219\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 3s 258us/step - loss: 0.3464 - categorical_accuracy: 0.8938 - val_loss: 1.0685 - val_categorical_accuracy: 0.7174\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 3s 257us/step - loss: 0.2072 - categorical_accuracy: 0.9370 - val_loss: 1.1416 - val_categorical_accuracy: 0.7437\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 3s 268us/step - loss: 0.1159 - categorical_accuracy: 0.9693 - val_loss: 1.4797 - val_categorical_accuracy: 0.7381\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 3s 257us/step - loss: 0.0783 - categorical_accuracy: 0.9830 - val_loss: 1.6060 - val_categorical_accuracy: 0.7527\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 3s 255us/step - loss: 0.0613 - categorical_accuracy: 0.9897 - val_loss: 1.6619 - val_categorical_accuracy: 0.7478\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 3s 273us/step - loss: 0.0544 - categorical_accuracy: 0.9906 - val_loss: 1.8396 - val_categorical_accuracy: 0.7189\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 3s 255us/step - loss: 0.0481 - categorical_accuracy: 0.9924 - val_loss: 1.8362 - val_categorical_accuracy: 0.7565\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 3s 267us/step - loss: 0.0459 - categorical_accuracy: 0.9927 - val_loss: 2.0937 - val_categorical_accuracy: 0.7358\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 3s 255us/step - loss: 0.0431 - categorical_accuracy: 0.9929 - val_loss: 1.8875 - val_categorical_accuracy: 0.7471\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 3s 242us/step - loss: 0.0379 - categorical_accuracy: 0.9941 - val_loss: 1.8887 - val_categorical_accuracy: 0.7520\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 3s 254us/step - loss: 0.0331 - categorical_accuracy: 0.9928 - val_loss: 2.0057 - val_categorical_accuracy: 0.7328\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 3s 249us/step - loss: 0.0327 - categorical_accuracy: 0.9932 - val_loss: 2.1286 - val_categorical_accuracy: 0.7117\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 3s 243us/step - loss: 0.0289 - categorical_accuracy: 0.9935 - val_loss: 2.4476 - val_categorical_accuracy: 0.7290\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 3s 252us/step - loss: 0.0275 - categorical_accuracy: 0.9943 - val_loss: 2.3575 - val_categorical_accuracy: 0.7256\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 3s 247us/step - loss: 0.0267 - categorical_accuracy: 0.9931 - val_loss: 2.0972 - val_categorical_accuracy: 0.7452\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 3s 242us/step - loss: 0.0237 - categorical_accuracy: 0.9936 - val_loss: 2.4253 - val_categorical_accuracy: 0.7211\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 3s 251us/step - loss: 0.0250 - categorical_accuracy: 0.9936 - val_loss: 2.2824 - val_categorical_accuracy: 0.7373\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 3s 249us/step - loss: 0.0227 - categorical_accuracy: 0.9940 - val_loss: 2.2633 - val_categorical_accuracy: 0.7550\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,551,454\n",
      "Trainable params: 2,551,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 1.3074 - categorical_accuracy: 0.5308 - val_loss: 1.3697 - val_categorical_accuracy: 0.4599\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 33s 3ms/step - loss: 0.8574 - categorical_accuracy: 0.7024 - val_loss: 1.0807 - val_categorical_accuracy: 0.6334\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.6304 - categorical_accuracy: 0.7909 - val_loss: 1.0489 - val_categorical_accuracy: 0.6534\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 33s 3ms/step - loss: 0.4925 - categorical_accuracy: 0.8405 - val_loss: 1.0015 - val_categorical_accuracy: 0.6906\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.3802 - categorical_accuracy: 0.8775 - val_loss: 0.9931 - val_categorical_accuracy: 0.6967\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.2939 - categorical_accuracy: 0.9080 - val_loss: 1.2044 - val_categorical_accuracy: 0.6816\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2153 - categorical_accuracy: 0.9330 - val_loss: 1.1097 - val_categorical_accuracy: 0.7204\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.1687 - categorical_accuracy: 0.9493 - val_loss: 1.2585 - val_categorical_accuracy: 0.6782\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.1291 - categorical_accuracy: 0.9610 - val_loss: 1.3078 - val_categorical_accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.1018 - categorical_accuracy: 0.9685 - val_loss: 1.4420 - val_categorical_accuracy: 0.6726\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0792 - categorical_accuracy: 0.9775 - val_loss: 1.7131 - val_categorical_accuracy: 0.6601\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.0677 - categorical_accuracy: 0.9815 - val_loss: 1.4544 - val_categorical_accuracy: 0.7181\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.0542 - categorical_accuracy: 0.9831 - val_loss: 1.4478 - val_categorical_accuracy: 0.7286\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0476 - categorical_accuracy: 0.9868 - val_loss: 1.5439 - val_categorical_accuracy: 0.6993\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0480 - categorical_accuracy: 0.9872 - val_loss: 1.5158 - val_categorical_accuracy: 0.7147\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0462 - categorical_accuracy: 0.9885 - val_loss: 1.6609 - val_categorical_accuracy: 0.7042\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0418 - categorical_accuracy: 0.9889 - val_loss: 1.6145 - val_categorical_accuracy: 0.7049\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.0362 - categorical_accuracy: 0.9907 - val_loss: 1.7674 - val_categorical_accuracy: 0.6808\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0322 - categorical_accuracy: 0.9913 - val_loss: 1.6442 - val_categorical_accuracy: 0.7102\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0359 - categorical_accuracy: 0.9909 - val_loss: 1.7511 - val_categorical_accuracy: 0.7027\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,581,054\n",
      "Trainable params: 2,581,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 37s 4ms/step - loss: 1.2543 - categorical_accuracy: 0.5661 - val_loss: 1.5499 - val_categorical_accuracy: 0.5563\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.7774 - categorical_accuracy: 0.7359 - val_loss: 1.1303 - val_categorical_accuracy: 0.6135\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.5905 - categorical_accuracy: 0.8065 - val_loss: 0.9485 - val_categorical_accuracy: 0.6993\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.4612 - categorical_accuracy: 0.8506 - val_loss: 0.9716 - val_categorical_accuracy: 0.7079\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.3664 - categorical_accuracy: 0.8851 - val_loss: 1.0826 - val_categorical_accuracy: 0.6970\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.2854 - categorical_accuracy: 0.9108 - val_loss: 1.3791 - val_categorical_accuracy: 0.6146\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.2182 - categorical_accuracy: 0.9312 - val_loss: 1.1605 - val_categorical_accuracy: 0.7140\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.1736 - categorical_accuracy: 0.9471 - val_loss: 1.2520 - val_categorical_accuracy: 0.6891\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.1306 - categorical_accuracy: 0.9611 - val_loss: 1.2228 - val_categorical_accuracy: 0.7215\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.1073 - categorical_accuracy: 0.9687 - val_loss: 1.3490 - val_categorical_accuracy: 0.7072\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0874 - categorical_accuracy: 0.9747 - val_loss: 1.4203 - val_categorical_accuracy: 0.7102\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 36s 3ms/step - loss: 0.0717 - categorical_accuracy: 0.9799 - val_loss: 1.4030 - val_categorical_accuracy: 0.7350\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0572 - categorical_accuracy: 0.9846 - val_loss: 1.6199 - val_categorical_accuracy: 0.6989\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0557 - categorical_accuracy: 0.9850 - val_loss: 1.5928 - val_categorical_accuracy: 0.6903\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0506 - categorical_accuracy: 0.9864 - val_loss: 1.7084 - val_categorical_accuracy: 0.6850\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 38s 4ms/step - loss: 0.0460 - categorical_accuracy: 0.9887 - val_loss: 1.6168 - val_categorical_accuracy: 0.7117\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.0441 - categorical_accuracy: 0.9880 - val_loss: 1.5845 - val_categorical_accuracy: 0.7222\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0435 - categorical_accuracy: 0.9893 - val_loss: 1.7324 - val_categorical_accuracy: 0.7158\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0397 - categorical_accuracy: 0.9890 - val_loss: 1.7815 - val_categorical_accuracy: 0.6899\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0379 - categorical_accuracy: 0.9902 - val_loss: 1.6482 - val_categorical_accuracy: 0.7260\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=limite_texto))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               61824     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,390,046\n",
      "Trainable params: 2,390,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 1.3380 - categorical_accuracy: 0.5256 - val_loss: 1.2719 - val_categorical_accuracy: 0.5653\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.9124 - categorical_accuracy: 0.6824 - val_loss: 1.2086 - val_categorical_accuracy: 0.6285\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.6985 - categorical_accuracy: 0.7654 - val_loss: 0.9802 - val_categorical_accuracy: 0.6846\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.5378 - categorical_accuracy: 0.8186 - val_loss: 0.9190 - val_categorical_accuracy: 0.7155\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.4188 - categorical_accuracy: 0.8661 - val_loss: 1.0448 - val_categorical_accuracy: 0.6737\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.3244 - categorical_accuracy: 0.8958 - val_loss: 1.0369 - val_categorical_accuracy: 0.6959\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.2510 - categorical_accuracy: 0.9244 - val_loss: 1.0797 - val_categorical_accuracy: 0.7125\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.1875 - categorical_accuracy: 0.9411 - val_loss: 1.2014 - val_categorical_accuracy: 0.7158\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.1422 - categorical_accuracy: 0.9575 - val_loss: 1.2800 - val_categorical_accuracy: 0.7023\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.1105 - categorical_accuracy: 0.9665 - val_loss: 1.5047 - val_categorical_accuracy: 0.6643\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.0912 - categorical_accuracy: 0.9747 - val_loss: 1.5991 - val_categorical_accuracy: 0.6579\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0759 - categorical_accuracy: 0.9779 - val_loss: 1.4661 - val_categorical_accuracy: 0.7019\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0652 - categorical_accuracy: 0.9827 - val_loss: 1.5137 - val_categorical_accuracy: 0.6944\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0566 - categorical_accuracy: 0.9827 - val_loss: 1.5959 - val_categorical_accuracy: 0.6970\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 37s 3ms/step - loss: 0.0540 - categorical_accuracy: 0.9849 - val_loss: 1.5972 - val_categorical_accuracy: 0.7015\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0457 - categorical_accuracy: 0.9873 - val_loss: 1.6166 - val_categorical_accuracy: 0.6925\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 34s 3ms/step - loss: 0.0427 - categorical_accuracy: 0.9887 - val_loss: 1.7572 - val_categorical_accuracy: 0.6797\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0409 - categorical_accuracy: 0.9895 - val_loss: 1.6099 - val_categorical_accuracy: 0.7079\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 35s 3ms/step - loss: 0.0384 - categorical_accuracy: 0.9898 - val_loss: 1.5395 - val_categorical_accuracy: 0.7136\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 33s 3ms/step - loss: 0.0368 - categorical_accuracy: 0.9910 - val_loss: 2.5013 - val_categorical_accuracy: 0.5856\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
