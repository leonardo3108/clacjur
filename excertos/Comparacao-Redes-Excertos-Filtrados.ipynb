{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtenção e organização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DESCR_AREA                                           filtrado\n",
       "0    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')[['DESCR_AREA', 'filtrado']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "        'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "        'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "        'Responsabilidade'], dtype='<U23'), (13285, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "lbArea.classes_, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCarregamento do modelo de acordaos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "print('\\tCarregamento do modelo de acordaos...')\n",
    "modelo = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTokenizacao e montagem de sequencias...\n",
      "\tMontagem da matriz de embeddings...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "print('\\tTokenizacao e montagem de sequencias...')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['filtrado'])\n",
    "vocabulario = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'])\n",
    "\n",
    "print('\\tMontagem da matriz de embeddings...')\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in modelo.wv:\n",
    "        embedding_matrix[i] = modelo.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamentos com Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos a serem comparados:\n",
    "\n",
    "* Teste 1 - Excertos filtrados (500) com rede recorrente\n",
    "* Teste 2 - Excertos filtrados (500) com rede convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_scores = list(lbArea.classes_)\n",
    "colunas_scores.extend(['accuracy', 'macro avg', 'weighted avg'])\n",
    "alternativas = ['rede recorrente sobre texto filtrado', 'rede convolucional sobre texto filtrado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Alternativa 1 - rede recorrente sobre texto filtrado\n",
      "\n",
      "\n",
      "Alternativa rede recorrente sobre texto filtrado - Fold 0:\n",
      "\tDefinicao de valores de entrada e saida da rede...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0321 16:14:39.879317 140033094072128 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0321 16:14:39.892505 140033094072128 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0321 16:14:39.894325 140033094072128 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0321 16:14:39.902577 140033094072128 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0321 16:14:39.903250 140033094072128 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTreinamento da rede...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0321 16:14:40.806172 140033094072128 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0321 16:14:41.203860 140033094072128 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0321 16:14:41.302528 140033094072128 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11956 samples, validate on 1329 samples\n",
      "Epoch 1/20\n",
      "11956/11956 [==============================] - 345s 29ms/step - loss: 1.1249 - categorical_accuracy: 0.6323 - val_loss: 1.0578 - val_categorical_accuracy: 0.6305\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.63055, saving model to weights0-0.hdf5\n",
      "Epoch 2/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.7514 - categorical_accuracy: 0.7498 - val_loss: 0.7501 - val_categorical_accuracy: 0.7585\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.63055 to 0.75847, saving model to weights0-0.hdf5\n",
      "Epoch 3/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.6082 - categorical_accuracy: 0.7996 - val_loss: 0.6560 - val_categorical_accuracy: 0.7825\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.75847 to 0.78254, saving model to weights0-0.hdf5\n",
      "Epoch 4/20\n",
      "11956/11956 [==============================] - 343s 29ms/step - loss: 0.5282 - categorical_accuracy: 0.8265 - val_loss: 0.5969 - val_categorical_accuracy: 0.7946\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.78254 to 0.79458, saving model to weights0-0.hdf5\n",
      "Epoch 5/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.4727 - categorical_accuracy: 0.8427 - val_loss: 0.5812 - val_categorical_accuracy: 0.8089\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.79458 to 0.80888, saving model to weights0-0.hdf5\n",
      "Epoch 6/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.4197 - categorical_accuracy: 0.8606 - val_loss: 0.5710 - val_categorical_accuracy: 0.8134\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.80888 to 0.81339, saving model to weights0-0.hdf5\n",
      "Epoch 7/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.3797 - categorical_accuracy: 0.8727 - val_loss: 0.5536 - val_categorical_accuracy: 0.8149\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.81339 to 0.81490, saving model to weights0-0.hdf5\n",
      "Epoch 8/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.3542 - categorical_accuracy: 0.8819 - val_loss: 0.5649 - val_categorical_accuracy: 0.8126\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.81490\n",
      "Epoch 9/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.3226 - categorical_accuracy: 0.8949 - val_loss: 0.5705 - val_categorical_accuracy: 0.8119\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.81490\n",
      "Epoch 10/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.2976 - categorical_accuracy: 0.9021 - val_loss: 0.5781 - val_categorical_accuracy: 0.8202\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.81490 to 0.82017, saving model to weights0-0.hdf5\n",
      "Epoch 11/20\n",
      "11956/11956 [==============================] - 343s 29ms/step - loss: 0.2734 - categorical_accuracy: 0.9084 - val_loss: 0.5823 - val_categorical_accuracy: 0.8202\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.82017 to 0.82017, saving model to weights0-0.hdf5\n",
      "Epoch 12/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.2565 - categorical_accuracy: 0.9126 - val_loss: 0.5733 - val_categorical_accuracy: 0.8337\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.82017 to 0.83371, saving model to weights0-0.hdf5\n",
      "Epoch 13/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.2290 - categorical_accuracy: 0.9279 - val_loss: 0.5869 - val_categorical_accuracy: 0.8232\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 14/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.2217 - categorical_accuracy: 0.9244 - val_loss: 0.6361 - val_categorical_accuracy: 0.8164\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 15/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.2104 - categorical_accuracy: 0.9307 - val_loss: 0.6216 - val_categorical_accuracy: 0.8141\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 16/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.2054 - categorical_accuracy: 0.9320 - val_loss: 0.6079 - val_categorical_accuracy: 0.8224\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 17/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.1932 - categorical_accuracy: 0.9350 - val_loss: 0.6655 - val_categorical_accuracy: 0.8232\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 18/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.1779 - categorical_accuracy: 0.9422 - val_loss: 0.6761 - val_categorical_accuracy: 0.8269\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 19/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.1778 - categorical_accuracy: 0.9415 - val_loss: 0.6835 - val_categorical_accuracy: 0.8269\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.83371\n",
      "Epoch 20/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.1772 - categorical_accuracy: 0.9379 - val_loss: 0.7072 - val_categorical_accuracy: 0.8149\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.83371\n",
      "\n",
      "\tAvaliacao do melhor modelo e registro dos scores...\n",
      "1329/1329 [==============================] - 13s 10ms/step\n",
      "\n",
      "\n",
      "Alternativa rede recorrente sobre texto filtrado - Fold 1:\n",
      "\tDefinicao de valores de entrada e saida da rede...\n",
      "\tTreinamento da rede...\n",
      "Train on 11956 samples, validate on 1329 samples\n",
      "Epoch 1/20\n",
      "11956/11956 [==============================] - 345s 29ms/step - loss: 1.0944 - categorical_accuracy: 0.6365 - val_loss: 0.9561 - val_categorical_accuracy: 0.6795\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.67946, saving model to weights0-1.hdf5\n",
      "Epoch 2/20\n",
      "11956/11956 [==============================] - 343s 29ms/step - loss: 0.7221 - categorical_accuracy: 0.7673 - val_loss: 0.6780 - val_categorical_accuracy: 0.7705\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.67946 to 0.77050, saving model to weights0-1.hdf5\n",
      "Epoch 3/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.5993 - categorical_accuracy: 0.8029 - val_loss: 0.5669 - val_categorical_accuracy: 0.7961\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.77050 to 0.79609, saving model to weights0-1.hdf5\n",
      "Epoch 4/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.5156 - categorical_accuracy: 0.8312 - val_loss: 0.5371 - val_categorical_accuracy: 0.8194\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.79609 to 0.81941, saving model to weights0-1.hdf5\n",
      "Epoch 5/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.4667 - categorical_accuracy: 0.8461 - val_loss: 0.5220 - val_categorical_accuracy: 0.8209\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.81941 to 0.82092, saving model to weights0-1.hdf5\n",
      "Epoch 6/20\n",
      "11956/11956 [==============================] - 345s 29ms/step - loss: 0.4197 - categorical_accuracy: 0.8632 - val_loss: 0.5020 - val_categorical_accuracy: 0.8375\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.82092 to 0.83747, saving model to weights0-1.hdf5\n",
      "Epoch 7/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.3838 - categorical_accuracy: 0.8730 - val_loss: 0.4972 - val_categorical_accuracy: 0.8473\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.83747 to 0.84725, saving model to weights0-1.hdf5\n",
      "Epoch 8/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.3480 - categorical_accuracy: 0.8857 - val_loss: 0.4989 - val_categorical_accuracy: 0.8442\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.84725\n",
      "Epoch 9/20\n",
      "11956/11956 [==============================] - 344s 29ms/step - loss: 0.3198 - categorical_accuracy: 0.8952 - val_loss: 0.5200 - val_categorical_accuracy: 0.8360\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.84725\n",
      "Epoch 10/20\n",
      "11956/11956 [==============================] - 345s 29ms/step - loss: 0.2985 - categorical_accuracy: 0.9006 - val_loss: 0.5000 - val_categorical_accuracy: 0.8495\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.84725 to 0.84951, saving model to weights0-1.hdf5\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.2748 - categorical_accuracy: 0.9043 - val_loss: 0.5031 - val_categorical_accuracy: 0.8412\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.84951\n",
      "Epoch 12/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.2512 - categorical_accuracy: 0.9144 - val_loss: 0.5116 - val_categorical_accuracy: 0.8525\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.84951 to 0.85252, saving model to weights0-1.hdf5\n",
      "Epoch 13/20\n",
      "11956/11956 [==============================] - 343s 29ms/step - loss: 0.2411 - categorical_accuracy: 0.9184 - val_loss: 0.5412 - val_categorical_accuracy: 0.8503\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.85252\n",
      "Epoch 14/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.2300 - categorical_accuracy: 0.9233 - val_loss: 0.5600 - val_categorical_accuracy: 0.8450\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.85252\n",
      "Epoch 15/20\n",
      "11956/11956 [==============================] - 343s 29ms/step - loss: 0.2137 - categorical_accuracy: 0.9273 - val_loss: 0.5672 - val_categorical_accuracy: 0.8495\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.85252\n",
      "Epoch 16/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.2030 - categorical_accuracy: 0.9310 - val_loss: 0.5301 - val_categorical_accuracy: 0.8503\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.85252\n",
      "Epoch 17/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.2018 - categorical_accuracy: 0.9324 - val_loss: 0.5721 - val_categorical_accuracy: 0.8473\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.85252\n",
      "Epoch 18/20\n",
      "11956/11956 [==============================] - 342s 29ms/step - loss: 0.1902 - categorical_accuracy: 0.9381 - val_loss: 0.5453 - val_categorical_accuracy: 0.8540\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.85252 to 0.85403, saving model to weights0-1.hdf5\n",
      "Epoch 19/20\n",
      "11956/11956 [==============================] - 360s 30ms/step - loss: 0.1691 - categorical_accuracy: 0.9419 - val_loss: 0.5738 - val_categorical_accuracy: 0.8578\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.85403 to 0.85779, saving model to weights0-1.hdf5\n",
      "Epoch 20/20\n",
      "11956/11956 [==============================] - 383s 32ms/step - loss: 0.1696 - categorical_accuracy: 0.9414 - val_loss: 0.5730 - val_categorical_accuracy: 0.8510\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.85779\n",
      "\n",
      "\tAvaliacao do melhor modelo e registro dos scores...\n",
      "1329/1329 [==============================] - 14s 10ms/step\n",
      "\n",
      "\n",
      "Alternativa rede recorrente sobre texto filtrado - Fold 2:\n",
      "\tDefinicao de valores de entrada e saida da rede...\n",
      "\tTreinamento da rede...\n",
      "Train on 11956 samples, validate on 1329 samples\n",
      "Epoch 1/20\n",
      "11956/11956 [==============================] - 357s 30ms/step - loss: 1.1046 - categorical_accuracy: 0.6375 - val_loss: 0.9816 - val_categorical_accuracy: 0.6336\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.63356, saving model to weights0-2.hdf5\n",
      "Epoch 2/20\n",
      "11956/11956 [==============================] - 349s 29ms/step - loss: 0.7356 - categorical_accuracy: 0.7588 - val_loss: 0.7118 - val_categorical_accuracy: 0.7615\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.63356 to 0.76147, saving model to weights0-2.hdf5\n",
      "Epoch 3/20\n",
      "11956/11956 [==============================] - 366s 31ms/step - loss: 0.5928 - categorical_accuracy: 0.8050 - val_loss: 0.6972 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.76147 to 0.76674, saving model to weights0-2.hdf5\n",
      "Epoch 4/20\n",
      "11956/11956 [==============================] - 352s 29ms/step - loss: 0.5208 - categorical_accuracy: 0.8291 - val_loss: 0.5875 - val_categorical_accuracy: 0.7983\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.76674 to 0.79834, saving model to weights0-2.hdf5\n",
      "Epoch 5/20\n",
      "11956/11956 [==============================] - 356s 30ms/step - loss: 0.4576 - categorical_accuracy: 0.8475 - val_loss: 0.5618 - val_categorical_accuracy: 0.8134\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.79834 to 0.81339, saving model to weights0-2.hdf5\n",
      "Epoch 6/20\n",
      "11956/11956 [==============================] - 354s 30ms/step - loss: 0.4072 - categorical_accuracy: 0.8636 - val_loss: 0.5150 - val_categorical_accuracy: 0.8299\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.81339 to 0.82995, saving model to weights0-2.hdf5\n",
      "Epoch 7/20\n",
      "11956/11956 [==============================] - 352s 29ms/step - loss: 0.3736 - categorical_accuracy: 0.8736 - val_loss: 0.5414 - val_categorical_accuracy: 0.8209\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.82995\n",
      "Epoch 8/20\n",
      "11956/11956 [==============================] - 350s 29ms/step - loss: 0.3480 - categorical_accuracy: 0.8807 - val_loss: 0.5304 - val_categorical_accuracy: 0.8277\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.82995\n",
      "Epoch 9/20\n",
      "11956/11956 [==============================] - 374s 31ms/step - loss: 0.3200 - categorical_accuracy: 0.8903 - val_loss: 0.5479 - val_categorical_accuracy: 0.8239\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.82995\n",
      "Epoch 10/20\n",
      "11956/11956 [==============================] - 360s 30ms/step - loss: 0.2956 - categorical_accuracy: 0.8999 - val_loss: 0.5624 - val_categorical_accuracy: 0.8262\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.82995\n",
      "Epoch 11/20\n",
      " 2592/11956 [=====>........................] - ETA: 4:42 - loss: 0.3691 - categorical_accuracy: 0.8704"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D, Flatten, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "df_medias = pd.DataFrame()\n",
    "for alt in range(0, 2):\n",
    "    str_alt = str(alt)\n",
    "    fold = 0\n",
    "    df_scores = pd.DataFrame()\n",
    "\n",
    "    print('\\n\\nAlternativa', alt+1, '-', alternativas[alt])\n",
    "    \n",
    "    for train_index, val_index in KFold(n_splits=10, random_state=42, shuffle=True).split(df):\n",
    "        str_fold = 'Fold ' + str(fold)\n",
    "        print()\n",
    "        print()\n",
    "        print('Alternativa ' + alternativas[alt], '-', str_fold + ':')\n",
    "        print('\\tDefinicao de valores de entrada e saida da rede...')\n",
    "\n",
    "        df_train = df.loc[train_index]\n",
    "        df_val = df.loc[val_index]\n",
    "\n",
    "            \n",
    "        sequences_train = tokenizer.texts_to_sequences(df_train['filtrado'])\n",
    "        sequences_val = tokenizer.texts_to_sequences(df_val['filtrado'])\n",
    "\n",
    "        x_train = pad_sequences(sequences_train, maxlen=limite_texto)\n",
    "        x_val = pad_sequences(sequences_val, maxlen=limite_texto)\n",
    "\n",
    "        y_train = lbArea.transform(df_train['DESCR_AREA'])\n",
    "        y_val = lbArea.transform(df_val['DESCR_AREA'])\n",
    "\n",
    "        print('\\tTreinamento da rede...')\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocabulario, dim_vetor, input_length=limite_texto, trainable=True,  weights=[embedding_matrix]))\n",
    "        \n",
    "        \n",
    "        if alt == 0:\n",
    "            model.add(GRU(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "            model.add(GRU(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "        else:\n",
    "            model.add(Conv1D(64, 7, activation='relu'))\n",
    "            model.add(MaxPooling1D(5))\n",
    "            model.add(Conv1D(32, 7, activation='relu'))\n",
    "            model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "            \n",
    "        model.add(Dense(y.shape[1], activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=['categorical_accuracy'])\n",
    "\n",
    "        checkpoint_filename = 'weights' + str_alt + '-' + str(fold) + '.hdf5'\n",
    "        checkpointer = ModelCheckpoint(filepath=checkpoint_filename, monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "        model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), verbose=1, shuffle=False, callbacks=[checkpointer])\n",
    "\n",
    "        print('\\n\\tAvaliacao do melhor modelo e registro dos scores...')\n",
    "        model.load_weights(checkpoint_filename)\n",
    "        y_val_pred = model.predict_classes(x_val, verbose=1)\n",
    "        y_val_i = [list(x).index(1) for x in y_val]\n",
    "        report = classification_report(y_val_i, y_val_pred, target_names=lbArea.classes_, output_dict = True)\n",
    "        for col in colunas_scores:\n",
    "            if col == 'accuracy':\n",
    "                f = report[col]\n",
    "            else:\n",
    "                f = report[col]['f1-score']\n",
    "            df_scores.loc[str_fold,col] = f\n",
    "        fold += 1\n",
    "    df_medias[alternativas[alt] + ' mean'] = df_scores.mean()\n",
    "    df_medias[alternativas[alt] + ' std'] = df_scores.std()\n",
    "df_medias.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias.T.to_csv('scores_excertos_filtrados.csv', encoding = 'Latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
