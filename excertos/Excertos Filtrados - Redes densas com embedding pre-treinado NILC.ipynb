{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>filtrado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>voto cuidar auto tomada conta especial instaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>voto cuidar auto solicitação congresso naciona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>relatório tratar embargo declaração opor exemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>voto relação outro processo judiciais tratar r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>voto relativo ato envolver senhor caber rememo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD          DESCR_AREA                                           filtrado\n",
       "0  1400    Responsabilidade  voto cuidar auto tomada conta especial instaur...\n",
       "1  1700   Finanças Públicas  voto cuidar auto solicitação congresso naciona...\n",
       "2  5700    Responsabilidade  relatório tratar embargo declaração opor exemp...\n",
       "3   284  Direito Processual  voto relação outro processo judiciais tratar r...\n",
       "4   298             Pessoal  voto relativo ato envolver senhor caber rememo..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/excertos_filtrados500.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22972 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 30000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado'].astype(str))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado'].astype(str))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 22972\n",
      "Encontrados no modelo: 19689 = 85.7086888385861\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:49:09.096304 140100677498688 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1125 18:49:09.121376 140100677498688 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 106,807,774\n",
      "Trainable params: 104,510,474\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 43s 4ms/step - loss: 2.5984 - categorical_accuracy: 0.3772 - val_loss: 1.6478 - val_categorical_accuracy: 0.3869\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 1.3890 - categorical_accuracy: 0.5486 - val_loss: 1.6817 - val_categorical_accuracy: 0.4099\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 1.1448 - categorical_accuracy: 0.6261 - val_loss: 1.5650 - val_categorical_accuracy: 0.4610\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.9693 - categorical_accuracy: 0.6850 - val_loss: 1.4165 - val_categorical_accuracy: 0.5521\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.8169 - categorical_accuracy: 0.7372 - val_loss: 1.3209 - val_categorical_accuracy: 0.5909\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.7446 - categorical_accuracy: 0.7721 - val_loss: 1.3531 - val_categorical_accuracy: 0.5630\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.6466 - categorical_accuracy: 0.8007 - val_loss: 1.5134 - val_categorical_accuracy: 0.5438\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.5600 - categorical_accuracy: 0.8335 - val_loss: 1.3765 - val_categorical_accuracy: 0.5721\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.5131 - categorical_accuracy: 0.8507 - val_loss: 1.6331 - val_categorical_accuracy: 0.5555\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.4681 - categorical_accuracy: 0.8589 - val_loss: 1.5152 - val_categorical_accuracy: 0.5661\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.4214 - categorical_accuracy: 0.8743 - val_loss: 1.5935 - val_categorical_accuracy: 0.5676\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.4189 - categorical_accuracy: 0.8832 - val_loss: 1.8278 - val_categorical_accuracy: 0.5070\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3603 - categorical_accuracy: 0.8995 - val_loss: 1.6254 - val_categorical_accuracy: 0.5137\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3659 - categorical_accuracy: 0.9011 - val_loss: 1.7083 - val_categorical_accuracy: 0.5533\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.3323 - categorical_accuracy: 0.9058 - val_loss: 1.6277 - val_categorical_accuracy: 0.5578\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 39s 4ms/step - loss: 0.3291 - categorical_accuracy: 0.9092 - val_loss: 1.6534 - val_categorical_accuracy: 0.5597\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.3112 - categorical_accuracy: 0.9149 - val_loss: 1.8283 - val_categorical_accuracy: 0.5303\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 40s 4ms/step - loss: 0.2820 - categorical_accuracy: 0.9288 - val_loss: 1.7486 - val_categorical_accuracy: 0.5578\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.3003 - categorical_accuracy: 0.9212 - val_loss: 1.8137 - val_categorical_accuracy: 0.5529\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 41s 4ms/step - loss: 0.2720 - categorical_accuracy: 0.9285 - val_loss: 1.6938 - val_categorical_accuracy: 0.5766\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:02:40.545113 140100677498688 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 106,807,774\n",
      "Trainable params: 106,807,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 44s 4ms/step - loss: 2.4981 - categorical_accuracy: 0.4134 - val_loss: 1.5371 - val_categorical_accuracy: 0.4001\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 1.2490 - categorical_accuracy: 0.5966 - val_loss: 1.5877 - val_categorical_accuracy: 0.4452\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.9852 - categorical_accuracy: 0.6903 - val_loss: 1.2858 - val_categorical_accuracy: 0.6071\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.7963 - categorical_accuracy: 0.7454 - val_loss: 1.2993 - val_categorical_accuracy: 0.6263\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.6555 - categorical_accuracy: 0.7978 - val_loss: 1.2410 - val_categorical_accuracy: 0.6161\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.5366 - categorical_accuracy: 0.8334 - val_loss: 1.3283 - val_categorical_accuracy: 0.6101\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.4819 - categorical_accuracy: 0.8588 - val_loss: 1.5844 - val_categorical_accuracy: 0.5548\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.4322 - categorical_accuracy: 0.8761 - val_loss: 1.3780 - val_categorical_accuracy: 0.6176\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.3871 - categorical_accuracy: 0.8940 - val_loss: 1.4318 - val_categorical_accuracy: 0.6139\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.3466 - categorical_accuracy: 0.9062 - val_loss: 1.4961 - val_categorical_accuracy: 0.6184\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.3219 - categorical_accuracy: 0.9144 - val_loss: 1.5443 - val_categorical_accuracy: 0.6063\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.3063 - categorical_accuracy: 0.9187 - val_loss: 1.5025 - val_categorical_accuracy: 0.6191\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2854 - categorical_accuracy: 0.9269 - val_loss: 1.4275 - val_categorical_accuracy: 0.6556\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2504 - categorical_accuracy: 0.9367 - val_loss: 1.4696 - val_categorical_accuracy: 0.6116\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2517 - categorical_accuracy: 0.9386 - val_loss: 1.5810 - val_categorical_accuracy: 0.6417\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2370 - categorical_accuracy: 0.9404 - val_loss: 1.5981 - val_categorical_accuracy: 0.6120\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2096 - categorical_accuracy: 0.9486 - val_loss: 1.5804 - val_categorical_accuracy: 0.6590\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2196 - categorical_accuracy: 0.9491 - val_loss: 1.7449 - val_categorical_accuracy: 0.6116\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.2017 - categorical_accuracy: 0.9539 - val_loss: 1.7618 - val_categorical_accuracy: 0.6489\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 42s 4ms/step - loss: 0.1846 - categorical_accuracy: 0.9584 - val_loss: 1.8138 - val_categorical_accuracy: 0.6361\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1125 21:36:30.174597 140418510731072 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1125 21:36:30.315871 140418510731072 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1125 21:36:30.317370 140418510731072 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1125 21:36:30.324594 140418510731072 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1125 21:36:30.325213 140418510731072 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1125 21:36:31.058864 140418510731072 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1125 21:36:31.102167 140418510731072 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1125 21:36:31.187025 140418510731072 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              51201024  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 54,028,254\n",
      "Trainable params: 51,730,954\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 1.7985 - categorical_accuracy: 0.4566 - val_loss: 1.7222 - val_categorical_accuracy: 0.3948\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 1.0913 - categorical_accuracy: 0.6407 - val_loss: 1.9397 - val_categorical_accuracy: 0.4027\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.8067 - categorical_accuracy: 0.7313 - val_loss: 1.2643 - val_categorical_accuracy: 0.6101\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.5856 - categorical_accuracy: 0.8073 - val_loss: 1.5303 - val_categorical_accuracy: 0.5356\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.4544 - categorical_accuracy: 0.8531 - val_loss: 1.3716 - val_categorical_accuracy: 0.6029\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.3436 - categorical_accuracy: 0.8901 - val_loss: 1.4470 - val_categorical_accuracy: 0.6248\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.2975 - categorical_accuracy: 0.9083 - val_loss: 1.5911 - val_categorical_accuracy: 0.6078\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.2468 - categorical_accuracy: 0.9255 - val_loss: 1.7176 - val_categorical_accuracy: 0.5804\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.2153 - categorical_accuracy: 0.9380 - val_loss: 1.5791 - val_categorical_accuracy: 0.5788\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.2014 - categorical_accuracy: 0.9441 - val_loss: 1.8980 - val_categorical_accuracy: 0.6229\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.1928 - categorical_accuracy: 0.9473 - val_loss: 1.8749 - val_categorical_accuracy: 0.5634\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.1735 - categorical_accuracy: 0.9520 - val_loss: 2.2147 - val_categorical_accuracy: 0.5649\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.1653 - categorical_accuracy: 0.9572 - val_loss: 2.1762 - val_categorical_accuracy: 0.5706\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.1575 - categorical_accuracy: 0.9602 - val_loss: 1.9642 - val_categorical_accuracy: 0.5913\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.1495 - categorical_accuracy: 0.9613 - val_loss: 2.0356 - val_categorical_accuracy: 0.5871\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 20s 2ms/step - loss: 0.1437 - categorical_accuracy: 0.9657 - val_loss: 1.9547 - val_categorical_accuracy: 0.5819\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1466 - categorical_accuracy: 0.9661 - val_loss: 2.0147 - val_categorical_accuracy: 0.5932\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1284 - categorical_accuracy: 0.9705 - val_loss: 1.8883 - val_categorical_accuracy: 0.5943\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1283 - categorical_accuracy: 0.9714 - val_loss: 2.3471 - val_categorical_accuracy: 0.5623\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1302 - categorical_accuracy: 0.9737 - val_loss: 2.4077 - val_categorical_accuracy: 0.5551\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              51201024  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 54,028,254\n",
      "Trainable params: 54,028,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 23s 2ms/step - loss: 1.7997 - categorical_accuracy: 0.4673 - val_loss: 1.8550 - val_categorical_accuracy: 0.3767\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.9830 - categorical_accuracy: 0.6737 - val_loss: 1.2810 - val_categorical_accuracy: 0.5819\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.6682 - categorical_accuracy: 0.7780 - val_loss: 1.2423 - val_categorical_accuracy: 0.6063\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.4747 - categorical_accuracy: 0.8419 - val_loss: 1.5780 - val_categorical_accuracy: 0.5280\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.3491 - categorical_accuracy: 0.8919 - val_loss: 1.5266 - val_categorical_accuracy: 0.5913\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.2715 - categorical_accuracy: 0.9189 - val_loss: 1.5437 - val_categorical_accuracy: 0.6233\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.2300 - categorical_accuracy: 0.9325 - val_loss: 1.5770 - val_categorical_accuracy: 0.6240\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1886 - categorical_accuracy: 0.9461 - val_loss: 1.8321 - val_categorical_accuracy: 0.6172\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1734 - categorical_accuracy: 0.9538 - val_loss: 1.6321 - val_categorical_accuracy: 0.6394\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1565 - categorical_accuracy: 0.9603 - val_loss: 1.8863 - val_categorical_accuracy: 0.6440\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1412 - categorical_accuracy: 0.9647 - val_loss: 1.8577 - val_categorical_accuracy: 0.6522\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1283 - categorical_accuracy: 0.9703 - val_loss: 1.8776 - val_categorical_accuracy: 0.6643\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1195 - categorical_accuracy: 0.9719 - val_loss: 1.8894 - val_categorical_accuracy: 0.6560\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1273 - categorical_accuracy: 0.9715 - val_loss: 2.3613 - val_categorical_accuracy: 0.6432\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1192 - categorical_accuracy: 0.9753 - val_loss: 1.6940 - val_categorical_accuracy: 0.6805\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1142 - categorical_accuracy: 0.9747 - val_loss: 1.7936 - val_categorical_accuracy: 0.6605\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1030 - categorical_accuracy: 0.9786 - val_loss: 2.0685 - val_categorical_accuracy: 0.6515\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1046 - categorical_accuracy: 0.9787 - val_loss: 2.0235 - val_categorical_accuracy: 0.6609\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.1006 - categorical_accuracy: 0.9802 - val_loss: 2.0432 - val_categorical_accuracy: 0.6492\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 0.0889 - categorical_accuracy: 0.9818 - val_loss: 2.1377 - val_categorical_accuracy: 0.6357\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              51201024  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 53,763,294\n",
      "Trainable params: 51,465,994\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 1.8052 - categorical_accuracy: 0.4381 - val_loss: 1.6188 - val_categorical_accuracy: 0.3895\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 1.0927 - categorical_accuracy: 0.6370 - val_loss: 1.4540 - val_categorical_accuracy: 0.5209\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.7375 - categorical_accuracy: 0.7558 - val_loss: 2.0159 - val_categorical_accuracy: 0.4388\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.5094 - categorical_accuracy: 0.8383 - val_loss: 1.7139 - val_categorical_accuracy: 0.4674\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.3644 - categorical_accuracy: 0.8901 - val_loss: 1.7203 - val_categorical_accuracy: 0.5337\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.2816 - categorical_accuracy: 0.9178 - val_loss: 1.4250 - val_categorical_accuracy: 0.6214\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.2352 - categorical_accuracy: 0.9344 - val_loss: 1.7886 - val_categorical_accuracy: 0.5845\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1867 - categorical_accuracy: 0.9468 - val_loss: 1.8446 - val_categorical_accuracy: 0.5947\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1724 - categorical_accuracy: 0.9551 - val_loss: 2.0190 - val_categorical_accuracy: 0.5668\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1575 - categorical_accuracy: 0.9573 - val_loss: 2.4199 - val_categorical_accuracy: 0.5502\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1472 - categorical_accuracy: 0.9651 - val_loss: 2.1461 - val_categorical_accuracy: 0.5612\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1339 - categorical_accuracy: 0.9675 - val_loss: 1.9352 - val_categorical_accuracy: 0.5932\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1313 - categorical_accuracy: 0.9686 - val_loss: 2.2019 - val_categorical_accuracy: 0.5747\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1308 - categorical_accuracy: 0.9730 - val_loss: 2.1615 - val_categorical_accuracy: 0.5804\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1133 - categorical_accuracy: 0.9751 - val_loss: 2.0422 - val_categorical_accuracy: 0.5875\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1158 - categorical_accuracy: 0.9754 - val_loss: 2.3238 - val_categorical_accuracy: 0.6165\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1111 - categorical_accuracy: 0.9777 - val_loss: 2.4988 - val_categorical_accuracy: 0.5653\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1104 - categorical_accuracy: 0.9782 - val_loss: 2.5567 - val_categorical_accuracy: 0.5676\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.1040 - categorical_accuracy: 0.9782 - val_loss: 2.4208 - val_categorical_accuracy: 0.5943\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 0.0950 - categorical_accuracy: 0.9812 - val_loss: 2.4102 - val_categorical_accuracy: 0.5743\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              51201024  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 53,763,294\n",
      "Trainable params: 53,763,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 22s 2ms/step - loss: 1.7960 - categorical_accuracy: 0.4661 - val_loss: 1.5014 - val_categorical_accuracy: 0.5194\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.9897 - categorical_accuracy: 0.6751 - val_loss: 1.1915 - val_categorical_accuracy: 0.6026\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.6679 - categorical_accuracy: 0.7838 - val_loss: 1.3308 - val_categorical_accuracy: 0.6101\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.4333 - categorical_accuracy: 0.8625 - val_loss: 1.2620 - val_categorical_accuracy: 0.6473\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.3162 - categorical_accuracy: 0.9037 - val_loss: 1.7036 - val_categorical_accuracy: 0.6157\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.2446 - categorical_accuracy: 0.9303 - val_loss: 1.5359 - val_categorical_accuracy: 0.6353\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1952 - categorical_accuracy: 0.9477 - val_loss: 1.6271 - val_categorical_accuracy: 0.6263\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1671 - categorical_accuracy: 0.9521 - val_loss: 1.7572 - val_categorical_accuracy: 0.6609\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1603 - categorical_accuracy: 0.9584 - val_loss: 1.7449 - val_categorical_accuracy: 0.6349\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1318 - categorical_accuracy: 0.9654 - val_loss: 1.7103 - val_categorical_accuracy: 0.6628\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1255 - categorical_accuracy: 0.9713 - val_loss: 1.9954 - val_categorical_accuracy: 0.6282\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1138 - categorical_accuracy: 0.9766 - val_loss: 1.9528 - val_categorical_accuracy: 0.6436\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1200 - categorical_accuracy: 0.9755 - val_loss: 2.1893 - val_categorical_accuracy: 0.6650\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1119 - categorical_accuracy: 0.9787 - val_loss: 2.0274 - val_categorical_accuracy: 0.6368\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1086 - categorical_accuracy: 0.9797 - val_loss: 2.2069 - val_categorical_accuracy: 0.6500\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0941 - categorical_accuracy: 0.9835 - val_loss: 2.1827 - val_categorical_accuracy: 0.6823\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.1119 - categorical_accuracy: 0.9807 - val_loss: 2.3336 - val_categorical_accuracy: 0.6537\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0991 - categorical_accuracy: 0.9816 - val_loss: 2.0979 - val_categorical_accuracy: 0.6733\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0924 - categorical_accuracy: 0.9839 - val_loss: 1.9932 - val_categorical_accuracy: 0.6647\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 21s 2ms/step - loss: 0.0984 - categorical_accuracy: 0.9840 - val_loss: 2.5910 - val_categorical_accuracy: 0.6240\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               25600512  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 28,031,710\n",
      "Trainable params: 25,734,410\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 1.7022 - categorical_accuracy: 0.4544 - val_loss: 1.7769 - val_categorical_accuracy: 0.3918\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 1.1471 - categorical_accuracy: 0.6181 - val_loss: 1.7893 - val_categorical_accuracy: 0.3986\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 10s 956us/step - loss: 0.8637 - categorical_accuracy: 0.7098 - val_loss: 1.6560 - val_categorical_accuracy: 0.4520\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.6681 - categorical_accuracy: 0.7708 - val_loss: 1.9144 - val_categorical_accuracy: 0.4821\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 10s 956us/step - loss: 0.5339 - categorical_accuracy: 0.8240 - val_loss: 1.5095 - val_categorical_accuracy: 0.5280\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 10s 955us/step - loss: 0.4401 - categorical_accuracy: 0.8559 - val_loss: 1.5882 - val_categorical_accuracy: 0.5397\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.3691 - categorical_accuracy: 0.8800 - val_loss: 1.5281 - val_categorical_accuracy: 0.6093\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.3162 - categorical_accuracy: 0.8986 - val_loss: 1.6459 - val_categorical_accuracy: 0.5928\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.2965 - categorical_accuracy: 0.9060 - val_loss: 1.8364 - val_categorical_accuracy: 0.5717\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.2524 - categorical_accuracy: 0.9171 - val_loss: 1.8095 - val_categorical_accuracy: 0.6044\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 10s 956us/step - loss: 0.2476 - categorical_accuracy: 0.9265 - val_loss: 1.8244 - val_categorical_accuracy: 0.5551\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 10s 956us/step - loss: 0.2240 - categorical_accuracy: 0.9309 - val_loss: 2.0346 - val_categorical_accuracy: 0.5864\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 10s 956us/step - loss: 0.1941 - categorical_accuracy: 0.9405 - val_loss: 2.0506 - val_categorical_accuracy: 0.5894\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1858 - categorical_accuracy: 0.9438 - val_loss: 1.7416 - val_categorical_accuracy: 0.5785\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 10s 956us/step - loss: 0.1905 - categorical_accuracy: 0.9467 - val_loss: 1.8991 - val_categorical_accuracy: 0.6029\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1759 - categorical_accuracy: 0.9506 - val_loss: 1.9544 - val_categorical_accuracy: 0.5544\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1548 - categorical_accuracy: 0.9552 - val_loss: 2.0074 - val_categorical_accuracy: 0.6033\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1489 - categorical_accuracy: 0.9583 - val_loss: 2.1914 - val_categorical_accuracy: 0.6214\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1435 - categorical_accuracy: 0.9620 - val_loss: 2.2945 - val_categorical_accuracy: 0.5706\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1404 - categorical_accuracy: 0.9605 - val_loss: 2.5260 - val_categorical_accuracy: 0.5510\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               25600512  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 28,031,710\n",
      "Trainable params: 28,031,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 1.6880 - categorical_accuracy: 0.4610 - val_loss: 1.6167 - val_categorical_accuracy: 0.4035\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 1.0579 - categorical_accuracy: 0.6520 - val_loss: 1.6429 - val_categorical_accuracy: 0.4415\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.7760 - categorical_accuracy: 0.7376 - val_loss: 1.2746 - val_categorical_accuracy: 0.6037\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.5787 - categorical_accuracy: 0.8081 - val_loss: 1.2122 - val_categorical_accuracy: 0.6428\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.4485 - categorical_accuracy: 0.8525 - val_loss: 1.4167 - val_categorical_accuracy: 0.6297\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.3616 - categorical_accuracy: 0.8841 - val_loss: 1.3771 - val_categorical_accuracy: 0.6409\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.3165 - categorical_accuracy: 0.9021 - val_loss: 1.6808 - val_categorical_accuracy: 0.6048\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2826 - categorical_accuracy: 0.9138 - val_loss: 1.4669 - val_categorical_accuracy: 0.6259\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2329 - categorical_accuracy: 0.9308 - val_loss: 1.6461 - val_categorical_accuracy: 0.6387\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2070 - categorical_accuracy: 0.9404 - val_loss: 1.7042 - val_categorical_accuracy: 0.6240\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2016 - categorical_accuracy: 0.9437 - val_loss: 1.7398 - val_categorical_accuracy: 0.6255\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1795 - categorical_accuracy: 0.9489 - val_loss: 1.6991 - val_categorical_accuracy: 0.6259\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1632 - categorical_accuracy: 0.9548 - val_loss: 2.6074 - val_categorical_accuracy: 0.6022\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1503 - categorical_accuracy: 0.9623 - val_loss: 1.8411 - val_categorical_accuracy: 0.6323\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1464 - categorical_accuracy: 0.9617 - val_loss: 1.7803 - val_categorical_accuracy: 0.6496\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1388 - categorical_accuracy: 0.9656 - val_loss: 1.9449 - val_categorical_accuracy: 0.6323\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1256 - categorical_accuracy: 0.9695 - val_loss: 1.8698 - val_categorical_accuracy: 0.6662\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1200 - categorical_accuracy: 0.9705 - val_loss: 2.2852 - val_categorical_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1166 - categorical_accuracy: 0.9707 - val_loss: 2.0306 - val_categorical_accuracy: 0.6398\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1127 - categorical_accuracy: 0.9736 - val_loss: 2.1562 - val_categorical_accuracy: 0.6568\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               25600512  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 27,964,766\n",
      "Trainable params: 25,667,466\n",
      "Non-trainable params: 2,297,300\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 1.7884 - categorical_accuracy: 0.4332 - val_loss: 1.4831 - val_categorical_accuracy: 0.4539\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 10s 959us/step - loss: 1.2032 - categorical_accuracy: 0.5938 - val_loss: 2.0711 - val_categorical_accuracy: 0.3628\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 10s 959us/step - loss: 0.9351 - categorical_accuracy: 0.6824 - val_loss: 1.6042 - val_categorical_accuracy: 0.5043\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.7201 - categorical_accuracy: 0.7610 - val_loss: 1.5319 - val_categorical_accuracy: 0.5363\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.5479 - categorical_accuracy: 0.8163 - val_loss: 1.4003 - val_categorical_accuracy: 0.5920\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.4525 - categorical_accuracy: 0.8585 - val_loss: 1.6702 - val_categorical_accuracy: 0.5566\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 10s 960us/step - loss: 0.3788 - categorical_accuracy: 0.8780 - val_loss: 1.6392 - val_categorical_accuracy: 0.5947\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.3347 - categorical_accuracy: 0.8929 - val_loss: 1.5191 - val_categorical_accuracy: 0.5770\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.2997 - categorical_accuracy: 0.9071 - val_loss: 1.8267 - val_categorical_accuracy: 0.5958\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.2592 - categorical_accuracy: 0.9203 - val_loss: 2.0351 - val_categorical_accuracy: 0.5585\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.2448 - categorical_accuracy: 0.9273 - val_loss: 1.8906 - val_categorical_accuracy: 0.5762\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.2255 - categorical_accuracy: 0.9323 - val_loss: 1.9560 - val_categorical_accuracy: 0.5807\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.2051 - categorical_accuracy: 0.9362 - val_loss: 2.0755 - val_categorical_accuracy: 0.6018\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.1920 - categorical_accuracy: 0.9417 - val_loss: 2.1147 - val_categorical_accuracy: 0.5533\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.1820 - categorical_accuracy: 0.9467 - val_loss: 2.0874 - val_categorical_accuracy: 0.5916\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1733 - categorical_accuracy: 0.9455 - val_loss: 2.2934 - val_categorical_accuracy: 0.5694\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 10s 957us/step - loss: 0.1728 - categorical_accuracy: 0.9498 - val_loss: 2.4315 - val_categorical_accuracy: 0.5687\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.1578 - categorical_accuracy: 0.9539 - val_loss: 2.2966 - val_categorical_accuracy: 0.5811\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 10s 959us/step - loss: 0.1647 - categorical_accuracy: 0.9541 - val_loss: 2.5060 - val_categorical_accuracy: 0.5796\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 10s 958us/step - loss: 0.1646 - categorical_accuracy: 0.9556 - val_loss: 2.3534 - val_categorical_accuracy: 0.5627\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               25600512  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 27,964,766\n",
      "Trainable params: 27,964,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 12s 1ms/step - loss: 1.6766 - categorical_accuracy: 0.4644 - val_loss: 1.5069 - val_categorical_accuracy: 0.3986\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 1.0860 - categorical_accuracy: 0.6403 - val_loss: 1.4249 - val_categorical_accuracy: 0.5333\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.7930 - categorical_accuracy: 0.7360 - val_loss: 1.2679 - val_categorical_accuracy: 0.6202\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.5532 - categorical_accuracy: 0.8205 - val_loss: 1.2241 - val_categorical_accuracy: 0.6432\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.4385 - categorical_accuracy: 0.8619 - val_loss: 1.2532 - val_categorical_accuracy: 0.6462\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.3437 - categorical_accuracy: 0.8891 - val_loss: 1.3303 - val_categorical_accuracy: 0.6312\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2946 - categorical_accuracy: 0.9108 - val_loss: 1.3612 - val_categorical_accuracy: 0.6530\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2323 - categorical_accuracy: 0.9301 - val_loss: 1.6024 - val_categorical_accuracy: 0.6330\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.2196 - categorical_accuracy: 0.9340 - val_loss: 1.5877 - val_categorical_accuracy: 0.6041\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1909 - categorical_accuracy: 0.9438 - val_loss: 1.8194 - val_categorical_accuracy: 0.6541\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1693 - categorical_accuracy: 0.9503 - val_loss: 1.6332 - val_categorical_accuracy: 0.6620\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1585 - categorical_accuracy: 0.9552 - val_loss: 1.8296 - val_categorical_accuracy: 0.6425\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1559 - categorical_accuracy: 0.9600 - val_loss: 1.9870 - val_categorical_accuracy: 0.6165\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1401 - categorical_accuracy: 0.9615 - val_loss: 1.8547 - val_categorical_accuracy: 0.6364\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1297 - categorical_accuracy: 0.9651 - val_loss: 1.9057 - val_categorical_accuracy: 0.6387\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1153 - categorical_accuracy: 0.9692 - val_loss: 1.9239 - val_categorical_accuracy: 0.6477\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1244 - categorical_accuracy: 0.9679 - val_loss: 1.8169 - val_categorical_accuracy: 0.6658\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1186 - categorical_accuracy: 0.9710 - val_loss: 2.0652 - val_categorical_accuracy: 0.6553\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1199 - categorical_accuracy: 0.9714 - val_loss: 2.0379 - val_categorical_accuracy: 0.6394\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 11s 1ms/step - loss: 0.1095 - categorical_accuracy: 0.9729 - val_loss: 2.0721 - val_categorical_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               12800256  \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,131,742\n",
      "Trainable params: 15,131,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 8s 729us/step - loss: 1.6573 - categorical_accuracy: 0.4612 - val_loss: 1.4545 - val_categorical_accuracy: 0.5160\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 1.1453 - categorical_accuracy: 0.6199 - val_loss: 1.2522 - val_categorical_accuracy: 0.6059\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.9310 - categorical_accuracy: 0.6776 - val_loss: 1.2808 - val_categorical_accuracy: 0.6139\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.7734 - categorical_accuracy: 0.7391 - val_loss: 1.2997 - val_categorical_accuracy: 0.6093\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.6509 - categorical_accuracy: 0.7798 - val_loss: 1.2896 - val_categorical_accuracy: 0.6338\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.5690 - categorical_accuracy: 0.8117 - val_loss: 1.3369 - val_categorical_accuracy: 0.6165\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.4892 - categorical_accuracy: 0.8432 - val_loss: 1.4084 - val_categorical_accuracy: 0.6330\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.4424 - categorical_accuracy: 0.8576 - val_loss: 1.5161 - val_categorical_accuracy: 0.6319\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.3895 - categorical_accuracy: 0.8777 - val_loss: 1.5560 - val_categorical_accuracy: 0.6199\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.3590 - categorical_accuracy: 0.8881 - val_loss: 1.5079 - val_categorical_accuracy: 0.6082\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.3316 - categorical_accuracy: 0.8963 - val_loss: 1.6304 - val_categorical_accuracy: 0.6413\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.3069 - categorical_accuracy: 0.9062 - val_loss: 1.5830 - val_categorical_accuracy: 0.6270\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2746 - categorical_accuracy: 0.9132 - val_loss: 1.7976 - val_categorical_accuracy: 0.6270\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2748 - categorical_accuracy: 0.9187 - val_loss: 1.7819 - val_categorical_accuracy: 0.6120\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.2566 - categorical_accuracy: 0.9218 - val_loss: 1.8254 - val_categorical_accuracy: 0.6553\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.2393 - categorical_accuracy: 0.9291 - val_loss: 2.3403 - val_categorical_accuracy: 0.6346\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2244 - categorical_accuracy: 0.9302 - val_loss: 1.9704 - val_categorical_accuracy: 0.6391\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.2202 - categorical_accuracy: 0.9281 - val_loss: 1.9276 - val_categorical_accuracy: 0.6451\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.2113 - categorical_accuracy: 0.9356 - val_loss: 1.9750 - val_categorical_accuracy: 0.6308\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.2043 - categorical_accuracy: 0.9426 - val_loss: 1.9578 - val_categorical_accuracy: 0.6801\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 500, 100)          2297300   \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               12800256  \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 15,114,654\n",
      "Trainable params: 15,114,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 8s 735us/step - loss: 1.7661 - categorical_accuracy: 0.4178 - val_loss: 1.6087 - val_categorical_accuracy: 0.4129\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 1.2350 - categorical_accuracy: 0.5892 - val_loss: 1.3051 - val_categorical_accuracy: 0.5898\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 7s 634us/step - loss: 0.9679 - categorical_accuracy: 0.6775 - val_loss: 1.2671 - val_categorical_accuracy: 0.5901\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.7622 - categorical_accuracy: 0.7451 - val_loss: 1.3831 - val_categorical_accuracy: 0.5958\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.6437 - categorical_accuracy: 0.7920 - val_loss: 1.4182 - val_categorical_accuracy: 0.6165\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.5412 - categorical_accuracy: 0.8250 - val_loss: 1.3639 - val_categorical_accuracy: 0.6432\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 7s 635us/step - loss: 0.4566 - categorical_accuracy: 0.8502 - val_loss: 1.5932 - val_categorical_accuracy: 0.6398\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 7s 635us/step - loss: 0.3970 - categorical_accuracy: 0.8718 - val_loss: 1.4957 - val_categorical_accuracy: 0.6233\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.3483 - categorical_accuracy: 0.8870 - val_loss: 1.4574 - val_categorical_accuracy: 0.6270\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.3326 - categorical_accuracy: 0.8903 - val_loss: 1.4791 - val_categorical_accuracy: 0.6481\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.3083 - categorical_accuracy: 0.8997 - val_loss: 1.8447 - val_categorical_accuracy: 0.6425\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2695 - categorical_accuracy: 0.9131 - val_loss: 1.5886 - val_categorical_accuracy: 0.6598\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.2665 - categorical_accuracy: 0.9146 - val_loss: 1.6803 - val_categorical_accuracy: 0.6530\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2405 - categorical_accuracy: 0.9227 - val_loss: 1.6094 - val_categorical_accuracy: 0.6680\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.2307 - categorical_accuracy: 0.9278 - val_loss: 1.7819 - val_categorical_accuracy: 0.6549\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.2166 - categorical_accuracy: 0.9332 - val_loss: 1.9429 - val_categorical_accuracy: 0.6620\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2095 - categorical_accuracy: 0.9356 - val_loss: 1.9226 - val_categorical_accuracy: 0.6688\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.1880 - categorical_accuracy: 0.9401 - val_loss: 1.8920 - val_categorical_accuracy: 0.6398\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.1827 - categorical_accuracy: 0.9446 - val_loss: 2.1416 - val_categorical_accuracy: 0.6293\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.1855 - categorical_accuracy: 0.9425 - val_loss: 2.0098 - val_categorical_accuracy: 0.6522\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
