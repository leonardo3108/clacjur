{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_EXCERTO</th>\n",
       "      <th>TEXTO_EXCERTO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995438</td>\n",
       "      <td>Voto:Cuidam os autos de tomada de contas espec...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025603</td>\n",
       "      <td>Voto:Cuidam os autos de Solicitação do Congres...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455375</td>\n",
       "      <td>Relatório:Trata-se de embargos de declaração o...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773747</td>\n",
       "      <td>Voto:8. Em relação a outros processos judiciai...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773403</td>\n",
       "      <td>Voto:11. Relativamente ao ato envolvendo a Sra...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_EXCERTO  \\\n",
       "0  Benefício previdenciário                    54995438   \n",
       "1                  Petróleo                    55025603   \n",
       "2                Dosimetria                    55455375   \n",
       "3          Decisão judicial                    54773747   \n",
       "4                 Nepotismo                    54773403   \n",
       "\n",
       "                                       TEXTO_EXCERTO                ACORDAO  \\\n",
       "0  Voto:Cuidam os autos de tomada de contas espec...  Acórdão 297/2016 - PL   \n",
       "1  Voto:Cuidam os autos de Solicitação do Congres...  Acórdão 366/2016 - PL   \n",
       "2  Relatório:Trata-se de embargos de declaração o...  Acórdão 944/2016 - PL   \n",
       "3  Voto:8. Em relação a outros processos judiciai...   Acórdão 30/2016 - PL   \n",
       "4  Voto:11. Relativamente ao ato envolvendo a Sra...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_excertos.CSV', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13285, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63925 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 70000\n",
    "limite_texto = 2000\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['TEXTO_EXCERTO'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_EXCERTO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13285, 2000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 63925\n",
      "Encontrados no modelo: 43317 = 67.76222135314822\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13285, 2000), (13285, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 11:23:28.170205 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1201 11:23:28.245075 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1201 11:23:28.247084 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1201 11:23:28.257300 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1201 11:23:28.258102 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1201 11:23:29.664319 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1201 11:23:29.709689 140521584768832 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1201 11:23:29.810900 140521584768832 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1994, 32)          22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 398, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 392, 32)           7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 6,422,562\n",
      "Trainable params: 29,962\n",
      "Non-trainable params: 6,392,600\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 4s 390us/step - loss: 1.2929 - categorical_accuracy: 0.5890 - val_loss: 1.9926 - val_categorical_accuracy: 0.4166\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 3s 263us/step - loss: 0.8268 - categorical_accuracy: 0.7224 - val_loss: 1.3946 - val_categorical_accuracy: 0.5032\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 3s 258us/step - loss: 0.6573 - categorical_accuracy: 0.7791 - val_loss: 1.1344 - val_categorical_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 3s 252us/step - loss: 0.5433 - categorical_accuracy: 0.8138 - val_loss: 1.0427 - val_categorical_accuracy: 0.6635\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 3s 257us/step - loss: 0.4403 - categorical_accuracy: 0.8471 - val_loss: 1.1711 - val_categorical_accuracy: 0.6191\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 3s 253us/step - loss: 0.3592 - categorical_accuracy: 0.8788 - val_loss: 1.6162 - val_categorical_accuracy: 0.5725\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 3s 245us/step - loss: 0.3052 - categorical_accuracy: 0.8967 - val_loss: 1.5675 - val_categorical_accuracy: 0.5476\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 3s 257us/step - loss: 0.2508 - categorical_accuracy: 0.9165 - val_loss: 2.0802 - val_categorical_accuracy: 0.5382\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 3s 244us/step - loss: 0.2117 - categorical_accuracy: 0.9291 - val_loss: 1.1918 - val_categorical_accuracy: 0.6665\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 3s 254us/step - loss: 0.1719 - categorical_accuracy: 0.9452 - val_loss: 2.3930 - val_categorical_accuracy: 0.5886\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 3s 244us/step - loss: 0.1526 - categorical_accuracy: 0.9490 - val_loss: 1.4189 - val_categorical_accuracy: 0.6537\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 3s 247us/step - loss: 0.1351 - categorical_accuracy: 0.9605 - val_loss: 1.6042 - val_categorical_accuracy: 0.6481\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 3s 257us/step - loss: 0.1244 - categorical_accuracy: 0.9626 - val_loss: 1.7555 - val_categorical_accuracy: 0.6722\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 3s 262us/step - loss: 0.1127 - categorical_accuracy: 0.9669 - val_loss: 2.3465 - val_categorical_accuracy: 0.5728\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 3s 249us/step - loss: 0.1049 - categorical_accuracy: 0.9689 - val_loss: 2.4593 - val_categorical_accuracy: 0.5630\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 3s 267us/step - loss: 0.0972 - categorical_accuracy: 0.9696 - val_loss: 1.7472 - val_categorical_accuracy: 0.6744\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 3s 251us/step - loss: 0.1044 - categorical_accuracy: 0.9690 - val_loss: 1.6517 - val_categorical_accuracy: 0.6519\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 3s 255us/step - loss: 0.0927 - categorical_accuracy: 0.9734 - val_loss: 2.0288 - val_categorical_accuracy: 0.6338\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 3s 276us/step - loss: 0.0940 - categorical_accuracy: 0.9743 - val_loss: 1.9925 - val_categorical_accuracy: 0.6594\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 3s 255us/step - loss: 0.0867 - categorical_accuracy: 0.9760 - val_loss: 1.9113 - val_categorical_accuracy: 0.6586\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1994, 32)          22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 398, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 392, 32)           7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 6,422,562\n",
      "Trainable params: 6,422,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 6s 557us/step - loss: 1.2649 - categorical_accuracy: 0.6027 - val_loss: 1.4161 - val_categorical_accuracy: 0.5732\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 6s 526us/step - loss: 0.8058 - categorical_accuracy: 0.7323 - val_loss: 1.1480 - val_categorical_accuracy: 0.6026\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 5s 512us/step - loss: 0.6246 - categorical_accuracy: 0.7933 - val_loss: 1.6856 - val_categorical_accuracy: 0.4460\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 6s 521us/step - loss: 0.5059 - categorical_accuracy: 0.8285 - val_loss: 1.3665 - val_categorical_accuracy: 0.6300\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 5s 507us/step - loss: 0.3940 - categorical_accuracy: 0.8683 - val_loss: 1.1699 - val_categorical_accuracy: 0.6669\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 5s 517us/step - loss: 0.3031 - categorical_accuracy: 0.9001 - val_loss: 1.5360 - val_categorical_accuracy: 0.5804\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 5s 510us/step - loss: 0.2349 - categorical_accuracy: 0.9254 - val_loss: 1.1217 - val_categorical_accuracy: 0.7057\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 5s 507us/step - loss: 0.1818 - categorical_accuracy: 0.9410 - val_loss: 1.7302 - val_categorical_accuracy: 0.6571\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 5s 515us/step - loss: 0.1434 - categorical_accuracy: 0.9575 - val_loss: 1.6779 - val_categorical_accuracy: 0.6330\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 5s 510us/step - loss: 0.1129 - categorical_accuracy: 0.9671 - val_loss: 1.2853 - val_categorical_accuracy: 0.7023\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 5s 513us/step - loss: 0.0978 - categorical_accuracy: 0.9716 - val_loss: 1.3460 - val_categorical_accuracy: 0.7012\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 5s 517us/step - loss: 0.0942 - categorical_accuracy: 0.9764 - val_loss: 1.4293 - val_categorical_accuracy: 0.6921\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 5s 508us/step - loss: 0.0813 - categorical_accuracy: 0.9800 - val_loss: 1.4881 - val_categorical_accuracy: 0.6831\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 6s 518us/step - loss: 0.0785 - categorical_accuracy: 0.9806 - val_loss: 1.5617 - val_categorical_accuracy: 0.7076\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 5s 511us/step - loss: 0.0728 - categorical_accuracy: 0.9839 - val_loss: 1.5035 - val_categorical_accuracy: 0.7076\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 5s 507us/step - loss: 0.0813 - categorical_accuracy: 0.9822 - val_loss: 2.2239 - val_categorical_accuracy: 0.5935\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 6s 519us/step - loss: 0.0694 - categorical_accuracy: 0.9846 - val_loss: 1.7072 - val_categorical_accuracy: 0.6872\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 5s 515us/step - loss: 0.0710 - categorical_accuracy: 0.9851 - val_loss: 1.6284 - val_categorical_accuracy: 0.6910\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 5s 511us/step - loss: 0.0746 - categorical_accuracy: 0.9857 - val_loss: 1.6278 - val_categorical_accuracy: 0.6963\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 5s 506us/step - loss: 0.0749 - categorical_accuracy: 0.9850 - val_loss: 1.5831 - val_categorical_accuracy: 0.7053\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1994, 64)          44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 398, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 392, 32)           14368     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 6,452,162\n",
      "Trainable params: 6,452,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 7s 696us/step - loss: 1.2979 - categorical_accuracy: 0.6016 - val_loss: 1.2556 - val_categorical_accuracy: 0.5777\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.7784 - categorical_accuracy: 0.7439 - val_loss: 1.1208 - val_categorical_accuracy: 0.6417\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 7s 639us/step - loss: 0.5845 - categorical_accuracy: 0.8064 - val_loss: 1.2349 - val_categorical_accuracy: 0.6082\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 7s 632us/step - loss: 0.4361 - categorical_accuracy: 0.8538 - val_loss: 1.0945 - val_categorical_accuracy: 0.6869\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 7s 636us/step - loss: 0.3270 - categorical_accuracy: 0.8906 - val_loss: 1.4020 - val_categorical_accuracy: 0.5826\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 7s 637us/step - loss: 0.2336 - categorical_accuracy: 0.9226 - val_loss: 1.4763 - val_categorical_accuracy: 0.6801\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 7s 645us/step - loss: 0.1766 - categorical_accuracy: 0.9435 - val_loss: 1.2474 - val_categorical_accuracy: 0.6692\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 7s 653us/step - loss: 0.1396 - categorical_accuracy: 0.9583 - val_loss: 1.7872 - val_categorical_accuracy: 0.6011\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 7s 650us/step - loss: 0.1154 - categorical_accuracy: 0.9693 - val_loss: 1.3718 - val_categorical_accuracy: 0.6989\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 7s 639us/step - loss: 0.1052 - categorical_accuracy: 0.9725 - val_loss: 1.4644 - val_categorical_accuracy: 0.6707\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 7s 644us/step - loss: 0.0965 - categorical_accuracy: 0.9765 - val_loss: 1.5712 - val_categorical_accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 7s 638us/step - loss: 0.0913 - categorical_accuracy: 0.9785 - val_loss: 1.6704 - val_categorical_accuracy: 0.6711\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 7s 639us/step - loss: 0.0848 - categorical_accuracy: 0.9825 - val_loss: 1.9932 - val_categorical_accuracy: 0.6545\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 7s 639us/step - loss: 0.0862 - categorical_accuracy: 0.9817 - val_loss: 1.6622 - val_categorical_accuracy: 0.6903\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 7s 642us/step - loss: 0.0969 - categorical_accuracy: 0.9817 - val_loss: 1.6997 - val_categorical_accuracy: 0.6775\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 7s 645us/step - loss: 0.0856 - categorical_accuracy: 0.9818 - val_loss: 1.8803 - val_categorical_accuracy: 0.6865\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 7s 652us/step - loss: 0.0926 - categorical_accuracy: 0.9841 - val_loss: 1.6750 - val_categorical_accuracy: 0.7132\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 7s 657us/step - loss: 0.0841 - categorical_accuracy: 0.9835 - val_loss: 2.1411 - val_categorical_accuracy: 0.6590\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 7s 656us/step - loss: 0.0839 - categorical_accuracy: 0.9850 - val_loss: 2.0595 - val_categorical_accuracy: 0.6492\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 7s 664us/step - loss: 0.0858 - categorical_accuracy: 0.9861 - val_loss: 2.1382 - val_categorical_accuracy: 0.6647\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1201 11:28:34.606268 140521584768832 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1994, 32)          22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 398, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 392, 32)           7200      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 6,646,754\n",
      "Trainable params: 6,646,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 190s 18ms/step - loss: 1.2584 - categorical_accuracy: 0.5840 - val_loss: 1.6753 - val_categorical_accuracy: 0.4204\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 174s 16ms/step - loss: 0.8500 - categorical_accuracy: 0.7138 - val_loss: 1.0604 - val_categorical_accuracy: 0.6519\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 183s 17ms/step - loss: 0.7033 - categorical_accuracy: 0.7586 - val_loss: 0.9734 - val_categorical_accuracy: 0.6771\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 178s 17ms/step - loss: 0.5975 - categorical_accuracy: 0.7971 - val_loss: 1.4800 - val_categorical_accuracy: 0.4998\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 186s 18ms/step - loss: 0.5159 - categorical_accuracy: 0.8229 - val_loss: 0.9371 - val_categorical_accuracy: 0.7121\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 289s 27ms/step - loss: 0.4443 - categorical_accuracy: 0.8497 - val_loss: 1.1047 - val_categorical_accuracy: 0.6327\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 261s 25ms/step - loss: 0.3894 - categorical_accuracy: 0.8693 - val_loss: 0.9681 - val_categorical_accuracy: 0.6752\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 245s 23ms/step - loss: 0.3368 - categorical_accuracy: 0.8833 - val_loss: 1.0569 - val_categorical_accuracy: 0.6744\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 263s 25ms/step - loss: 0.2961 - categorical_accuracy: 0.8985 - val_loss: 1.0000 - val_categorical_accuracy: 0.7155\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 289s 27ms/step - loss: 0.2534 - categorical_accuracy: 0.9123 - val_loss: 0.9708 - val_categorical_accuracy: 0.7177\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 331s 31ms/step - loss: 0.2131 - categorical_accuracy: 0.9269 - val_loss: 1.0033 - val_categorical_accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 261s 25ms/step - loss: 0.1855 - categorical_accuracy: 0.9389 - val_loss: 1.0497 - val_categorical_accuracy: 0.7102\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 280s 26ms/step - loss: 0.1582 - categorical_accuracy: 0.9488 - val_loss: 1.3858 - val_categorical_accuracy: 0.6737\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 274s 26ms/step - loss: 0.1359 - categorical_accuracy: 0.9541 - val_loss: 1.2046 - val_categorical_accuracy: 0.7072\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 237s 22ms/step - loss: 0.1311 - categorical_accuracy: 0.9537 - val_loss: 1.1985 - val_categorical_accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 237s 22ms/step - loss: 0.1331 - categorical_accuracy: 0.9554 - val_loss: 1.2021 - val_categorical_accuracy: 0.7211\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 326s 31ms/step - loss: 0.1052 - categorical_accuracy: 0.9634 - val_loss: 1.1438 - val_categorical_accuracy: 0.7317\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 397s 37ms/step - loss: 0.1039 - categorical_accuracy: 0.9681 - val_loss: 1.2127 - val_categorical_accuracy: 0.7286\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 240s 23ms/step - loss: 0.0989 - categorical_accuracy: 0.9679 - val_loss: 1.2564 - val_categorical_accuracy: 0.7241\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 145s 14ms/step - loss: 0.0909 - categorical_accuracy: 0.9697 - val_loss: 1.2812 - val_categorical_accuracy: 0.7294\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1994, 32)          22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 398, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 392, 32)           7200      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               61824     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 6,485,346\n",
      "Trainable params: 6,485,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 143s 13ms/step - loss: 1.2403 - categorical_accuracy: 0.5920 - val_loss: 1.2266 - val_categorical_accuracy: 0.5969\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 141s 13ms/step - loss: 0.8456 - categorical_accuracy: 0.7156 - val_loss: 1.3001 - val_categorical_accuracy: 0.5781\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 135s 13ms/step - loss: 0.6982 - categorical_accuracy: 0.7651 - val_loss: 1.4597 - val_categorical_accuracy: 0.5581\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 131s 12ms/step - loss: 0.6062 - categorical_accuracy: 0.7964 - val_loss: 1.0991 - val_categorical_accuracy: 0.6466\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 131s 12ms/step - loss: 0.5231 - categorical_accuracy: 0.8234 - val_loss: 0.9290 - val_categorical_accuracy: 0.6948\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 131s 12ms/step - loss: 0.4625 - categorical_accuracy: 0.8435 - val_loss: 0.8349 - val_categorical_accuracy: 0.7170\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 136s 13ms/step - loss: 0.4052 - categorical_accuracy: 0.8623 - val_loss: 1.0485 - val_categorical_accuracy: 0.6669\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 142s 13ms/step - loss: 0.3560 - categorical_accuracy: 0.8780 - val_loss: 0.9618 - val_categorical_accuracy: 0.6993\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 143s 13ms/step - loss: 0.3145 - categorical_accuracy: 0.8953 - val_loss: 0.8365 - val_categorical_accuracy: 0.7429\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 140s 13ms/step - loss: 0.2754 - categorical_accuracy: 0.9110 - val_loss: 0.8823 - val_categorical_accuracy: 0.7437\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.2399 - categorical_accuracy: 0.9197 - val_loss: 1.0741 - val_categorical_accuracy: 0.6903\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.2086 - categorical_accuracy: 0.9315 - val_loss: 0.9116 - val_categorical_accuracy: 0.7452\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1774 - categorical_accuracy: 0.9418 - val_loss: 0.9294 - val_categorical_accuracy: 0.7576\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1552 - categorical_accuracy: 0.9491 - val_loss: 0.9224 - val_categorical_accuracy: 0.7584\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1312 - categorical_accuracy: 0.9568 - val_loss: 1.2441 - val_categorical_accuracy: 0.6929\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1256 - categorical_accuracy: 0.9576 - val_loss: 1.4489 - val_categorical_accuracy: 0.6583\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1083 - categorical_accuracy: 0.9647 - val_loss: 1.0886 - val_categorical_accuracy: 0.7426\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0983 - categorical_accuracy: 0.9695 - val_loss: 1.1688 - val_categorical_accuracy: 0.7561\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0919 - categorical_accuracy: 0.9705 - val_loss: 1.0859 - val_categorical_accuracy: 0.7640\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0797 - categorical_accuracy: 0.9747 - val_loss: 1.1508 - val_categorical_accuracy: 0.7429\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 1994, 64)          44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 398, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 392, 32)           14368     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 256)               221952    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 6,676,354\n",
      "Trainable params: 6,676,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 133s 13ms/step - loss: 1.2784 - categorical_accuracy: 0.5688 - val_loss: 2.0962 - val_categorical_accuracy: 0.4106\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.8601 - categorical_accuracy: 0.7065 - val_loss: 0.9599 - val_categorical_accuracy: 0.6936\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.6878 - categorical_accuracy: 0.7679 - val_loss: 1.1942 - val_categorical_accuracy: 0.5883\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.5757 - categorical_accuracy: 0.8061 - val_loss: 1.1904 - val_categorical_accuracy: 0.6033\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.4992 - categorical_accuracy: 0.8312 - val_loss: 0.7914 - val_categorical_accuracy: 0.7576\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.4136 - categorical_accuracy: 0.8591 - val_loss: 0.8523 - val_categorical_accuracy: 0.7429\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.3374 - categorical_accuracy: 0.8877 - val_loss: 1.0628 - val_categorical_accuracy: 0.7030\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.2848 - categorical_accuracy: 0.9056 - val_loss: 1.1839 - val_categorical_accuracy: 0.6571\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.2251 - categorical_accuracy: 0.9249 - val_loss: 0.9896 - val_categorical_accuracy: 0.7268\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1862 - categorical_accuracy: 0.9390 - val_loss: 0.9689 - val_categorical_accuracy: 0.7580\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 133s 12ms/step - loss: 0.1604 - categorical_accuracy: 0.9463 - val_loss: 1.1747 - val_categorical_accuracy: 0.7061\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1307 - categorical_accuracy: 0.9557 - val_loss: 1.2373 - val_categorical_accuracy: 0.7520\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.1162 - categorical_accuracy: 0.9594 - val_loss: 1.1179 - val_categorical_accuracy: 0.7467\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0994 - categorical_accuracy: 0.9661 - val_loss: 1.1625 - val_categorical_accuracy: 0.7358\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0993 - categorical_accuracy: 0.9681 - val_loss: 1.2342 - val_categorical_accuracy: 0.7505\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0826 - categorical_accuracy: 0.9726 - val_loss: 1.3558 - val_categorical_accuracy: 0.7079\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0886 - categorical_accuracy: 0.9730 - val_loss: 1.2757 - val_categorical_accuracy: 0.7354\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0722 - categorical_accuracy: 0.9759 - val_loss: 1.3245 - val_categorical_accuracy: 0.7335\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0718 - categorical_accuracy: 0.9770 - val_loss: 1.3415 - val_categorical_accuracy: 0.7347\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 132s 12ms/step - loss: 0.0673 - categorical_accuracy: 0.9786 - val_loss: 1.3675 - val_categorical_accuracy: 0.7275\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1994, 32)          22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 398, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               3260672   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 9,678,274\n",
      "Trainable params: 9,678,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 6s 564us/step - loss: 1.1914 - categorical_accuracy: 0.5875 - val_loss: 1.2757 - val_categorical_accuracy: 0.6202\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 5s 491us/step - loss: 0.6589 - categorical_accuracy: 0.7798 - val_loss: 1.0197 - val_categorical_accuracy: 0.6854\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 5s 482us/step - loss: 0.3798 - categorical_accuracy: 0.8789 - val_loss: 1.1327 - val_categorical_accuracy: 0.7170\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 5s 491us/step - loss: 0.2104 - categorical_accuracy: 0.9378 - val_loss: 1.4946 - val_categorical_accuracy: 0.6940\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 5s 497us/step - loss: 0.1042 - categorical_accuracy: 0.9750 - val_loss: 1.6001 - val_categorical_accuracy: 0.7245\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 5s 486us/step - loss: 0.0731 - categorical_accuracy: 0.9870 - val_loss: 1.7671 - val_categorical_accuracy: 0.7324\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 5s 488us/step - loss: 0.0624 - categorical_accuracy: 0.9896 - val_loss: 2.0868 - val_categorical_accuracy: 0.7275\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 5s 487us/step - loss: 0.0495 - categorical_accuracy: 0.9933 - val_loss: 2.1314 - val_categorical_accuracy: 0.7143\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 5s 489us/step - loss: 0.0480 - categorical_accuracy: 0.9929 - val_loss: 1.9332 - val_categorical_accuracy: 0.7268\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 5s 490us/step - loss: 0.0417 - categorical_accuracy: 0.9929 - val_loss: 2.4078 - val_categorical_accuracy: 0.5932\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 5s 485us/step - loss: 0.0359 - categorical_accuracy: 0.9940 - val_loss: 2.7095 - val_categorical_accuracy: 0.6869\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 5s 488us/step - loss: 0.0374 - categorical_accuracy: 0.9930 - val_loss: 2.2127 - val_categorical_accuracy: 0.7249\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 5s 490us/step - loss: 0.0319 - categorical_accuracy: 0.9939 - val_loss: 2.1094 - val_categorical_accuracy: 0.7237\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 5s 482us/step - loss: 0.0289 - categorical_accuracy: 0.9939 - val_loss: 2.3307 - val_categorical_accuracy: 0.7200\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 5s 495us/step - loss: 0.0243 - categorical_accuracy: 0.9947 - val_loss: 2.2254 - val_categorical_accuracy: 0.7015\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 5s 490us/step - loss: 0.0245 - categorical_accuracy: 0.9936 - val_loss: 2.5514 - val_categorical_accuracy: 0.7143\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 5s 483us/step - loss: 0.0260 - categorical_accuracy: 0.9938 - val_loss: 2.3750 - val_categorical_accuracy: 0.7034\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 5s 492us/step - loss: 0.0206 - categorical_accuracy: 0.9944 - val_loss: 2.7285 - val_categorical_accuracy: 0.6823\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 5s 489us/step - loss: 0.0200 - categorical_accuracy: 0.9947 - val_loss: 2.5925 - val_categorical_accuracy: 0.7117\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 5s 494us/step - loss: 0.0207 - categorical_accuracy: 0.9944 - val_loss: 2.6909 - val_categorical_accuracy: 0.6857\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 1994, 64)          44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 398, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25472)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               6521088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 12,961,122\n",
      "Trainable params: 12,961,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 8s 748us/step - loss: 1.2310 - categorical_accuracy: 0.5818 - val_loss: 1.1893 - val_categorical_accuracy: 0.6289\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 7s 666us/step - loss: 0.6805 - categorical_accuracy: 0.7730 - val_loss: 1.3054 - val_categorical_accuracy: 0.6696\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 7s 672us/step - loss: 0.3919 - categorical_accuracy: 0.8791 - val_loss: 1.2113 - val_categorical_accuracy: 0.7317\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 7s 670us/step - loss: 0.2110 - categorical_accuracy: 0.9368 - val_loss: 1.6641 - val_categorical_accuracy: 0.7087\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 7s 673us/step - loss: 0.1147 - categorical_accuracy: 0.9721 - val_loss: 1.6362 - val_categorical_accuracy: 0.7177\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 7s 672us/step - loss: 0.0784 - categorical_accuracy: 0.9833 - val_loss: 1.9615 - val_categorical_accuracy: 0.6970\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 7s 671us/step - loss: 0.0612 - categorical_accuracy: 0.9889 - val_loss: 2.0610 - val_categorical_accuracy: 0.7143\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 7s 661us/step - loss: 0.0595 - categorical_accuracy: 0.9904 - val_loss: 2.2188 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 7s 662us/step - loss: 0.0474 - categorical_accuracy: 0.9911 - val_loss: 2.1037 - val_categorical_accuracy: 0.7170\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 7s 670us/step - loss: 0.0437 - categorical_accuracy: 0.9920 - val_loss: 2.4300 - val_categorical_accuracy: 0.6895\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 7s 675us/step - loss: 0.0399 - categorical_accuracy: 0.9929 - val_loss: 2.2600 - val_categorical_accuracy: 0.6801\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 7s 673us/step - loss: 0.0309 - categorical_accuracy: 0.9934 - val_loss: 2.4807 - val_categorical_accuracy: 0.7046\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 7s 674us/step - loss: 0.0349 - categorical_accuracy: 0.9923 - val_loss: 2.8115 - val_categorical_accuracy: 0.6609\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 7s 669us/step - loss: 0.0280 - categorical_accuracy: 0.9930 - val_loss: 2.1786 - val_categorical_accuracy: 0.7015\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 7s 671us/step - loss: 0.0294 - categorical_accuracy: 0.9942 - val_loss: 3.0344 - val_categorical_accuracy: 0.6658\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 7s 662us/step - loss: 0.0224 - categorical_accuracy: 0.9939 - val_loss: 2.9864 - val_categorical_accuracy: 0.6921\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 7s 663us/step - loss: 0.0249 - categorical_accuracy: 0.9937 - val_loss: 2.5149 - val_categorical_accuracy: 0.6925\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 7s 670us/step - loss: 0.0216 - categorical_accuracy: 0.9938 - val_loss: 3.0329 - val_categorical_accuracy: 0.6680\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 7s 670us/step - loss: 0.0235 - categorical_accuracy: 0.9935 - val_loss: 2.9370 - val_categorical_accuracy: 0.6481\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 7s 673us/step - loss: 0.0215 - categorical_accuracy: 0.9942 - val_loss: 2.6134 - val_categorical_accuracy: 0.7049\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 2000, 100)         6392600   \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1994, 64)          44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 398, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25472)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2048)              52168704  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 58,869,730\n",
      "Trainable params: 58,869,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10628 samples, validate on 2657 samples\n",
      "Epoch 1/20\n",
      "10628/10628 [==============================] - 19s 2ms/step - loss: 1.2130 - categorical_accuracy: 0.5805 - val_loss: 1.2619 - val_categorical_accuracy: 0.5683\n",
      "Epoch 2/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.6526 - categorical_accuracy: 0.7820 - val_loss: 1.2993 - val_categorical_accuracy: 0.6086\n",
      "Epoch 3/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.3496 - categorical_accuracy: 0.8956 - val_loss: 1.2358 - val_categorical_accuracy: 0.7207\n",
      "Epoch 4/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.1779 - categorical_accuracy: 0.9562 - val_loss: 1.7520 - val_categorical_accuracy: 0.6985\n",
      "Epoch 5/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0979 - categorical_accuracy: 0.9776 - val_loss: 1.9644 - val_categorical_accuracy: 0.7102\n",
      "Epoch 6/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0714 - categorical_accuracy: 0.9862 - val_loss: 2.5504 - val_categorical_accuracy: 0.6989\n",
      "Epoch 7/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0619 - categorical_accuracy: 0.9896 - val_loss: 2.0484 - val_categorical_accuracy: 0.7174\n",
      "Epoch 8/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0524 - categorical_accuracy: 0.9908 - val_loss: 2.4259 - val_categorical_accuracy: 0.7046\n",
      "Epoch 9/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0585 - categorical_accuracy: 0.9894 - val_loss: 2.7932 - val_categorical_accuracy: 0.6240\n",
      "Epoch 10/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0452 - categorical_accuracy: 0.9914 - val_loss: 2.5556 - val_categorical_accuracy: 0.6628\n",
      "Epoch 11/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0541 - categorical_accuracy: 0.9904 - val_loss: 2.6827 - val_categorical_accuracy: 0.7226\n",
      "Epoch 12/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0460 - categorical_accuracy: 0.9917 - val_loss: 2.5559 - val_categorical_accuracy: 0.6876\n",
      "Epoch 13/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0371 - categorical_accuracy: 0.9924 - val_loss: 3.7828 - val_categorical_accuracy: 0.6105\n",
      "Epoch 14/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0443 - categorical_accuracy: 0.9918 - val_loss: 3.2200 - val_categorical_accuracy: 0.7098\n",
      "Epoch 15/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0519 - categorical_accuracy: 0.9909 - val_loss: 3.3600 - val_categorical_accuracy: 0.6820\n",
      "Epoch 16/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0547 - categorical_accuracy: 0.9913 - val_loss: 3.5911 - val_categorical_accuracy: 0.6654\n",
      "Epoch 17/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0405 - categorical_accuracy: 0.9920 - val_loss: 3.0107 - val_categorical_accuracy: 0.6989\n",
      "Epoch 18/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0449 - categorical_accuracy: 0.9926 - val_loss: 3.5623 - val_categorical_accuracy: 0.6778\n",
      "Epoch 19/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0369 - categorical_accuracy: 0.9928 - val_loss: 3.2394 - val_categorical_accuracy: 0.7155\n",
      "Epoch 20/20\n",
      "10628/10628 [==============================] - 17s 2ms/step - loss: 0.0430 - categorical_accuracy: 0.9934 - val_loss: 4.3351 - val_categorical_accuracy: 0.6244\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
