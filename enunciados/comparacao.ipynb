{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_ENUNCIADO</th>\n",
       "      <th>TEXTO_ENUNCIADO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995437</td>\n",
       "      <td>Não comprovada a participação do beneficiário ...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025587</td>\n",
       "      <td>A operação ficta de exportação de plataformas ...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455370</td>\n",
       "      <td>No âmbito do TCU, a dosimetria da pena tem com...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773746</td>\n",
       "      <td>O princípio da independência das instâncias pe...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773402</td>\n",
       "      <td>É vedado aos dirigentes das entidades do Siste...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_ENUNCIADO  \\\n",
       "0  Benefício previdenciário                      54995437   \n",
       "1                  Petróleo                      55025587   \n",
       "2                Dosimetria                      55455370   \n",
       "3          Decisão judicial                      54773746   \n",
       "4                 Nepotismo                      54773402   \n",
       "\n",
       "                                     TEXTO_ENUNCIADO                ACORDAO  \\\n",
       "0  Não comprovada a participação do beneficiário ...  Acórdão 297/2016 - PL   \n",
       "1  A operação ficta de exportação de plataformas ...  Acórdão 366/2016 - PL   \n",
       "2  No âmbito do TCU, a dosimetria da pena tem com...  Acórdão 944/2016 - PL   \n",
       "3  O princípio da independência das instâncias pe...   Acórdão 30/2016 - PL   \n",
       "4  É vedado aos dirigentes das entidades do Siste...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_enunciados.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13312, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13312, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 20000\n",
    "limite_texto = 200\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TEXTO_ENUNCIADO'])\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_ENUNCIADO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13312, 200)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=======================================================================================================\n",
      "===             TREINAMENTO GRU (dropout .2) COM EMBEDDING SEM PRÉ-TREINO - FOLD 0 / 10             ===\n",
      "=======================================================================================================\n",
      "\n",
      "Train on 11980 samples, validate on 1332 samples\n",
      "Epoch 1/5\n",
      "11980/11980 [==============================] - 75s 6ms/step - loss: 1.7837 - categorical_accuracy: 0.4094 - val_loss: 1.5419 - val_categorical_accuracy: 0.4857\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.48574, saving model to /tmp/weights.hdf5\n",
      "Epoch 2/5\n",
      "11980/11980 [==============================] - 73s 6ms/step - loss: 1.2641 - categorical_accuracy: 0.5854 - val_loss: 1.2789 - val_categorical_accuracy: 0.5908\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.48574 to 0.59084, saving model to /tmp/weights.hdf5\n",
      "Epoch 3/5\n",
      " 6080/11980 [==============>...............] - ETA: 34s - loss: 0.9457 - categorical_accuracy: 0.6910"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "fold=0\n",
    "scores = []\n",
    "for train_index, val_index in KFold(n_splits=10, random_state=42, shuffle=True).split(df):\n",
    "    print()\n",
    "    print()\n",
    "    print('=======================================================================================================')\n",
    "    print('===             TREINAMENTO GRU (dropout .2) COM EMBEDDING SEM PRÉ-TREINO - FOLD', fold, '/ 10             ===')\n",
    "    print('=======================================================================================================')\n",
    "    print()\n",
    "    df_train = df.loc[train_index]\n",
    "    df_val = df.loc[val_index]\n",
    "    \n",
    "    sequences_train = tokenizer.texts_to_sequences(df_train['TEXTO_ENUNCIADO'])\n",
    "    sequences_val = tokenizer.texts_to_sequences(df_val['TEXTO_ENUNCIADO'])\n",
    "\n",
    "    x_train = pad_sequences(sequences_train, maxlen=limite_texto)\n",
    "    x_val = pad_sequences(sequences_val, maxlen=limite_texto)\n",
    "    \n",
    "    y_train = lbArea.transform(df_train['DESCR_AREA'])\n",
    "    y_val = lbArea.transform(df_val['DESCR_AREA'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "    model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val), verbose=1, shuffle=False, callbacks=[checkpointer])\n",
    "    \n",
    "    print('Evaluating best model and registering score:')\n",
    "    \n",
    "    model.load_weights('/tmp/weights.hdf5')\n",
    "    score = model.evaluate(x_val, y_val)\n",
    "    print(model.metrics_names[1], '=', score[1])\n",
    "    scores.append(score[1])\n",
    "    \n",
    "    fold += 1\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Dataframe(data = score, columns = [['sem pré-treino']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "fold=0\n",
    "score = []\n",
    "for train_index, val_index in KFold(n_splits=10, random_state=42, shuffle=True).split(df):\n",
    "    print()\n",
    "    print()\n",
    "    print('=======================================================================================================')\n",
    "    print('===            TREINAMENTO GRU (dropout .2) COM EMBEDDING TREINO NILC FIXO - FOLD', fold, '/ 10         ===')\n",
    "    print('=======================================================================================================')\n",
    "    print()\n",
    "    df_train = df.loc[train_index]\n",
    "    df_val = df.loc[val_index]\n",
    "    \n",
    "    sequences_train = tokenizer.texts_to_sequences(df_train['TEXTO_ENUNCIADO'])\n",
    "    sequences_val = tokenizer.texts_to_sequences(df_val['TEXTO_ENUNCIADO'])\n",
    "\n",
    "    x_train = pad_sequences(sequences_train, maxlen=limite_texto)\n",
    "    x_val = pad_sequences(sequences_val, maxlen=limite_texto)\n",
    "    \n",
    "    y_train = lbArea.transform(df_train['DESCR_AREA'])\n",
    "    y_val = lbArea.transform(df_val['DESCR_AREA'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "    model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), verbose=1, shuffle=False, callbacks=[checkpointer])\n",
    "    model.load_weights('/tmp/weights.hdf5')\n",
    "    score.append(model.evaluate(x_val, y_val))\n",
    "    \n",
    "    fold += 1\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NILC fixo'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "fold=0\n",
    "score = []\n",
    "for train_index, val_index in KFold(n_splits=10, random_state=42, shuffle=True).split(df):\n",
    "    print()\n",
    "    print()\n",
    "    print('=======================================================================================================')\n",
    "    print('===          TREINAMENTO GRU (dropout .2) COM EMBEDDING TREINO NILC VARIAVEL - FOLD', fold, '/ 10       ===')\n",
    "    print('=======================================================================================================')\n",
    "    print()\n",
    "    df_train = df.loc[train_index]\n",
    "    df_val = df.loc[val_index]\n",
    "    \n",
    "    sequences_train = tokenizer.texts_to_sequences(df_train['TEXTO_ENUNCIADO'])\n",
    "    sequences_val = tokenizer.texts_to_sequences(df_val['TEXTO_ENUNCIADO'])\n",
    "\n",
    "    x_train = pad_sequences(sequences_train, maxlen=limite_texto)\n",
    "    x_val = pad_sequences(sequences_val, maxlen=limite_texto)\n",
    "    \n",
    "    y_train = lbArea.transform(df_train['DESCR_AREA'])\n",
    "    y_val = lbArea.transform(df_val['DESCR_AREA'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "    model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), verbose=1, shuffle=False, callbacks=[checkpointer])\n",
    "    model.load_weights('/tmp/weights.hdf5')\n",
    "    score.append(model.evaluate(x_val, y_val))\n",
    "    \n",
    "    fold += 1\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NILC variavel'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('../vocabularios/modelo-acordaos2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "fold=0\n",
    "score = []\n",
    "for train_index, val_index in KFold(n_splits=10, random_state=42, shuffle=True).split(df):\n",
    "    print()\n",
    "    print()\n",
    "    print('=======================================================================================================')\n",
    "    print('===          TREINAMENTO GRU (dropout .2) COM EMBEDDING TREINO ACORDAOS FIXO - FOLD', fold, '/ 10       ===')\n",
    "    print('=======================================================================================================')\n",
    "    print()\n",
    "    df_train = df.loc[train_index]\n",
    "    df_val = df.loc[val_index]\n",
    "    \n",
    "    sequences_train = tokenizer.texts_to_sequences(df_train['TEXTO_ENUNCIADO'])\n",
    "    sequences_val = tokenizer.texts_to_sequences(df_val['TEXTO_ENUNCIADO'])\n",
    "\n",
    "    x_train = pad_sequences(sequences_train, maxlen=limite_texto)\n",
    "    x_val = pad_sequences(sequences_val, maxlen=limite_texto)\n",
    "    \n",
    "    y_train = lbArea.transform(df_train['DESCR_AREA'])\n",
    "    y_val = lbArea.transform(df_val['DESCR_AREA'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "    model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), verbose=1, shuffle=False, callbacks=[checkpointer])\n",
    "    model.load_weights('/tmp/weights.hdf5')\n",
    "    score.append(model.evaluate(x_val, y_val))\n",
    "    \n",
    "    fold += 1\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Acordaos fixo'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "fold=0\n",
    "score = []\n",
    "for train_index, val_index in KFold(n_splits=10, random_state=42, shuffle=True).split(df):\n",
    "    print()\n",
    "    print()\n",
    "    print('=======================================================================================================')\n",
    "    print('===     TREINAMENTO GRU (dropout .2) COM EMBEDDING TREINO ACORDAOS VARIAVEL - FOLD', fold, '/ 10     ===')\n",
    "    print('=======================================================================================================')\n",
    "    print()\n",
    "    df_train = df.loc[train_index]\n",
    "    df_val = df.loc[val_index]\n",
    "    \n",
    "    sequences_train = tokenizer.texts_to_sequences(df_train['TEXTO_ENUNCIADO'])\n",
    "    sequences_val = tokenizer.texts_to_sequences(df_val['TEXTO_ENUNCIADO'])\n",
    "\n",
    "    x_train = pad_sequences(sequences_train, maxlen=limite_texto)\n",
    "    x_val = pad_sequences(sequences_val, maxlen=limite_texto)\n",
    "    \n",
    "    y_train = lbArea.transform(df_train['DESCR_AREA'])\n",
    "    y_val = lbArea.transform(df_val['DESCR_AREA'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "    model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val), verbose=1, shuffle=False, callbacks=[checkpointer])\n",
    "    model.load_weights('/tmp/weights.hdf5')\n",
    "    score.append(model.evaluate(x_val, y_val))\n",
    "    \n",
    "    fold += 1\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Acordao variavel'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
