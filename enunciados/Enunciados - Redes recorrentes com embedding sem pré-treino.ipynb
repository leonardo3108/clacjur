{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_ENUNCIADO</th>\n",
       "      <th>TEXTO_ENUNCIADO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995437</td>\n",
       "      <td>Não comprovada a participação do beneficiário ...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025587</td>\n",
       "      <td>A operação ficta de exportação de plataformas ...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455370</td>\n",
       "      <td>No âmbito do TCU, a dosimetria da pena tem com...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773746</td>\n",
       "      <td>O princípio da independência das instâncias pe...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773402</td>\n",
       "      <td>É vedado aos dirigentes das entidades do Siste...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_ENUNCIADO  \\\n",
       "0  Benefício previdenciário                      54995437   \n",
       "1                  Petróleo                      55025587   \n",
       "2                Dosimetria                      55455370   \n",
       "3          Decisão judicial                      54773746   \n",
       "4                 Nepotismo                      54773402   \n",
       "\n",
       "                                     TEXTO_ENUNCIADO                ACORDAO  \\\n",
       "0  Não comprovada a participação do beneficiário ...  Acórdão 297/2016 - PL   \n",
       "1  A operação ficta de exportação de plataformas ...  Acórdão 366/2016 - PL   \n",
       "2  No âmbito do TCU, a dosimetria da pena tem com...  Acórdão 944/2016 - PL   \n",
       "3  O princípio da independência das instâncias pe...   Acórdão 30/2016 - PL   \n",
       "4  É vedado aos dirigentes das entidades do Siste...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('jurisprudencia_selecionada_enunciados.txt', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13312, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCR_AREA\n",
       "Competência do TCU          557\n",
       "Contrato Administrativo     942\n",
       "Convênio                    685\n",
       "Desestatização              140\n",
       "Direito Processual         1813\n",
       "Finanças Públicas           328\n",
       "Gestão Administrativa       339\n",
       "Licitação                  2765\n",
       "Pessoal                    3396\n",
       "Responsabilidade           2347\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DESCR_AREA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13312, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15387 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 20000\n",
    "limite_texto = 200\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['TEXTO_ENUNCIADO'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_ENUNCIADO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 45.17240084134615, 633, 22.57216215856166, 13312, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = 0\n",
    "lens = []\n",
    "for seq in sequences:\n",
    "    lens.append(len(seq))\n",
    "np.min(lens), np.mean(lens), np.max(lens), np.std(lens), len(lens), sum(pd.Series(lens) > 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13312, 200)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13312, 200), (13312, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 22:21:24.370933 140625392871232 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0811 22:21:24.382889 140625392871232 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0811 22:21:24.385090 140625392871232 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0811 22:21:24.524893 140625392871232 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0811 22:21:24.545795 140625392871232 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               91392     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,093,962\n",
      "Trainable params: 2,093,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(SimpleRNN(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 22:21:29.363127 140625392871232 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0811 22:21:29.522457 140625392871232 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 25s 2ms/step - loss: 2.0226 - categorical_accuracy: 0.2641 - val_loss: 2.1966 - val_categorical_accuracy: 0.1889\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 23s 2ms/step - loss: 1.8140 - categorical_accuracy: 0.3844 - val_loss: 1.8714 - val_categorical_accuracy: 0.3090\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 23s 2ms/step - loss: 1.6826 - categorical_accuracy: 0.4464 - val_loss: 2.0279 - val_categorical_accuracy: 0.2786\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 1.6313 - categorical_accuracy: 0.4707 - val_loss: 1.7418 - val_categorical_accuracy: 0.4484\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 23s 2ms/step - loss: 1.3032 - categorical_accuracy: 0.5822 - val_loss: 1.4745 - val_categorical_accuracy: 0.5325\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 1.0774 - categorical_accuracy: 0.6481 - val_loss: 1.5173 - val_categorical_accuracy: 0.4701\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.9451 - categorical_accuracy: 0.6925 - val_loss: 1.2781 - val_categorical_accuracy: 0.6125\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.8596 - categorical_accuracy: 0.7225 - val_loss: 1.3798 - val_categorical_accuracy: 0.5768\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.7706 - categorical_accuracy: 0.7538 - val_loss: 1.4538 - val_categorical_accuracy: 0.5374\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.6822 - categorical_accuracy: 0.7849 - val_loss: 1.2954 - val_categorical_accuracy: 0.6162\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.5933 - categorical_accuracy: 0.8082 - val_loss: 1.3286 - val_categorical_accuracy: 0.6200\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.5321 - categorical_accuracy: 0.8327 - val_loss: 1.3103 - val_categorical_accuracy: 0.6391\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 25s 2ms/step - loss: 0.4427 - categorical_accuracy: 0.8613 - val_loss: 1.3374 - val_categorical_accuracy: 0.6192\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 23s 2ms/step - loss: 0.3792 - categorical_accuracy: 0.8825 - val_loss: 1.4626 - val_categorical_accuracy: 0.6147\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 23s 2ms/step - loss: 0.3360 - categorical_accuracy: 0.8934 - val_loss: 1.4908 - val_categorical_accuracy: 0.6421\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 25s 2ms/step - loss: 0.2778 - categorical_accuracy: 0.9142 - val_loss: 1.4414 - val_categorical_accuracy: 0.6361\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.2436 - categorical_accuracy: 0.9222 - val_loss: 1.6125 - val_categorical_accuracy: 0.5918\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.2041 - categorical_accuracy: 0.9380 - val_loss: 1.5759 - val_categorical_accuracy: 0.6361\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.1526 - categorical_accuracy: 0.9554 - val_loss: 1.6380 - val_categorical_accuracy: 0.6342\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 24s 2ms/step - loss: 0.1225 - categorical_accuracy: 0.9635 - val_loss: 1.6336 - val_categorical_accuracy: 0.6695\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,276,746\n",
      "Trainable params: 2,276,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 1.3817 - categorical_accuracy: 0.5309 - val_loss: 1.0729 - val_categorical_accuracy: 0.6650\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.5755 - categorical_accuracy: 0.8183 - val_loss: 0.7486 - val_categorical_accuracy: 0.7792\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.3085 - categorical_accuracy: 0.9069 - val_loss: 0.9187 - val_categorical_accuracy: 0.7766\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1851 - categorical_accuracy: 0.9457 - val_loss: 0.7330 - val_categorical_accuracy: 0.8104\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.1123 - categorical_accuracy: 0.9666 - val_loss: 0.9175 - val_categorical_accuracy: 0.7540\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0818 - categorical_accuracy: 0.9748 - val_loss: 0.8235 - val_categorical_accuracy: 0.8119\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0487 - categorical_accuracy: 0.9866 - val_loss: 0.9279 - val_categorical_accuracy: 0.8021\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0338 - categorical_accuracy: 0.9906 - val_loss: 1.1385 - val_categorical_accuracy: 0.7927\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0245 - categorical_accuracy: 0.9937 - val_loss: 1.0504 - val_categorical_accuracy: 0.8160\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0284 - categorical_accuracy: 0.9925 - val_loss: 1.0067 - val_categorical_accuracy: 0.8179\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0158 - categorical_accuracy: 0.9965 - val_loss: 1.0949 - val_categorical_accuracy: 0.8029\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0246 - categorical_accuracy: 0.9931 - val_loss: 1.0852 - val_categorical_accuracy: 0.7987\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0140 - categorical_accuracy: 0.9963 - val_loss: 1.1108 - val_categorical_accuracy: 0.8014\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0108 - categorical_accuracy: 0.9965 - val_loss: 1.2234 - val_categorical_accuracy: 0.8081\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 58s 5ms/step - loss: 0.0087 - categorical_accuracy: 0.9987 - val_loss: 1.1272 - val_categorical_accuracy: 0.8164\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0111 - categorical_accuracy: 0.9973 - val_loss: 1.1266 - val_categorical_accuracy: 0.8070\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 58s 5ms/step - loss: 0.0095 - categorical_accuracy: 0.9977 - val_loss: 1.1831 - val_categorical_accuracy: 0.7983\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0044 - categorical_accuracy: 0.9991 - val_loss: 1.1732 - val_categorical_accuracy: 0.8111\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0025 - categorical_accuracy: 0.9994 - val_loss: 1.2691 - val_categorical_accuracy: 0.8059\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 1.2905 - val_categorical_accuracy: 0.8115\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               365568    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,368,138\n",
      "Trainable params: 2,368,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 1.4046 - categorical_accuracy: 0.5244 - val_loss: 1.0654 - val_categorical_accuracy: 0.6579\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 69s 7ms/step - loss: 0.6492 - categorical_accuracy: 0.7884 - val_loss: 0.8428 - val_categorical_accuracy: 0.7349\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.4476 - categorical_accuracy: 0.8592 - val_loss: 0.8489 - val_categorical_accuracy: 0.7540\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.3116 - categorical_accuracy: 0.9045 - val_loss: 0.9499 - val_categorical_accuracy: 0.7364\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.2001 - categorical_accuracy: 0.9407 - val_loss: 0.7989 - val_categorical_accuracy: 0.7773\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.1278 - categorical_accuracy: 0.9625 - val_loss: 0.9232 - val_categorical_accuracy: 0.7841\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 69s 7ms/step - loss: 0.1176 - categorical_accuracy: 0.9684 - val_loss: 0.8477 - val_categorical_accuracy: 0.7995\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0777 - categorical_accuracy: 0.9792 - val_loss: 0.9271 - val_categorical_accuracy: 0.7747\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0540 - categorical_accuracy: 0.9869 - val_loss: 1.0806 - val_categorical_accuracy: 0.7905\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0580 - categorical_accuracy: 0.9852 - val_loss: 1.0554 - val_categorical_accuracy: 0.7758\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0393 - categorical_accuracy: 0.9895 - val_loss: 1.1817 - val_categorical_accuracy: 0.7341\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0245 - categorical_accuracy: 0.9935 - val_loss: 1.0714 - val_categorical_accuracy: 0.7664\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 71s 7ms/step - loss: 0.0543 - categorical_accuracy: 0.9839 - val_loss: 1.0541 - val_categorical_accuracy: 0.7901\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0387 - categorical_accuracy: 0.9887 - val_loss: 1.0989 - val_categorical_accuracy: 0.7830\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0138 - categorical_accuracy: 0.9961 - val_loss: 1.1499 - val_categorical_accuracy: 0.7961\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 71s 7ms/step - loss: 0.0080 - categorical_accuracy: 0.9974 - val_loss: 1.1618 - val_categorical_accuracy: 0.7950\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0073 - categorical_accuracy: 0.9984 - val_loss: 1.1939 - val_categorical_accuracy: 0.7923\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0222 - categorical_accuracy: 0.9948 - val_loss: 1.0768 - val_categorical_accuracy: 0.7998\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0262 - categorical_accuracy: 0.9923 - val_loss: 1.0837 - val_categorical_accuracy: 0.7938\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 70s 7ms/step - loss: 0.0227 - categorical_accuracy: 0.9932 - val_loss: 1.1863 - val_categorical_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               182784    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,187,914\n",
      "Trainable params: 2,187,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 37s 3ms/step - loss: 1.9635 - categorical_accuracy: 0.3052 - val_loss: 1.9216 - val_categorical_accuracy: 0.2186\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 37s 3ms/step - loss: 1.6218 - categorical_accuracy: 0.4861 - val_loss: 1.7495 - val_categorical_accuracy: 0.4424\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 36s 3ms/step - loss: 1.3261 - categorical_accuracy: 0.5918 - val_loss: 1.7347 - val_categorical_accuracy: 0.4585\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 1.1202 - categorical_accuracy: 0.6476 - val_loss: 1.7425 - val_categorical_accuracy: 0.4563\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.9590 - categorical_accuracy: 0.6962 - val_loss: 1.5649 - val_categorical_accuracy: 0.5471\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 35s 3ms/step - loss: 0.7990 - categorical_accuracy: 0.7486 - val_loss: 1.6269 - val_categorical_accuracy: 0.5543\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.6785 - categorical_accuracy: 0.7866 - val_loss: 1.9790 - val_categorical_accuracy: 0.4720\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 35s 3ms/step - loss: 0.5983 - categorical_accuracy: 0.8141 - val_loss: 2.0583 - val_categorical_accuracy: 0.5118\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.5228 - categorical_accuracy: 0.8377 - val_loss: 2.0707 - val_categorical_accuracy: 0.4728\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 36s 3ms/step - loss: 0.4172 - categorical_accuracy: 0.8705 - val_loss: 2.0679 - val_categorical_accuracy: 0.5295\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 37s 4ms/step - loss: 0.3022 - categorical_accuracy: 0.9087 - val_loss: 2.3345 - val_categorical_accuracy: 0.5193\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 35s 3ms/step - loss: 0.2730 - categorical_accuracy: 0.9138 - val_loss: 2.2743 - val_categorical_accuracy: 0.5441\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.2310 - categorical_accuracy: 0.9305 - val_loss: 2.4346 - val_categorical_accuracy: 0.5238\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.1872 - categorical_accuracy: 0.9437 - val_loss: 2.6161 - val_categorical_accuracy: 0.5344\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 36s 3ms/step - loss: 0.2416 - categorical_accuracy: 0.9248 - val_loss: 2.9567 - val_categorical_accuracy: 0.4656\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.2155 - categorical_accuracy: 0.9325 - val_loss: 3.2386 - val_categorical_accuracy: 0.4953\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 36s 3ms/step - loss: 0.1669 - categorical_accuracy: 0.9501 - val_loss: 2.6583 - val_categorical_accuracy: 0.5347\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 34s 3ms/step - loss: 0.1586 - categorical_accuracy: 0.9496 - val_loss: 3.4131 - val_categorical_accuracy: 0.5069\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 36s 3ms/step - loss: 0.3959 - categorical_accuracy: 0.8720 - val_loss: 2.8441 - val_categorical_accuracy: 0.5107\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 35s 3ms/step - loss: 0.2100 - categorical_accuracy: 0.9332 - val_loss: 3.3224 - val_categorical_accuracy: 0.4889\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Bidirectional(SimpleRNN(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               548352    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,553,482\n",
      "Trainable params: 2,553,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 1.4726 - categorical_accuracy: 0.4970 - val_loss: 1.3131 - val_categorical_accuracy: 0.5712\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.7837 - categorical_accuracy: 0.7291 - val_loss: 0.8875 - val_categorical_accuracy: 0.7217\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.4455 - categorical_accuracy: 0.8616 - val_loss: 0.8279 - val_categorical_accuracy: 0.7630\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.2616 - categorical_accuracy: 0.9226 - val_loss: 0.7997 - val_categorical_accuracy: 0.7676\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.1471 - categorical_accuracy: 0.9598 - val_loss: 0.8946 - val_categorical_accuracy: 0.7942\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 98s 9ms/step - loss: 0.0925 - categorical_accuracy: 0.9735 - val_loss: 0.8521 - val_categorical_accuracy: 0.8059\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.0573 - categorical_accuracy: 0.9845 - val_loss: 0.9876 - val_categorical_accuracy: 0.7702\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.0298 - categorical_accuracy: 0.9929 - val_loss: 1.0304 - val_categorical_accuracy: 0.7965\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 0.0238 - categorical_accuracy: 0.9937 - val_loss: 1.0818 - val_categorical_accuracy: 0.7901\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 0.0294 - categorical_accuracy: 0.9929 - val_loss: 0.9994 - val_categorical_accuracy: 0.8029\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.0225 - categorical_accuracy: 0.9938 - val_loss: 1.0216 - val_categorical_accuracy: 0.7991\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.0293 - categorical_accuracy: 0.9925 - val_loss: 1.0957 - val_categorical_accuracy: 0.8014\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 0.0184 - categorical_accuracy: 0.9950 - val_loss: 1.1702 - val_categorical_accuracy: 0.7867\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 0.0183 - categorical_accuracy: 0.9961 - val_loss: 1.1484 - val_categorical_accuracy: 0.7912\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 0.0140 - categorical_accuracy: 0.9971 - val_loss: 1.1830 - val_categorical_accuracy: 0.7852\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 98s 9ms/step - loss: 0.0076 - categorical_accuracy: 0.9983 - val_loss: 1.2628 - val_categorical_accuracy: 0.7826\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 97s 9ms/step - loss: 0.0031 - categorical_accuracy: 0.9994 - val_loss: 1.2451 - val_categorical_accuracy: 0.8014\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 100s 9ms/step - loss: 0.0048 - categorical_accuracy: 0.9985 - val_loss: 1.4411 - val_categorical_accuracy: 0.7721\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 99s 9ms/step - loss: 0.0149 - categorical_accuracy: 0.9955 - val_loss: 1.2644 - val_categorical_accuracy: 0.7908\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 98s 9ms/step - loss: 0.0184 - categorical_accuracy: 0.9949 - val_loss: 1.1910 - val_categorical_accuracy: 0.7905\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Bidirectional(GRU(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 512)               731136    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,736,266\n",
      "Trainable params: 2,736,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 1.3166 - categorical_accuracy: 0.5374 - val_loss: 1.0455 - val_categorical_accuracy: 0.6853\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 124s 12ms/step - loss: 0.7376 - categorical_accuracy: 0.7542 - val_loss: 0.8998 - val_categorical_accuracy: 0.7473\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.4686 - categorical_accuracy: 0.8521 - val_loss: 0.8207 - val_categorical_accuracy: 0.7642\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 125s 12ms/step - loss: 0.3274 - categorical_accuracy: 0.8985 - val_loss: 0.9543 - val_categorical_accuracy: 0.7555\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 125s 12ms/step - loss: 0.2532 - categorical_accuracy: 0.9241 - val_loss: 0.9124 - val_categorical_accuracy: 0.7604\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.1924 - categorical_accuracy: 0.9452 - val_loss: 0.7947 - val_categorical_accuracy: 0.8160\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 127s 12ms/step - loss: 0.1049 - categorical_accuracy: 0.9705 - val_loss: 1.0554 - val_categorical_accuracy: 0.7499\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 127s 12ms/step - loss: 0.0698 - categorical_accuracy: 0.9807 - val_loss: 0.9114 - val_categorical_accuracy: 0.7983\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.0648 - categorical_accuracy: 0.9808 - val_loss: 0.9869 - val_categorical_accuracy: 0.8070\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.0372 - categorical_accuracy: 0.9907 - val_loss: 1.0427 - val_categorical_accuracy: 0.8006\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 127s 12ms/step - loss: 0.0213 - categorical_accuracy: 0.9950 - val_loss: 1.0484 - val_categorical_accuracy: 0.7987\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 125s 12ms/step - loss: 0.0372 - categorical_accuracy: 0.9906 - val_loss: 1.1715 - val_categorical_accuracy: 0.7600\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.0390 - categorical_accuracy: 0.9909 - val_loss: 0.9487 - val_categorical_accuracy: 0.8100\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.0275 - categorical_accuracy: 0.9935 - val_loss: 1.0282 - val_categorical_accuracy: 0.7995\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 126s 12ms/step - loss: 0.0237 - categorical_accuracy: 0.9950 - val_loss: 1.1236 - val_categorical_accuracy: 0.7784\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 125s 12ms/step - loss: 0.0086 - categorical_accuracy: 0.9978 - val_loss: 1.0712 - val_categorical_accuracy: 0.7995\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 125s 12ms/step - loss: 0.0252 - categorical_accuracy: 0.9931 - val_loss: 1.0651 - val_categorical_accuracy: 0.8029\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 123s 12ms/step - loss: 0.0245 - categorical_accuracy: 0.9933 - val_loss: 1.2442 - val_categorical_accuracy: 0.7679\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 123s 12ms/step - loss: 0.0198 - categorical_accuracy: 0.9946 - val_loss: 1.1909 - val_categorical_accuracy: 0.7968\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 123s 12ms/step - loss: 0.0073 - categorical_accuracy: 0.9987 - val_loss: 1.1791 - val_categorical_accuracy: 0.7916\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               87936     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,089,226\n",
      "Trainable params: 2,089,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 1.4039 - categorical_accuracy: 0.5244 - val_loss: 1.0735 - val_categorical_accuracy: 0.6286\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.6603 - categorical_accuracy: 0.7822 - val_loss: 0.7896 - val_categorical_accuracy: 0.7702\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.3540 - categorical_accuracy: 0.8896 - val_loss: 0.8107 - val_categorical_accuracy: 0.7702\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1887 - categorical_accuracy: 0.9438 - val_loss: 0.7903 - val_categorical_accuracy: 0.8032\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1174 - categorical_accuracy: 0.9658 - val_loss: 0.9177 - val_categorical_accuracy: 0.7890\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0767 - categorical_accuracy: 0.9776 - val_loss: 0.9949 - val_categorical_accuracy: 0.7792\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0537 - categorical_accuracy: 0.9853 - val_loss: 1.0257 - val_categorical_accuracy: 0.7766\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0280 - categorical_accuracy: 0.9936 - val_loss: 1.0369 - val_categorical_accuracy: 0.7980\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0181 - categorical_accuracy: 0.9949 - val_loss: 1.1397 - val_categorical_accuracy: 0.7863\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0156 - categorical_accuracy: 0.9958 - val_loss: 1.1019 - val_categorical_accuracy: 0.7957\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0291 - categorical_accuracy: 0.9916 - val_loss: 1.0952 - val_categorical_accuracy: 0.7991\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0288 - categorical_accuracy: 0.9920 - val_loss: 1.1018 - val_categorical_accuracy: 0.7818\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0134 - categorical_accuracy: 0.9964 - val_loss: 1.2048 - val_categorical_accuracy: 0.7968\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0039 - categorical_accuracy: 0.9994 - val_loss: 1.1577 - val_categorical_accuracy: 0.8040\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0134 - categorical_accuracy: 0.9962 - val_loss: 1.3294 - val_categorical_accuracy: 0.7807\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0246 - categorical_accuracy: 0.9926 - val_loss: 1.3497 - val_categorical_accuracy: 0.7721\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0169 - categorical_accuracy: 0.9955 - val_loss: 1.2607 - val_categorical_accuracy: 0.7818\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0174 - categorical_accuracy: 0.9950 - val_loss: 1.2277 - val_categorical_accuracy: 0.7976\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0053 - categorical_accuracy: 0.9990 - val_loss: 1.3422 - val_categorical_accuracy: 0.7856\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0028 - categorical_accuracy: 0.9993 - val_loss: 1.4139 - val_categorical_accuracy: 0.7807\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 64)                31680     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,032,330\n",
      "Trainable params: 2,032,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 1.4666 - categorical_accuracy: 0.5002 - val_loss: 1.2265 - val_categorical_accuracy: 0.5959\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.6659 - categorical_accuracy: 0.7835 - val_loss: 0.8770 - val_categorical_accuracy: 0.7567\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.3686 - categorical_accuracy: 0.8868 - val_loss: 0.9351 - val_categorical_accuracy: 0.7469\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.2114 - categorical_accuracy: 0.9382 - val_loss: 0.8464 - val_categorical_accuracy: 0.7691\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1175 - categorical_accuracy: 0.9687 - val_loss: 0.8993 - val_categorical_accuracy: 0.7837\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0781 - categorical_accuracy: 0.9790 - val_loss: 0.9002 - val_categorical_accuracy: 0.7923\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0480 - categorical_accuracy: 0.9892 - val_loss: 1.0300 - val_categorical_accuracy: 0.7871\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0321 - categorical_accuracy: 0.9931 - val_loss: 1.0137 - val_categorical_accuracy: 0.7957\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0450 - categorical_accuracy: 0.9884 - val_loss: 1.2049 - val_categorical_accuracy: 0.7754\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0196 - categorical_accuracy: 0.9957 - val_loss: 1.2039 - val_categorical_accuracy: 0.7717\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0234 - categorical_accuracy: 0.9946 - val_loss: 1.1588 - val_categorical_accuracy: 0.7942\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0119 - categorical_accuracy: 0.9979 - val_loss: 1.1635 - val_categorical_accuracy: 0.8002\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0070 - categorical_accuracy: 0.9987 - val_loss: 1.1855 - val_categorical_accuracy: 0.7946\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0080 - categorical_accuracy: 0.9979 - val_loss: 1.3057 - val_categorical_accuracy: 0.7799\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0055 - categorical_accuracy: 0.9987 - val_loss: 1.3027 - val_categorical_accuracy: 0.7807\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0178 - categorical_accuracy: 0.9947 - val_loss: 1.4179 - val_categorical_accuracy: 0.7646\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0267 - categorical_accuracy: 0.9919 - val_loss: 1.3411 - val_categorical_accuracy: 0.7679\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0106 - categorical_accuracy: 0.9974 - val_loss: 1.3363 - val_categorical_accuracy: 0.7867\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0100 - categorical_accuracy: 0.9978 - val_loss: 1.2695 - val_categorical_accuracy: 0.7897\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0036 - categorical_accuracy: 0.9993 - val_loss: 1.3559 - val_categorical_accuracy: 0.7920\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 512)               941568    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,946,698\n",
      "Trainable params: 2,946,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 1.4041 - categorical_accuracy: 0.5319 - val_loss: 1.1134 - val_categorical_accuracy: 0.6192\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.5892 - categorical_accuracy: 0.8113 - val_loss: 0.7049 - val_categorical_accuracy: 0.7923\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.3048 - categorical_accuracy: 0.9114 - val_loss: 0.9487 - val_categorical_accuracy: 0.7296\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1719 - categorical_accuracy: 0.9484 - val_loss: 0.9048 - val_categorical_accuracy: 0.7623\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1046 - categorical_accuracy: 0.9676 - val_loss: 0.9820 - val_categorical_accuracy: 0.7702\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0702 - categorical_accuracy: 0.9784 - val_loss: 0.9317 - val_categorical_accuracy: 0.7916\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0565 - categorical_accuracy: 0.9838 - val_loss: 1.0364 - val_categorical_accuracy: 0.7867\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0334 - categorical_accuracy: 0.9907 - val_loss: 0.9766 - val_categorical_accuracy: 0.8051\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0305 - categorical_accuracy: 0.9915 - val_loss: 1.2024 - val_categorical_accuracy: 0.7830\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0267 - categorical_accuracy: 0.9928 - val_loss: 1.1517 - val_categorical_accuracy: 0.8070\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0558 - categorical_accuracy: 0.9853 - val_loss: 1.0083 - val_categorical_accuracy: 0.7807\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0226 - categorical_accuracy: 0.9938 - val_loss: 1.0248 - val_categorical_accuracy: 0.8077\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0155 - categorical_accuracy: 0.9961 - val_loss: 1.0928 - val_categorical_accuracy: 0.7935\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0062 - categorical_accuracy: 0.9989 - val_loss: 1.1885 - val_categorical_accuracy: 0.8047\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0095 - categorical_accuracy: 0.9975 - val_loss: 1.2386 - val_categorical_accuracy: 0.8025\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0244 - categorical_accuracy: 0.9942 - val_loss: 1.2101 - val_categorical_accuracy: 0.7923\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0096 - categorical_accuracy: 0.9975 - val_loss: 1.1701 - val_categorical_accuracy: 0.8006\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0085 - categorical_accuracy: 0.9979 - val_loss: 1.2095 - val_categorical_accuracy: 0.7938\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0030 - categorical_accuracy: 0.9992 - val_loss: 1.2461 - val_categorical_accuracy: 0.8006\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0016 - categorical_accuracy: 0.9995 - val_loss: 1.2658 - val_categorical_accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(512))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,308,362\n",
      "Trainable params: 2,308,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 1.3405 - categorical_accuracy: 0.5431 - val_loss: 1.1215 - val_categorical_accuracy: 0.6485\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.5903 - categorical_accuracy: 0.8071 - val_loss: 0.7747 - val_categorical_accuracy: 0.7646\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.3147 - categorical_accuracy: 0.9022 - val_loss: 0.8074 - val_categorical_accuracy: 0.7863\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.1964 - categorical_accuracy: 0.9373 - val_loss: 0.7832 - val_categorical_accuracy: 0.8002\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.1108 - categorical_accuracy: 0.9663 - val_loss: 0.8843 - val_categorical_accuracy: 0.7908\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0656 - categorical_accuracy: 0.9811 - val_loss: 0.9542 - val_categorical_accuracy: 0.8002\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0488 - categorical_accuracy: 0.9858 - val_loss: 1.0493 - val_categorical_accuracy: 0.7890\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0345 - categorical_accuracy: 0.9901 - val_loss: 1.2570 - val_categorical_accuracy: 0.7818\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0372 - categorical_accuracy: 0.9902 - val_loss: 1.1081 - val_categorical_accuracy: 0.8171\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0250 - categorical_accuracy: 0.9928 - val_loss: 1.3749 - val_categorical_accuracy: 0.7848\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0154 - categorical_accuracy: 0.9963 - val_loss: 1.2614 - val_categorical_accuracy: 0.7762\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0205 - categorical_accuracy: 0.9939 - val_loss: 1.3350 - val_categorical_accuracy: 0.7908\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0208 - categorical_accuracy: 0.9950 - val_loss: 1.2427 - val_categorical_accuracy: 0.7886\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0121 - categorical_accuracy: 0.9967 - val_loss: 1.3515 - val_categorical_accuracy: 0.7968\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0077 - categorical_accuracy: 0.9980 - val_loss: 1.3193 - val_categorical_accuracy: 0.7968\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0080 - categorical_accuracy: 0.9984 - val_loss: 1.4184 - val_categorical_accuracy: 0.8066\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0097 - categorical_accuracy: 0.9972 - val_loss: 1.3904 - val_categorical_accuracy: 0.7942\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0234 - categorical_accuracy: 0.9937 - val_loss: 1.3496 - val_categorical_accuracy: 0.7837\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0195 - categorical_accuracy: 0.9941 - val_loss: 1.2885 - val_categorical_accuracy: 0.7935\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0091 - categorical_accuracy: 0.9975 - val_loss: 1.3637 - val_categorical_accuracy: 0.8055\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,291,274\n",
      "Trainable params: 2,291,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 1.4478 - categorical_accuracy: 0.5017 - val_loss: 1.2458 - val_categorical_accuracy: 0.5896\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.6323 - categorical_accuracy: 0.7906 - val_loss: 0.8050 - val_categorical_accuracy: 0.7563\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.3428 - categorical_accuracy: 0.8916 - val_loss: 0.8166 - val_categorical_accuracy: 0.7796\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.1917 - categorical_accuracy: 0.9438 - val_loss: 0.9476 - val_categorical_accuracy: 0.7630\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.1216 - categorical_accuracy: 0.9643 - val_loss: 0.9713 - val_categorical_accuracy: 0.7630\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0879 - categorical_accuracy: 0.9746 - val_loss: 1.0962 - val_categorical_accuracy: 0.7668\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0583 - categorical_accuracy: 0.9833 - val_loss: 1.0414 - val_categorical_accuracy: 0.7709\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0460 - categorical_accuracy: 0.9874 - val_loss: 1.2011 - val_categorical_accuracy: 0.7784\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0275 - categorical_accuracy: 0.9923 - val_loss: 1.3398 - val_categorical_accuracy: 0.7615\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0384 - categorical_accuracy: 0.9876 - val_loss: 1.2409 - val_categorical_accuracy: 0.7627\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0242 - categorical_accuracy: 0.9929 - val_loss: 1.2176 - val_categorical_accuracy: 0.7938\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0126 - categorical_accuracy: 0.9962 - val_loss: 1.2581 - val_categorical_accuracy: 0.7905\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0051 - categorical_accuracy: 0.9988 - val_loss: 1.5043 - val_categorical_accuracy: 0.7679\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0106 - categorical_accuracy: 0.9977 - val_loss: 1.3110 - val_categorical_accuracy: 0.7867\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 55s 5ms/step - loss: 0.0183 - categorical_accuracy: 0.9959 - val_loss: 1.5933 - val_categorical_accuracy: 0.7548\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0360 - categorical_accuracy: 0.9891 - val_loss: 1.4002 - val_categorical_accuracy: 0.7642\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0317 - categorical_accuracy: 0.9908 - val_loss: 1.2315 - val_categorical_accuracy: 0.7792\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0122 - categorical_accuracy: 0.9963 - val_loss: 1.3474 - val_categorical_accuracy: 0.7938\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0061 - categorical_accuracy: 0.9988 - val_loss: 1.4528 - val_categorical_accuracy: 0.7863\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0026 - categorical_accuracy: 0.9992 - val_loss: 1.3988 - val_categorical_accuracy: 0.7983\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,282,730\n",
      "Trainable params: 2,282,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 59s 6ms/step - loss: 1.4137 - categorical_accuracy: 0.5170 - val_loss: 1.0261 - val_categorical_accuracy: 0.6658\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.6033 - categorical_accuracy: 0.8038 - val_loss: 0.7917 - val_categorical_accuracy: 0.7428\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.3366 - categorical_accuracy: 0.8945 - val_loss: 0.8913 - val_categorical_accuracy: 0.7353\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.1995 - categorical_accuracy: 0.9392 - val_loss: 0.7926 - val_categorical_accuracy: 0.7792\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.1129 - categorical_accuracy: 0.9667 - val_loss: 0.9174 - val_categorical_accuracy: 0.7784\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0620 - categorical_accuracy: 0.9813 - val_loss: 0.9732 - val_categorical_accuracy: 0.7867\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0503 - categorical_accuracy: 0.9853 - val_loss: 1.0890 - val_categorical_accuracy: 0.7875\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0369 - categorical_accuracy: 0.9894 - val_loss: 1.1903 - val_categorical_accuracy: 0.7769\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0244 - categorical_accuracy: 0.9928 - val_loss: 1.0633 - val_categorical_accuracy: 0.7998\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0220 - categorical_accuracy: 0.9931 - val_loss: 1.1995 - val_categorical_accuracy: 0.7953\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0168 - categorical_accuracy: 0.9950 - val_loss: 1.2494 - val_categorical_accuracy: 0.7882\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0174 - categorical_accuracy: 0.9954 - val_loss: 1.2086 - val_categorical_accuracy: 0.7961\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0115 - categorical_accuracy: 0.9970 - val_loss: 1.4472 - val_categorical_accuracy: 0.7912\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0118 - categorical_accuracy: 0.9968 - val_loss: 1.3203 - val_categorical_accuracy: 0.8029\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0029 - categorical_accuracy: 0.9996 - val_loss: 1.4086 - val_categorical_accuracy: 0.7998\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0018 - categorical_accuracy: 0.9995 - val_loss: 1.4086 - val_categorical_accuracy: 0.8044\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0021 - categorical_accuracy: 0.9994 - val_loss: 1.4351 - val_categorical_accuracy: 0.7995\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0261 - categorical_accuracy: 0.9911 - val_loss: 1.2997 - val_categorical_accuracy: 0.7901\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0248 - categorical_accuracy: 0.9925 - val_loss: 1.3656 - val_categorical_accuracy: 0.7983\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0073 - categorical_accuracy: 0.9980 - val_loss: 1.3456 - val_categorical_accuracy: 0.8081\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 02:32:38.886567 140625392871232 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,276,746\n",
      "Trainable params: 2,276,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 1.4181 - categorical_accuracy: 0.5189 - val_loss: 1.0890 - val_categorical_accuracy: 0.6463\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.6399 - categorical_accuracy: 0.7962 - val_loss: 0.8191 - val_categorical_accuracy: 0.7646\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.3721 - categorical_accuracy: 0.8880 - val_loss: 0.7507 - val_categorical_accuracy: 0.7773\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.2538 - categorical_accuracy: 0.9210 - val_loss: 0.7205 - val_categorical_accuracy: 0.8044\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.1615 - categorical_accuracy: 0.9507 - val_loss: 0.7879 - val_categorical_accuracy: 0.8104\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.1018 - categorical_accuracy: 0.9699 - val_loss: 0.8636 - val_categorical_accuracy: 0.7968\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0654 - categorical_accuracy: 0.9829 - val_loss: 0.8746 - val_categorical_accuracy: 0.8100\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0482 - categorical_accuracy: 0.9854 - val_loss: 0.9657 - val_categorical_accuracy: 0.7950\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0536 - categorical_accuracy: 0.9844 - val_loss: 0.9291 - val_categorical_accuracy: 0.8044\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0382 - categorical_accuracy: 0.9901 - val_loss: 1.0488 - val_categorical_accuracy: 0.7912\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0289 - categorical_accuracy: 0.9923 - val_loss: 0.9507 - val_categorical_accuracy: 0.7927\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0184 - categorical_accuracy: 0.9950 - val_loss: 1.0122 - val_categorical_accuracy: 0.8119\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0157 - categorical_accuracy: 0.9956 - val_loss: 1.0890 - val_categorical_accuracy: 0.7957\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0151 - categorical_accuracy: 0.9959 - val_loss: 1.1047 - val_categorical_accuracy: 0.8014\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0178 - categorical_accuracy: 0.9953 - val_loss: 1.0312 - val_categorical_accuracy: 0.8032\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0094 - categorical_accuracy: 0.9976 - val_loss: 1.1465 - val_categorical_accuracy: 0.8126\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0079 - categorical_accuracy: 0.9982 - val_loss: 1.1593 - val_categorical_accuracy: 0.8104\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0070 - categorical_accuracy: 0.9983 - val_loss: 1.1620 - val_categorical_accuracy: 0.8077\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0080 - categorical_accuracy: 0.9983 - val_loss: 1.1047 - val_categorical_accuracy: 0.8077\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0101 - categorical_accuracy: 0.9974 - val_loss: 1.1531 - val_categorical_accuracy: 0.8032\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,276,746\n",
      "Trainable params: 2,276,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 1.4751 - categorical_accuracy: 0.5074 - val_loss: 1.1594 - val_categorical_accuracy: 0.6395\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.7497 - categorical_accuracy: 0.7595 - val_loss: 0.8329 - val_categorical_accuracy: 0.7477\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.4634 - categorical_accuracy: 0.8563 - val_loss: 0.8712 - val_categorical_accuracy: 0.7559\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.3193 - categorical_accuracy: 0.9055 - val_loss: 0.7707 - val_categorical_accuracy: 0.7863\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 64s 6ms/step - loss: 0.2120 - categorical_accuracy: 0.9380 - val_loss: 0.7881 - val_categorical_accuracy: 0.7950\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 69s 7ms/step - loss: 0.1377 - categorical_accuracy: 0.9602 - val_loss: 0.8561 - val_categorical_accuracy: 0.7938\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 68s 6ms/step - loss: 0.0936 - categorical_accuracy: 0.9730 - val_loss: 0.8878 - val_categorical_accuracy: 0.7938\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0688 - categorical_accuracy: 0.9807 - val_loss: 0.9301 - val_categorical_accuracy: 0.7908\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0436 - categorical_accuracy: 0.9885 - val_loss: 1.0957 - val_categorical_accuracy: 0.7807\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0395 - categorical_accuracy: 0.9889 - val_loss: 1.0333 - val_categorical_accuracy: 0.8017\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 0.0284 - categorical_accuracy: 0.9935 - val_loss: 1.1333 - val_categorical_accuracy: 0.7803\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 0.0253 - categorical_accuracy: 0.9931 - val_loss: 1.1036 - val_categorical_accuracy: 0.7983\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 68s 6ms/step - loss: 0.0195 - categorical_accuracy: 0.9955 - val_loss: 1.1191 - val_categorical_accuracy: 0.8066\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 68s 6ms/step - loss: 0.0140 - categorical_accuracy: 0.9958 - val_loss: 1.1751 - val_categorical_accuracy: 0.7995\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 0.0141 - categorical_accuracy: 0.9966 - val_loss: 1.2507 - val_categorical_accuracy: 0.8010\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0126 - categorical_accuracy: 0.9968 - val_loss: 1.2115 - val_categorical_accuracy: 0.7957\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0083 - categorical_accuracy: 0.9977 - val_loss: 1.2516 - val_categorical_accuracy: 0.7950\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0109 - categorical_accuracy: 0.9975 - val_loss: 1.1700 - val_categorical_accuracy: 0.8040\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0083 - categorical_accuracy: 0.9981 - val_loss: 1.2036 - val_categorical_accuracy: 0.8014\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0087 - categorical_accuracy: 0.9979 - val_loss: 1.2549 - val_categorical_accuracy: 0.7916\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,276,746\n",
      "Trainable params: 2,276,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 59s 5ms/step - loss: 1.4352 - categorical_accuracy: 0.5175 - val_loss: 1.2630 - val_categorical_accuracy: 0.6324\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.7153 - categorical_accuracy: 0.7670 - val_loss: 0.7977 - val_categorical_accuracy: 0.7552\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.4737 - categorical_accuracy: 0.8551 - val_loss: 0.7051 - val_categorical_accuracy: 0.7871\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.3501 - categorical_accuracy: 0.8898 - val_loss: 0.6546 - val_categorical_accuracy: 0.8010\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.2642 - categorical_accuracy: 0.9171 - val_loss: 0.6706 - val_categorical_accuracy: 0.8032\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1953 - categorical_accuracy: 0.9381 - val_loss: 0.7884 - val_categorical_accuracy: 0.7901\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1414 - categorical_accuracy: 0.9565 - val_loss: 0.7491 - val_categorical_accuracy: 0.8100\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1094 - categorical_accuracy: 0.9673 - val_loss: 0.7553 - val_categorical_accuracy: 0.8194\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0748 - categorical_accuracy: 0.9770 - val_loss: 0.8478 - val_categorical_accuracy: 0.8089\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0510 - categorical_accuracy: 0.9846 - val_loss: 0.7795 - val_categorical_accuracy: 0.8299\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0318 - categorical_accuracy: 0.9914 - val_loss: 1.0809 - val_categorical_accuracy: 0.7822\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0237 - categorical_accuracy: 0.9932 - val_loss: 1.1303 - val_categorical_accuracy: 0.8014\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0193 - categorical_accuracy: 0.9950 - val_loss: 1.0922 - val_categorical_accuracy: 0.8137\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0146 - categorical_accuracy: 0.9962 - val_loss: 1.0588 - val_categorical_accuracy: 0.8246\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0116 - categorical_accuracy: 0.9963 - val_loss: 1.1586 - val_categorical_accuracy: 0.8134\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0073 - categorical_accuracy: 0.9980 - val_loss: 1.2861 - val_categorical_accuracy: 0.8096\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 57s 5ms/step - loss: 0.0080 - categorical_accuracy: 0.9980 - val_loss: 1.2179 - val_categorical_accuracy: 0.8111\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0064 - categorical_accuracy: 0.9990 - val_loss: 1.1875 - val_categorical_accuracy: 0.8280\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0044 - categorical_accuracy: 0.9992 - val_loss: 1.4397 - val_categorical_accuracy: 0.8250\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0050 - categorical_accuracy: 0.9989 - val_loss: 1.3973 - val_categorical_accuracy: 0.8111\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,276,746\n",
      "Trainable params: 2,276,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 58s 5ms/step - loss: 1.7543 - categorical_accuracy: 0.3958 - val_loss: 1.5719 - val_categorical_accuracy: 0.5103\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 1.0487 - categorical_accuracy: 0.6483 - val_loss: 1.0767 - val_categorical_accuracy: 0.6474\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.7981 - categorical_accuracy: 0.7327 - val_loss: 1.1257 - val_categorical_accuracy: 0.6361\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.6314 - categorical_accuracy: 0.7956 - val_loss: 0.8677 - val_categorical_accuracy: 0.7338\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.5055 - categorical_accuracy: 0.8380 - val_loss: 0.9881 - val_categorical_accuracy: 0.6846\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.4033 - categorical_accuracy: 0.8730 - val_loss: 0.8938 - val_categorical_accuracy: 0.7548\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.3316 - categorical_accuracy: 0.8984 - val_loss: 0.8579 - val_categorical_accuracy: 0.7582\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.2665 - categorical_accuracy: 0.9191 - val_loss: 0.9445 - val_categorical_accuracy: 0.7822\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.2229 - categorical_accuracy: 0.9339 - val_loss: 0.7971 - val_categorical_accuracy: 0.7901\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1854 - categorical_accuracy: 0.9451 - val_loss: 0.8111 - val_categorical_accuracy: 0.7867\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1482 - categorical_accuracy: 0.9568 - val_loss: 1.0481 - val_categorical_accuracy: 0.7630\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.1118 - categorical_accuracy: 0.9684 - val_loss: 0.8700 - val_categorical_accuracy: 0.7833\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0890 - categorical_accuracy: 0.9755 - val_loss: 0.8832 - val_categorical_accuracy: 0.7991\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0695 - categorical_accuracy: 0.9812 - val_loss: 1.0058 - val_categorical_accuracy: 0.7863\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0536 - categorical_accuracy: 0.9856 - val_loss: 1.0898 - val_categorical_accuracy: 0.7788\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0430 - categorical_accuracy: 0.9890 - val_loss: 1.0946 - val_categorical_accuracy: 0.7845\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0340 - categorical_accuracy: 0.9915 - val_loss: 1.0297 - val_categorical_accuracy: 0.8002\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0276 - categorical_accuracy: 0.9924 - val_loss: 1.0750 - val_categorical_accuracy: 0.7920\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0213 - categorical_accuracy: 0.9945 - val_loss: 1.1506 - val_categorical_accuracy: 0.7946\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 56s 5ms/step - loss: 0.0166 - categorical_accuracy: 0.9955 - val_loss: 1.2092 - val_categorical_accuracy: 0.7908\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 200, 256)          274176    \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 32)                27744     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,302,250\n",
      "Trainable params: 2,302,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 113s 11ms/step - loss: 1.3182 - categorical_accuracy: 0.5488 - val_loss: 0.9676 - val_categorical_accuracy: 0.7041\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 111s 10ms/step - loss: 0.5629 - categorical_accuracy: 0.8251 - val_loss: 1.0325 - val_categorical_accuracy: 0.6673\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 109s 10ms/step - loss: 0.3333 - categorical_accuracy: 0.9021 - val_loss: 0.8020 - val_categorical_accuracy: 0.7672\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 110s 10ms/step - loss: 0.2275 - categorical_accuracy: 0.9350 - val_loss: 0.7825 - val_categorical_accuracy: 0.7852\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 113s 11ms/step - loss: 0.1523 - categorical_accuracy: 0.9577 - val_loss: 0.9408 - val_categorical_accuracy: 0.7439\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 110s 10ms/step - loss: 0.0853 - categorical_accuracy: 0.9776 - val_loss: 0.8598 - val_categorical_accuracy: 0.7957\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 111s 10ms/step - loss: 0.0623 - categorical_accuracy: 0.9834 - val_loss: 0.8818 - val_categorical_accuracy: 0.7905\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 111s 10ms/step - loss: 0.0605 - categorical_accuracy: 0.9835 - val_loss: 0.9607 - val_categorical_accuracy: 0.7732\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 114s 11ms/step - loss: 0.0419 - categorical_accuracy: 0.9883 - val_loss: 0.8695 - val_categorical_accuracy: 0.8134\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 116s 11ms/step - loss: 0.0147 - categorical_accuracy: 0.9972 - val_loss: 1.0116 - val_categorical_accuracy: 0.7893\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 113s 11ms/step - loss: 0.0194 - categorical_accuracy: 0.9958 - val_loss: 1.1503 - val_categorical_accuracy: 0.7717\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 109s 10ms/step - loss: 0.0210 - categorical_accuracy: 0.9953 - val_loss: 1.0650 - val_categorical_accuracy: 0.7811\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 110s 10ms/step - loss: 0.0247 - categorical_accuracy: 0.9935 - val_loss: 1.0097 - val_categorical_accuracy: 0.7942\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 111s 10ms/step - loss: 0.0201 - categorical_accuracy: 0.9940 - val_loss: 1.1656 - val_categorical_accuracy: 0.7698\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 110s 10ms/step - loss: 0.0270 - categorical_accuracy: 0.9916 - val_loss: 1.0934 - val_categorical_accuracy: 0.7946\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 114s 11ms/step - loss: 0.0088 - categorical_accuracy: 0.9977 - val_loss: 1.1221 - val_categorical_accuracy: 0.8017\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 112s 11ms/step - loss: 0.0114 - categorical_accuracy: 0.9962 - val_loss: 1.0818 - val_categorical_accuracy: 0.8066\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 110s 10ms/step - loss: 0.0105 - categorical_accuracy: 0.9968 - val_loss: 1.0729 - val_categorical_accuracy: 0.8096\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 110s 10ms/step - loss: 0.0053 - categorical_accuracy: 0.9987 - val_loss: 1.1609 - val_categorical_accuracy: 0.8014\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 111s 10ms/step - loss: 0.0112 - categorical_accuracy: 0.9972 - val_loss: 1.0933 - val_categorical_accuracy: 0.8089\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,308,362\n",
      "Trainable params: 2,308,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 68s 6ms/step - loss: 1.5159 - categorical_accuracy: 0.4928 - val_loss: 1.2520 - val_categorical_accuracy: 0.6072\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.8833 - categorical_accuracy: 0.7157 - val_loss: 1.0628 - val_categorical_accuracy: 0.6654\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.5975 - categorical_accuracy: 0.8072 - val_loss: 0.8795 - val_categorical_accuracy: 0.7345\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.3944 - categorical_accuracy: 0.8763 - val_loss: 0.8197 - val_categorical_accuracy: 0.7593\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.2519 - categorical_accuracy: 0.9229 - val_loss: 0.8764 - val_categorical_accuracy: 0.7661\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.1671 - categorical_accuracy: 0.9509 - val_loss: 0.9578 - val_categorical_accuracy: 0.7818\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 0.1221 - categorical_accuracy: 0.9634 - val_loss: 0.9087 - val_categorical_accuracy: 0.7953\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0706 - categorical_accuracy: 0.9793 - val_loss: 1.0381 - val_categorical_accuracy: 0.7938\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0533 - categorical_accuracy: 0.9842 - val_loss: 1.1886 - val_categorical_accuracy: 0.7893\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0522 - categorical_accuracy: 0.9842 - val_loss: 1.2174 - val_categorical_accuracy: 0.7942\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0357 - categorical_accuracy: 0.9888 - val_loss: 1.4323 - val_categorical_accuracy: 0.7630\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 68s 6ms/step - loss: 0.0251 - categorical_accuracy: 0.9931 - val_loss: 1.3023 - val_categorical_accuracy: 0.7957\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0214 - categorical_accuracy: 0.9943 - val_loss: 1.3423 - val_categorical_accuracy: 0.7965\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 65s 6ms/step - loss: 0.0210 - categorical_accuracy: 0.9946 - val_loss: 1.5689 - val_categorical_accuracy: 0.7743\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0156 - categorical_accuracy: 0.9951 - val_loss: 1.4840 - val_categorical_accuracy: 0.7856\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0109 - categorical_accuracy: 0.9970 - val_loss: 1.5194 - val_categorical_accuracy: 0.7927\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0133 - categorical_accuracy: 0.9962 - val_loss: 1.3650 - val_categorical_accuracy: 0.8040\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0185 - categorical_accuracy: 0.9946 - val_loss: 1.4791 - val_categorical_accuracy: 0.7882\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 67s 6ms/step - loss: 0.0139 - categorical_accuracy: 0.9963 - val_loss: 1.5817 - val_categorical_accuracy: 0.7856\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 66s 6ms/step - loss: 0.0110 - categorical_accuracy: 0.9965 - val_loss: 1.6619 - val_categorical_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "gru_24 (GRU)                 (None, 256)               274176    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,276,746\n",
      "Trainable params: 2,276,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 31s 3ms/step - loss: 1.7200 - categorical_accuracy: 0.4266 - val_loss: 1.5657 - val_categorical_accuracy: 0.4949\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 29s 3ms/step - loss: 0.8242 - categorical_accuracy: 0.7287 - val_loss: 0.9061 - val_categorical_accuracy: 0.7105\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.4204 - categorical_accuracy: 0.8647 - val_loss: 0.8603 - val_categorical_accuracy: 0.7548\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.2225 - categorical_accuracy: 0.9315 - val_loss: 0.8004 - val_categorical_accuracy: 0.7938\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.1350 - categorical_accuracy: 0.9610 - val_loss: 0.9716 - val_categorical_accuracy: 0.7781\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.0757 - categorical_accuracy: 0.9805 - val_loss: 1.0531 - val_categorical_accuracy: 0.7897\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.0454 - categorical_accuracy: 0.9875 - val_loss: 1.1064 - val_categorical_accuracy: 0.7751\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.0393 - categorical_accuracy: 0.9911 - val_loss: 0.9980 - val_categorical_accuracy: 0.7905\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 29s 3ms/step - loss: 0.0228 - categorical_accuracy: 0.9937 - val_loss: 1.0801 - val_categorical_accuracy: 0.7792\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 30s 3ms/step - loss: 0.0176 - categorical_accuracy: 0.9960 - val_loss: 1.0872 - val_categorical_accuracy: 0.8010\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 31s 3ms/step - loss: 0.0149 - categorical_accuracy: 0.9966 - val_loss: 1.1053 - val_categorical_accuracy: 0.7972\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 30s 3ms/step - loss: 0.0215 - categorical_accuracy: 0.9934 - val_loss: 1.2977 - val_categorical_accuracy: 0.7649\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.0187 - categorical_accuracy: 0.9941 - val_loss: 1.2190 - val_categorical_accuracy: 0.7935\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 30s 3ms/step - loss: 0.0080 - categorical_accuracy: 0.9979 - val_loss: 1.2080 - val_categorical_accuracy: 0.7976\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 29s 3ms/step - loss: 0.0074 - categorical_accuracy: 0.9985 - val_loss: 1.3396 - val_categorical_accuracy: 0.7848\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 29s 3ms/step - loss: 0.0164 - categorical_accuracy: 0.9962 - val_loss: 1.2480 - val_categorical_accuracy: 0.7923\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 29s 3ms/step - loss: 0.0138 - categorical_accuracy: 0.9963 - val_loss: 1.2773 - val_categorical_accuracy: 0.7912\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.0151 - categorical_accuracy: 0.9959 - val_loss: 1.3368 - val_categorical_accuracy: 0.7762\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 28s 3ms/step - loss: 0.0283 - categorical_accuracy: 0.9920 - val_loss: 1.3220 - val_categorical_accuracy: 0.7811\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 29s 3ms/step - loss: 0.0092 - categorical_accuracy: 0.9974 - val_loss: 1.1837 - val_categorical_accuracy: 0.8122\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=64, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
