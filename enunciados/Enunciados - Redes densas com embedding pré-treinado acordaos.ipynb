{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>NUM_ENUNCIADO</th>\n",
       "      <th>COD_AREA</th>\n",
       "      <th>DESCR_AREA</th>\n",
       "      <th>COD_TEMA</th>\n",
       "      <th>DESCR_TEMA</th>\n",
       "      <th>COD_SUBTEMA</th>\n",
       "      <th>DESCR_SUBTEMA</th>\n",
       "      <th>COD_DOC_TRAMITAVEL_ENUNCIADO</th>\n",
       "      <th>TEXTO_ENUNCIADO</th>\n",
       "      <th>ACORDAO</th>\n",
       "      <th>TIPO_PROCESSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>1236</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>488</td>\n",
       "      <td>Solidariedade</td>\n",
       "      <td>261</td>\n",
       "      <td>Benefício previdenciário</td>\n",
       "      <td>54995437</td>\n",
       "      <td>Não comprovada a participação do beneficiário ...</td>\n",
       "      <td>Acórdão 297/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>981</td>\n",
       "      <td>Exportação</td>\n",
       "      <td>983</td>\n",
       "      <td>Petróleo</td>\n",
       "      <td>55025587</td>\n",
       "      <td>A operação ficta de exportação de plataformas ...</td>\n",
       "      <td>Acórdão 366/2016 - PL</td>\n",
       "      <td>Solicitação do Congresso Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5700</td>\n",
       "      <td>5314</td>\n",
       "      <td>50</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>203</td>\n",
       "      <td>Multa</td>\n",
       "      <td>1021</td>\n",
       "      <td>Dosimetria</td>\n",
       "      <td>55455370</td>\n",
       "      <td>No âmbito do TCU, a dosimetria da pena tem com...</td>\n",
       "      <td>Acórdão 944/2016 - PL</td>\n",
       "      <td>Acompanhamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>162</td>\n",
       "      <td>Princípio da independência das instâncias</td>\n",
       "      <td>481</td>\n",
       "      <td>Decisão judicial</td>\n",
       "      <td>54773746</td>\n",
       "      <td>O princípio da independência das instâncias pe...</td>\n",
       "      <td>Acórdão 30/2016 - PL</td>\n",
       "      <td>Tomada de Contas Especial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>141</td>\n",
       "      <td>Sistema S</td>\n",
       "      <td>142</td>\n",
       "      <td>Nepotismo</td>\n",
       "      <td>54773402</td>\n",
       "      <td>É vedado aos dirigentes das entidades do Siste...</td>\n",
       "      <td>Acórdão 55/2016 - PL</td>\n",
       "      <td>Representação</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD  NUM_ENUNCIADO  COD_AREA          DESCR_AREA  COD_TEMA  \\\n",
       "0  1400           1236        50    Responsabilidade       488   \n",
       "1  1700           1534        46   Finanças Públicas       981   \n",
       "2  5700           5314        50    Responsabilidade       203   \n",
       "3   284             40        45  Direito Processual       162   \n",
       "4   298             54        49             Pessoal       141   \n",
       "\n",
       "                                  DESCR_TEMA  COD_SUBTEMA  \\\n",
       "0                              Solidariedade          261   \n",
       "1                                 Exportação          983   \n",
       "2                                      Multa         1021   \n",
       "3  Princípio da independência das instâncias          481   \n",
       "4                                  Sistema S          142   \n",
       "\n",
       "              DESCR_SUBTEMA  COD_DOC_TRAMITAVEL_ENUNCIADO  \\\n",
       "0  Benefício previdenciário                      54995437   \n",
       "1                  Petróleo                      55025587   \n",
       "2                Dosimetria                      55455370   \n",
       "3          Decisão judicial                      54773746   \n",
       "4                 Nepotismo                      54773402   \n",
       "\n",
       "                                     TEXTO_ENUNCIADO                ACORDAO  \\\n",
       "0  Não comprovada a participação do beneficiário ...  Acórdão 297/2016 - PL   \n",
       "1  A operação ficta de exportação de plataformas ...  Acórdão 366/2016 - PL   \n",
       "2  No âmbito do TCU, a dosimetria da pena tem com...  Acórdão 944/2016 - PL   \n",
       "3  O princípio da independência das instâncias pe...   Acórdão 30/2016 - PL   \n",
       "4  É vedado aos dirigentes das entidades do Siste...   Acórdão 55/2016 - PL   \n",
       "\n",
       "                        TIPO_PROCESSO  \n",
       "0           Tomada de Contas Especial  \n",
       "1   Solicitação do Congresso Nacional  \n",
       "2                      Acompanhamento  \n",
       "3           Tomada de Contas Especial  \n",
       "4                       Representação  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/jurisprudencia_selecionada_enunciados.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13312, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCR_AREA\n",
       "Competência do TCU          557\n",
       "Contrato Administrativo     942\n",
       "Convênio                    685\n",
       "Desestatização              140\n",
       "Direito Processual         1813\n",
       "Finanças Públicas           328\n",
       "Gestão Administrativa       339\n",
       "Licitação                  2765\n",
       "Pessoal                    3396\n",
       "Responsabilidade           2347\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['DESCR_AREA']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['DESCR_AREA']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13312, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['DESCR_AREA'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15387 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "limite_texto = 200\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TEXTO_ENUNCIADO'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['TEXTO_ENUNCIADO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13312, 200)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 15387\n",
      "Encontrados no modelo: 7889 = 51.270553064275035\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, 100))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model.wv:\n",
    "        embedding_matrix[i] = model.wv[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcu\n",
      "666\n",
      "443\n",
      "ec\n",
      "bdi\n",
      "vpni\n",
      "ti\n",
      "mp\n",
      "sus\n",
      "inss\n",
      "stf\n",
      "911\n",
      "iso\n",
      "cobit\n",
      "lc\n",
      "sicro\n",
      "711\n",
      "lo\n",
      "1952\n",
      "nbr\n",
      "iec\n"
     ]
    }
   ],
   "source": [
    "nok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word not in model.wv:\n",
    "        print(word)\n",
    "        nok += 1\n",
    "        if nok > 20: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding com pesos fixos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 11:41:11.086553 140465010759488 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding = Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 11:41:19.223565 140465010759488 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0904 11:41:19.308441 140465010759488 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0904 11:41:19.346229 140465010759488 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0904 11:41:19.347670 140465010759488 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0904 11:41:32.496978 140465010759488 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0904 11:41:32.497677 140465010759488 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0904 11:41:32.524185 140465010759488 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0904 11:41:32.547036 140465010759488 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          1538800   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              40962048  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 44,609,274\n",
      "Trainable params: 43,070,474\n",
      "Non-trainable params: 1,538,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 11:41:45.129506 140465010759488 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 20s 2ms/step - loss: 1.5372 - categorical_accuracy: 0.5714 - val_loss: 1.2034 - val_categorical_accuracy: 0.5937\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.8696 - categorical_accuracy: 0.7483 - val_loss: 1.0174 - val_categorical_accuracy: 0.6940\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.5528 - categorical_accuracy: 0.8382 - val_loss: 1.2643 - val_categorical_accuracy: 0.6692\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.3574 - categorical_accuracy: 0.8944 - val_loss: 1.4318 - val_categorical_accuracy: 0.6812\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.2524 - categorical_accuracy: 0.9272 - val_loss: 1.5010 - val_categorical_accuracy: 0.6801\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.1740 - categorical_accuracy: 0.9527 - val_loss: 1.7441 - val_categorical_accuracy: 0.6861\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.1418 - categorical_accuracy: 0.9632 - val_loss: 1.7802 - val_categorical_accuracy: 0.7007\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.1179 - categorical_accuracy: 0.9674 - val_loss: 2.0447 - val_categorical_accuracy: 0.6827\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.1016 - categorical_accuracy: 0.9760 - val_loss: 1.9851 - val_categorical_accuracy: 0.6951\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0869 - categorical_accuracy: 0.9789 - val_loss: 2.1513 - val_categorical_accuracy: 0.6883\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0761 - categorical_accuracy: 0.9816 - val_loss: 2.2862 - val_categorical_accuracy: 0.6819\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0702 - categorical_accuracy: 0.9833 - val_loss: 2.3948 - val_categorical_accuracy: 0.6778\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0609 - categorical_accuracy: 0.9862 - val_loss: 2.2434 - val_categorical_accuracy: 0.7037\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0601 - categorical_accuracy: 0.9859 - val_loss: 2.2833 - val_categorical_accuracy: 0.7075\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0598 - categorical_accuracy: 0.9861 - val_loss: 2.5085 - val_categorical_accuracy: 0.6879\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0520 - categorical_accuracy: 0.9891 - val_loss: 2.6440 - val_categorical_accuracy: 0.6857\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0481 - categorical_accuracy: 0.9889 - val_loss: 2.5564 - val_categorical_accuracy: 0.6977\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0441 - categorical_accuracy: 0.9900 - val_loss: 2.6843 - val_categorical_accuracy: 0.6988\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0489 - categorical_accuracy: 0.9901 - val_loss: 2.7851 - val_categorical_accuracy: 0.6891\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0523 - categorical_accuracy: 0.9891 - val_loss: 2.7394 - val_categorical_accuracy: 0.6917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 1.2368 - categorical_accuracy: 0.6253 - val_loss: 1.2598 - val_categorical_accuracy: 0.6102\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.4607 - categorical_accuracy: 0.8558 - val_loss: 1.0949 - val_categorical_accuracy: 0.6962\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.1594 - categorical_accuracy: 0.9489 - val_loss: 1.5818 - val_categorical_accuracy: 0.6609\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0699 - categorical_accuracy: 0.9803 - val_loss: 2.1032 - val_categorical_accuracy: 0.6557\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0495 - categorical_accuracy: 0.9869 - val_loss: 2.2420 - val_categorical_accuracy: 0.6530\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0303 - categorical_accuracy: 0.9914 - val_loss: 2.2602 - val_categorical_accuracy: 0.6876\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0265 - categorical_accuracy: 0.9936 - val_loss: 2.3581 - val_categorical_accuracy: 0.6804\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0241 - categorical_accuracy: 0.9941 - val_loss: 2.4475 - val_categorical_accuracy: 0.6718\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0205 - categorical_accuracy: 0.9953 - val_loss: 2.6291 - val_categorical_accuracy: 0.6662\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0180 - categorical_accuracy: 0.9959 - val_loss: 2.5874 - val_categorical_accuracy: 0.6767\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0217 - categorical_accuracy: 0.9957 - val_loss: 2.7317 - val_categorical_accuracy: 0.6789\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0125 - categorical_accuracy: 0.9977 - val_loss: 2.6894 - val_categorical_accuracy: 0.6842\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0165 - categorical_accuracy: 0.9961 - val_loss: 2.7910 - val_categorical_accuracy: 0.6879\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0112 - categorical_accuracy: 0.9972 - val_loss: 2.7617 - val_categorical_accuracy: 0.6861\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0144 - categorical_accuracy: 0.9971 - val_loss: 2.7299 - val_categorical_accuracy: 0.6913\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0138 - categorical_accuracy: 0.9972 - val_loss: 2.9732 - val_categorical_accuracy: 0.6707\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0121 - categorical_accuracy: 0.9979 - val_loss: 2.9405 - val_categorical_accuracy: 0.6665\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0117 - categorical_accuracy: 0.9981 - val_loss: 2.9328 - val_categorical_accuracy: 0.6778\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0095 - categorical_accuracy: 0.9985 - val_loss: 2.8592 - val_categorical_accuracy: 0.6782\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0124 - categorical_accuracy: 0.9972 - val_loss: 3.0556 - val_categorical_accuracy: 0.6665\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 1.2599 - categorical_accuracy: 0.6106 - val_loss: 1.1121 - val_categorical_accuracy: 0.6350\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.6460 - categorical_accuracy: 0.7932 - val_loss: 1.1354 - val_categorical_accuracy: 0.6665\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.3330 - categorical_accuracy: 0.8935 - val_loss: 1.3580 - val_categorical_accuracy: 0.6684\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.1751 - categorical_accuracy: 0.9443 - val_loss: 1.5582 - val_categorical_accuracy: 0.6816\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.1011 - categorical_accuracy: 0.9716 - val_loss: 2.0785 - val_categorical_accuracy: 0.6654\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0678 - categorical_accuracy: 0.9778 - val_loss: 1.9780 - val_categorical_accuracy: 0.6744\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0474 - categorical_accuracy: 0.9851 - val_loss: 2.4335 - val_categorical_accuracy: 0.6654\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0402 - categorical_accuracy: 0.9878 - val_loss: 2.2593 - val_categorical_accuracy: 0.6872\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0332 - categorical_accuracy: 0.9903 - val_loss: 2.3113 - val_categorical_accuracy: 0.6910\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0251 - categorical_accuracy: 0.9930 - val_loss: 2.7810 - val_categorical_accuracy: 0.6594\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0263 - categorical_accuracy: 0.9927 - val_loss: 2.4358 - val_categorical_accuracy: 0.6932\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0261 - categorical_accuracy: 0.9935 - val_loss: 2.4857 - val_categorical_accuracy: 0.6906\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0206 - categorical_accuracy: 0.9956 - val_loss: 2.6877 - val_categorical_accuracy: 0.6951\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0248 - categorical_accuracy: 0.9930 - val_loss: 2.5928 - val_categorical_accuracy: 0.6925\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.9950 - val_loss: 2.7214 - val_categorical_accuracy: 0.6868\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0202 - categorical_accuracy: 0.9946 - val_loss: 2.7056 - val_categorical_accuracy: 0.6940\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0119 - categorical_accuracy: 0.9971 - val_loss: 2.7144 - val_categorical_accuracy: 0.6973\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 16s 1ms/step - loss: 0.0138 - categorical_accuracy: 0.9969 - val_loss: 2.8426 - val_categorical_accuracy: 0.6879\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0136 - categorical_accuracy: 0.9972 - val_loss: 2.7436 - val_categorical_accuracy: 0.7007\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 16s 2ms/step - loss: 0.0145 - categorical_accuracy: 0.9970 - val_loss: 3.0194 - val_categorical_accuracy: 0.6834\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding com pesos ajustáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 11:58:45.674276 140465010759488 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0904 11:58:45.699276 140465010759488 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 100)          1538800   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2048)              40962048  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 44,609,274\n",
      "Trainable params: 44,609,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 19s 2ms/step - loss: 1.5353 - categorical_accuracy: 0.5744 - val_loss: 1.1145 - val_categorical_accuracy: 0.6241\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.8599 - categorical_accuracy: 0.7478 - val_loss: 1.1044 - val_categorical_accuracy: 0.6414\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.5738 - categorical_accuracy: 0.8342 - val_loss: 1.1411 - val_categorical_accuracy: 0.6639\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.3427 - categorical_accuracy: 0.9003 - val_loss: 1.5054 - val_categorical_accuracy: 0.6414\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.2535 - categorical_accuracy: 0.9285 - val_loss: 1.4571 - val_categorical_accuracy: 0.6966\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.1721 - categorical_accuracy: 0.9488 - val_loss: 1.6198 - val_categorical_accuracy: 0.6917\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.1354 - categorical_accuracy: 0.9638 - val_loss: 1.8932 - val_categorical_accuracy: 0.6962\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.1104 - categorical_accuracy: 0.9709 - val_loss: 1.9078 - val_categorical_accuracy: 0.6876\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0807 - categorical_accuracy: 0.9785 - val_loss: 2.0042 - val_categorical_accuracy: 0.6977\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0806 - categorical_accuracy: 0.9792 - val_loss: 2.0986 - val_categorical_accuracy: 0.6812\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0787 - categorical_accuracy: 0.9821 - val_loss: 2.1348 - val_categorical_accuracy: 0.6973\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0684 - categorical_accuracy: 0.9834 - val_loss: 2.1670 - val_categorical_accuracy: 0.7018\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0692 - categorical_accuracy: 0.9844 - val_loss: 2.3328 - val_categorical_accuracy: 0.6876\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0554 - categorical_accuracy: 0.9865 - val_loss: 2.2618 - val_categorical_accuracy: 0.7041\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0516 - categorical_accuracy: 0.9869 - val_loss: 2.3245 - val_categorical_accuracy: 0.7018\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0474 - categorical_accuracy: 0.9893 - val_loss: 2.4253 - val_categorical_accuracy: 0.6940\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0509 - categorical_accuracy: 0.9886 - val_loss: 2.5171 - val_categorical_accuracy: 0.6857\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0382 - categorical_accuracy: 0.9905 - val_loss: 2.6472 - val_categorical_accuracy: 0.6782\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0377 - categorical_accuracy: 0.9918 - val_loss: 2.5946 - val_categorical_accuracy: 0.6921\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0446 - categorical_accuracy: 0.9900 - val_loss: 2.4781 - val_categorical_accuracy: 0.7112\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 19s 2ms/step - loss: 1.2292 - categorical_accuracy: 0.6262 - val_loss: 1.1266 - val_categorical_accuracy: 0.6568\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.4563 - categorical_accuracy: 0.8561 - val_loss: 1.2245 - val_categorical_accuracy: 0.6541\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.1393 - categorical_accuracy: 0.9541 - val_loss: 1.6815 - val_categorical_accuracy: 0.6684\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0772 - categorical_accuracy: 0.9791 - val_loss: 1.9124 - val_categorical_accuracy: 0.6748\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0417 - categorical_accuracy: 0.9881 - val_loss: 2.0857 - val_categorical_accuracy: 0.6921\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0367 - categorical_accuracy: 0.9902 - val_loss: 2.2142 - val_categorical_accuracy: 0.6808\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0253 - categorical_accuracy: 0.9935 - val_loss: 2.4891 - val_categorical_accuracy: 0.6695\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0246 - categorical_accuracy: 0.9942 - val_loss: 2.7097 - val_categorical_accuracy: 0.6639\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0147 - categorical_accuracy: 0.9970 - val_loss: 2.5764 - val_categorical_accuracy: 0.6883\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0169 - categorical_accuracy: 0.9961 - val_loss: 2.6414 - val_categorical_accuracy: 0.6786\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0179 - categorical_accuracy: 0.9973 - val_loss: 2.7795 - val_categorical_accuracy: 0.6647\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0140 - categorical_accuracy: 0.9977 - val_loss: 2.6160 - val_categorical_accuracy: 0.6853\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0132 - categorical_accuracy: 0.9977 - val_loss: 2.8050 - val_categorical_accuracy: 0.6801\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0118 - categorical_accuracy: 0.9981 - val_loss: 2.8334 - val_categorical_accuracy: 0.6763\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0107 - categorical_accuracy: 0.9983 - val_loss: 2.8238 - val_categorical_accuracy: 0.6797\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0103 - categorical_accuracy: 0.9984 - val_loss: 2.7084 - val_categorical_accuracy: 0.6868\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0103 - categorical_accuracy: 0.9982 - val_loss: 2.7395 - val_categorical_accuracy: 0.6868\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0119 - categorical_accuracy: 0.9979 - val_loss: 2.9381 - val_categorical_accuracy: 0.6819\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0099 - categorical_accuracy: 0.9986 - val_loss: 2.8359 - val_categorical_accuracy: 0.6804\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0075 - categorical_accuracy: 0.9987 - val_loss: 2.8919 - val_categorical_accuracy: 0.6774\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10649 samples, validate on 2663 samples\n",
      "Epoch 1/20\n",
      "10649/10649 [==============================] - 19s 2ms/step - loss: 1.2478 - categorical_accuracy: 0.6103 - val_loss: 1.1523 - val_categorical_accuracy: 0.5952\n",
      "Epoch 2/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.6521 - categorical_accuracy: 0.7896 - val_loss: 1.0691 - val_categorical_accuracy: 0.6940\n",
      "Epoch 3/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.3369 - categorical_accuracy: 0.8916 - val_loss: 1.5083 - val_categorical_accuracy: 0.6583\n",
      "Epoch 4/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.1657 - categorical_accuracy: 0.9469 - val_loss: 1.7315 - val_categorical_accuracy: 0.6857\n",
      "Epoch 5/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0981 - categorical_accuracy: 0.9701 - val_loss: 1.8432 - val_categorical_accuracy: 0.6928\n",
      "Epoch 6/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0761 - categorical_accuracy: 0.9807 - val_loss: 1.9499 - val_categorical_accuracy: 0.6876\n",
      "Epoch 7/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0496 - categorical_accuracy: 0.9861 - val_loss: 2.3254 - val_categorical_accuracy: 0.6756\n",
      "Epoch 8/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0449 - categorical_accuracy: 0.9887 - val_loss: 2.3692 - val_categorical_accuracy: 0.6812\n",
      "Epoch 9/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0267 - categorical_accuracy: 0.9918 - val_loss: 2.4169 - val_categorical_accuracy: 0.6940\n",
      "Epoch 10/20\n",
      "10649/10649 [==============================] - 17s 2ms/step - loss: 0.0259 - categorical_accuracy: 0.9928 - val_loss: 2.5486 - val_categorical_accuracy: 0.6940\n",
      "Epoch 11/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0259 - categorical_accuracy: 0.9931 - val_loss: 2.5300 - val_categorical_accuracy: 0.6928\n",
      "Epoch 12/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0179 - categorical_accuracy: 0.9947 - val_loss: 2.6631 - val_categorical_accuracy: 0.6857\n",
      "Epoch 13/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0218 - categorical_accuracy: 0.9950 - val_loss: 2.7559 - val_categorical_accuracy: 0.6812\n",
      "Epoch 14/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0183 - categorical_accuracy: 0.9955 - val_loss: 2.8616 - val_categorical_accuracy: 0.6756\n",
      "Epoch 15/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0213 - categorical_accuracy: 0.9945 - val_loss: 2.7651 - val_categorical_accuracy: 0.6793\n",
      "Epoch 16/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0177 - categorical_accuracy: 0.9958 - val_loss: 2.6592 - val_categorical_accuracy: 0.6864\n",
      "Epoch 17/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0142 - categorical_accuracy: 0.9969 - val_loss: 2.8122 - val_categorical_accuracy: 0.6849\n",
      "Epoch 18/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0125 - categorical_accuracy: 0.9968 - val_loss: 2.8636 - val_categorical_accuracy: 0.6767\n",
      "Epoch 19/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0135 - categorical_accuracy: 0.9976 - val_loss: 2.9059 - val_categorical_accuracy: 0.6812\n",
      "Epoch 20/20\n",
      "10649/10649 [==============================] - 18s 2ms/step - loss: 0.0151 - categorical_accuracy: 0.9964 - val_loss: 2.9897 - val_categorical_accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
