{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>areas</th>\n",
       "      <th>filtrado_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>conta conta gerência instituto nacional seguro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>senado petróleo petróleo regime aduaneiro expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>tribunal conta plenário embargo declaração aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>embargo declaração inss recorrente marco antôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>senac senac senac empresa senac giselle araújo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao               areas  \\\n",
       "0  297/2016-P    Responsabilidade   \n",
       "1  366/2016-P   Finanças Públicas   \n",
       "2  944/2016-P    Responsabilidade   \n",
       "3   30/2016-P  Direito Processual   \n",
       "4   55/2016-P             Pessoal   \n",
       "\n",
       "                                        filtrado_500  \n",
       "0  conta conta gerência instituto nacional seguro...  \n",
       "1  senado petróleo petróleo regime aduaneiro expo...  \n",
       "2  tribunal conta plenário embargo declaração aco...  \n",
       "3  embargo declaração inss recorrente marco antôn...  \n",
       "4  senac senac senac empresa senac giselle araújo...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-selecionada-filtrados-500.csv', sep = '|')\n",
    "df['filtrado_500']=df['filtrado_500'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10524, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10524, 91)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['areas']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33339 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 35000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado_500'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado_500'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10524, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10524, 500), (10524, 91))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 33339\n",
      "Encontrados no modelo: 25799 = 77.38384474639311\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0318 10:41:34.175041 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0318 10:41:34.244674 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0318 10:41:34.247420 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0318 10:41:34.254717 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0318 10:41:34.255289 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0318 10:41:35.230607 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0318 10:41:35.266857 140371563280192 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0318 10:41:35.351544 140371563280192 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 91)                3003      \n",
      "=================================================================\n",
      "Total params: 3,532,635\n",
      "Trainable params: 32,635\n",
      "Non-trainable params: 3,500,000\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 2s 264us/step - loss: 1.7277 - categorical_accuracy: 0.5616 - val_loss: 1.6051 - val_categorical_accuracy: 0.5145\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 1s 105us/step - loss: 1.3927 - categorical_accuracy: 0.6237 - val_loss: 1.8310 - val_categorical_accuracy: 0.4660\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 1s 106us/step - loss: 1.2916 - categorical_accuracy: 0.6498 - val_loss: 1.6248 - val_categorical_accuracy: 0.4846\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 1s 98us/step - loss: 1.2160 - categorical_accuracy: 0.6597 - val_loss: 1.5360 - val_categorical_accuracy: 0.5558\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 1s 100us/step - loss: 1.1426 - categorical_accuracy: 0.6867 - val_loss: 1.6259 - val_categorical_accuracy: 0.5335\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 1s 105us/step - loss: 1.0773 - categorical_accuracy: 0.7048 - val_loss: 1.7918 - val_categorical_accuracy: 0.4470\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 1s 100us/step - loss: 1.0110 - categorical_accuracy: 0.7249 - val_loss: 1.5449 - val_categorical_accuracy: 0.5743\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 1s 100us/step - loss: 0.9487 - categorical_accuracy: 0.7430 - val_loss: 1.7461 - val_categorical_accuracy: 0.5881\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 1s 99us/step - loss: 0.8923 - categorical_accuracy: 0.7586 - val_loss: 1.7168 - val_categorical_accuracy: 0.5477\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 1s 123us/step - loss: 0.8362 - categorical_accuracy: 0.7721 - val_loss: 1.7573 - val_categorical_accuracy: 0.5914\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 1s 150us/step - loss: 0.7874 - categorical_accuracy: 0.7835 - val_loss: 1.9530 - val_categorical_accuracy: 0.5040\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 1s 111us/step - loss: 0.7398 - categorical_accuracy: 0.7984 - val_loss: 2.1315 - val_categorical_accuracy: 0.4765\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 1s 102us/step - loss: 0.7002 - categorical_accuracy: 0.8086 - val_loss: 1.9226 - val_categorical_accuracy: 0.5135\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 1s 104us/step - loss: 0.6621 - categorical_accuracy: 0.8146 - val_loss: 2.1083 - val_categorical_accuracy: 0.5188\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 1s 102us/step - loss: 0.6350 - categorical_accuracy: 0.8278 - val_loss: 2.3805 - val_categorical_accuracy: 0.4808\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 1s 99us/step - loss: 0.6007 - categorical_accuracy: 0.8362 - val_loss: 2.2796 - val_categorical_accuracy: 0.4751\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 1s 97us/step - loss: 0.5733 - categorical_accuracy: 0.8437 - val_loss: 2.2413 - val_categorical_accuracy: 0.4969\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 1s 103us/step - loss: 0.5513 - categorical_accuracy: 0.8470 - val_loss: 2.2521 - val_categorical_accuracy: 0.5582\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 1s 105us/step - loss: 0.5259 - categorical_accuracy: 0.8563 - val_loss: 2.5857 - val_categorical_accuracy: 0.4722\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 1s 106us/step - loss: 0.5073 - categorical_accuracy: 0.8613 - val_loss: 2.5228 - val_categorical_accuracy: 0.5173\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 91)                3003      \n",
      "=================================================================\n",
      "Total params: 3,562,235\n",
      "Trainable params: 3,562,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 2s 267us/step - loss: 1.7293 - categorical_accuracy: 0.5680 - val_loss: 1.6742 - val_categorical_accuracy: 0.5439\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 1.3857 - categorical_accuracy: 0.6321 - val_loss: 1.7659 - val_categorical_accuracy: 0.5188\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 1.2658 - categorical_accuracy: 0.6586 - val_loss: 1.8610 - val_categorical_accuracy: 0.3986\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 1.1659 - categorical_accuracy: 0.6857 - val_loss: 1.7380 - val_categorical_accuracy: 0.4613\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 219us/step - loss: 1.0608 - categorical_accuracy: 0.7139 - val_loss: 1.8947 - val_categorical_accuracy: 0.4337\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 208us/step - loss: 0.9624 - categorical_accuracy: 0.7428 - val_loss: 1.6780 - val_categorical_accuracy: 0.5378\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 213us/step - loss: 0.8655 - categorical_accuracy: 0.7722 - val_loss: 1.7575 - val_categorical_accuracy: 0.5363\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 210us/step - loss: 0.7741 - categorical_accuracy: 0.7945 - val_loss: 1.8569 - val_categorical_accuracy: 0.5477\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 219us/step - loss: 0.6973 - categorical_accuracy: 0.8177 - val_loss: 2.4020 - val_categorical_accuracy: 0.4252\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 223us/step - loss: 0.6342 - categorical_accuracy: 0.8313 - val_loss: 2.2789 - val_categorical_accuracy: 0.4542\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 0.5812 - categorical_accuracy: 0.8511 - val_loss: 2.2545 - val_categorical_accuracy: 0.4698\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 221us/step - loss: 0.5295 - categorical_accuracy: 0.8588 - val_loss: 2.0818 - val_categorical_accuracy: 0.5069\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 211us/step - loss: 0.4883 - categorical_accuracy: 0.8706 - val_loss: 2.4184 - val_categorical_accuracy: 0.5710\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 229us/step - loss: 0.4577 - categorical_accuracy: 0.8753 - val_loss: 2.5990 - val_categorical_accuracy: 0.4917\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 0.4202 - categorical_accuracy: 0.8914 - val_loss: 2.7252 - val_categorical_accuracy: 0.4874\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 213us/step - loss: 0.3924 - categorical_accuracy: 0.8927 - val_loss: 2.4363 - val_categorical_accuracy: 0.5107\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 227us/step - loss: 0.3767 - categorical_accuracy: 0.9007 - val_loss: 2.5873 - val_categorical_accuracy: 0.5069\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 224us/step - loss: 0.3582 - categorical_accuracy: 0.9064 - val_loss: 2.6380 - val_categorical_accuracy: 0.5283\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 214us/step - loss: 0.3443 - categorical_accuracy: 0.9065 - val_loss: 2.7502 - val_categorical_accuracy: 0.5055\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 214us/step - loss: 0.3289 - categorical_accuracy: 0.9161 - val_loss: 2.9021 - val_categorical_accuracy: 0.5131\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0318 10:42:32.220121 140371563280192 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 91)                23387     \n",
      "=================================================================\n",
      "Total params: 3,730,331\n",
      "Trainable params: 3,730,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 2s 296us/step - loss: 1.8274 - categorical_accuracy: 0.5385 - val_loss: 1.8305 - val_categorical_accuracy: 0.4855\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 253us/step - loss: 1.4661 - categorical_accuracy: 0.6067 - val_loss: 1.6710 - val_categorical_accuracy: 0.5235\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 239us/step - loss: 1.3495 - categorical_accuracy: 0.6344 - val_loss: 2.0228 - val_categorical_accuracy: 0.4076\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 240us/step - loss: 1.2589 - categorical_accuracy: 0.6590 - val_loss: 1.6249 - val_categorical_accuracy: 0.5525\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 235us/step - loss: 1.1789 - categorical_accuracy: 0.6823 - val_loss: 2.3151 - val_categorical_accuracy: 0.4722\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 258us/step - loss: 1.0782 - categorical_accuracy: 0.7023 - val_loss: 2.0497 - val_categorical_accuracy: 0.5373\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 243us/step - loss: 0.9758 - categorical_accuracy: 0.7304 - val_loss: 1.9239 - val_categorical_accuracy: 0.5017\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 242us/step - loss: 0.9038 - categorical_accuracy: 0.7523 - val_loss: 2.0237 - val_categorical_accuracy: 0.5102\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 239us/step - loss: 0.8223 - categorical_accuracy: 0.7741 - val_loss: 2.0928 - val_categorical_accuracy: 0.4964\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 247us/step - loss: 0.7619 - categorical_accuracy: 0.7950 - val_loss: 3.2042 - val_categorical_accuracy: 0.4736\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 241us/step - loss: 0.7176 - categorical_accuracy: 0.8073 - val_loss: 2.7815 - val_categorical_accuracy: 0.5306\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 239us/step - loss: 0.6816 - categorical_accuracy: 0.8183 - val_loss: 2.8133 - val_categorical_accuracy: 0.4846\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 245us/step - loss: 0.6467 - categorical_accuracy: 0.8253 - val_loss: 2.7741 - val_categorical_accuracy: 0.4964\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 246us/step - loss: 0.6096 - categorical_accuracy: 0.8398 - val_loss: 3.3133 - val_categorical_accuracy: 0.4399\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 242us/step - loss: 0.6238 - categorical_accuracy: 0.8415 - val_loss: 3.1342 - val_categorical_accuracy: 0.4413\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 240us/step - loss: 0.5734 - categorical_accuracy: 0.8533 - val_loss: 3.0643 - val_categorical_accuracy: 0.4660\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 240us/step - loss: 0.5520 - categorical_accuracy: 0.8634 - val_loss: 4.0353 - val_categorical_accuracy: 0.4798\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 247us/step - loss: 0.5563 - categorical_accuracy: 0.8607 - val_loss: 3.4015 - val_categorical_accuracy: 0.4565\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 251us/step - loss: 0.5491 - categorical_accuracy: 0.8664 - val_loss: 3.4748 - val_categorical_accuracy: 0.4670\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 238us/step - loss: 0.5405 - categorical_accuracy: 0.8665 - val_loss: 4.1911 - val_categorical_accuracy: 0.4627\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 494, 64)           44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 92, 32)            14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 91)                11739     \n",
      "=================================================================\n",
      "Total params: 4,293,019\n",
      "Trainable params: 4,293,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 3s 318us/step - loss: 1.8718 - categorical_accuracy: 0.5356 - val_loss: 2.2394 - val_categorical_accuracy: 0.3919\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 269us/step - loss: 1.5240 - categorical_accuracy: 0.6020 - val_loss: 1.8114 - val_categorical_accuracy: 0.5273\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 261us/step - loss: 1.4211 - categorical_accuracy: 0.6182 - val_loss: 2.0263 - val_categorical_accuracy: 0.3815\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 262us/step - loss: 1.3201 - categorical_accuracy: 0.6517 - val_loss: 1.8844 - val_categorical_accuracy: 0.5373\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 260us/step - loss: 1.2414 - categorical_accuracy: 0.6671 - val_loss: 2.4274 - val_categorical_accuracy: 0.5515\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 269us/step - loss: 1.1605 - categorical_accuracy: 0.6797 - val_loss: 1.9837 - val_categorical_accuracy: 0.5211\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 253us/step - loss: 1.0917 - categorical_accuracy: 0.7021 - val_loss: 1.8624 - val_categorical_accuracy: 0.5591\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 257us/step - loss: 1.0169 - categorical_accuracy: 0.7208 - val_loss: 2.5079 - val_categorical_accuracy: 0.5017\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 268us/step - loss: 0.9845 - categorical_accuracy: 0.7356 - val_loss: 2.2326 - val_categorical_accuracy: 0.5050\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 266us/step - loss: 0.9531 - categorical_accuracy: 0.7446 - val_loss: 2.7042 - val_categorical_accuracy: 0.5107\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 258us/step - loss: 0.9212 - categorical_accuracy: 0.7573 - val_loss: 3.0690 - val_categorical_accuracy: 0.4071\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 260us/step - loss: 0.9029 - categorical_accuracy: 0.7634 - val_loss: 3.1936 - val_categorical_accuracy: 0.4627\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 267us/step - loss: 0.8987 - categorical_accuracy: 0.7696 - val_loss: 2.6063 - val_categorical_accuracy: 0.4979\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 262us/step - loss: 0.8579 - categorical_accuracy: 0.7837 - val_loss: 2.7788 - val_categorical_accuracy: 0.4418\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 260us/step - loss: 0.8798 - categorical_accuracy: 0.7851 - val_loss: 2.8937 - val_categorical_accuracy: 0.4546\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 256us/step - loss: 0.8370 - categorical_accuracy: 0.7925 - val_loss: 3.0225 - val_categorical_accuracy: 0.4698\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 268us/step - loss: 0.8485 - categorical_accuracy: 0.7926 - val_loss: 3.9071 - val_categorical_accuracy: 0.4485\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 259us/step - loss: 0.8540 - categorical_accuracy: 0.7933 - val_loss: 2.8822 - val_categorical_accuracy: 0.4575\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 260us/step - loss: 0.8780 - categorical_accuracy: 0.7962 - val_loss: 3.5131 - val_categorical_accuracy: 0.4684\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 255us/step - loss: 0.8420 - categorical_accuracy: 0.7974 - val_loss: 3.3297 - val_categorical_accuracy: 0.4347\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
