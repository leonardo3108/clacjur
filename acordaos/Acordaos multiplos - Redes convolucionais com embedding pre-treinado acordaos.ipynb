{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>arquivo</th>\n",
       "      <th>texto</th>\n",
       "      <th>areas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>547240.txt</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 010.084/2015-0...</td>\n",
       "      <td>Responsabilidade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>549518.txt</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 005.933/2014-5...</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>554399.txt</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 042.038/2012-0...</td>\n",
       "      <td>Responsabilidade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>545010.txt</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 000.742/2014-7...</td>\n",
       "      <td>Direito Processual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>544046.txt</td>\n",
       "      <td>;-;;Wania Lucia Pasquarelli do NascimentoTCUWa...</td>\n",
       "      <td>Pessoal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao     arquivo                                              texto  \\\n",
       "0  297/2016-P  547240.txt  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 010.084/2015-0...   \n",
       "1  366/2016-P  549518.txt  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 005.933/2014-5...   \n",
       "2  944/2016-P  554399.txt  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 042.038/2012-0...   \n",
       "3   30/2016-P  545010.txt  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 000.742/2014-7...   \n",
       "4   55/2016-P  544046.txt  ;-;;Wania Lucia Pasquarelli do NascimentoTCUWa...   \n",
       "\n",
       "                areas  \n",
       "0    Responsabilidade  \n",
       "1   Finanças Públicas  \n",
       "2    Responsabilidade  \n",
       "3  Direito Processual  \n",
       "4             Pessoal  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-selecionada.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10524, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10524, 91)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['areas']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344296 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 350000\n",
    "limite_texto = 40000\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['texto'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['texto'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocabulario = len(word_index) + 1\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10524, 40000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10524, 40000), (10524, 91))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('../vocabularios/modelo-acordaos.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 344296\n",
      "Encontrados no modelo: 90722 = 26.350001161791017\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0316 10:39:04.079303 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0316 10:39:04.151840 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0316 10:39:04.153613 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0316 10:39:04.160598 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0316 10:39:04.161242 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0316 10:39:05.077288 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0316 10:39:05.113540 140301668058944 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0316 10:39:05.194134 140301668058944 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40000, 100)        34429700  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 39994, 32)         22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7998, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 7992, 32)          7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 91)                3003      \n",
      "=================================================================\n",
      "Total params: 34,462,335\n",
      "Trainable params: 32,635\n",
      "Non-trainable params: 34,429,700\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 24s 3ms/step - loss: 2.0260 - categorical_accuracy: 0.4988 - val_loss: 2.0475 - val_categorical_accuracy: 0.3734\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.5677 - categorical_accuracy: 0.5920 - val_loss: 1.8758 - val_categorical_accuracy: 0.4803\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.4752 - categorical_accuracy: 0.6079 - val_loss: 1.6547 - val_categorical_accuracy: 0.5116\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.4050 - categorical_accuracy: 0.6292 - val_loss: 1.6906 - val_categorical_accuracy: 0.4565\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.3255 - categorical_accuracy: 0.6507 - val_loss: 1.6317 - val_categorical_accuracy: 0.5487\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 23s 3ms/step - loss: 1.2496 - categorical_accuracy: 0.6741 - val_loss: 2.0224 - val_categorical_accuracy: 0.4485\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.1895 - categorical_accuracy: 0.6909 - val_loss: 1.7075 - val_categorical_accuracy: 0.4850\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.1414 - categorical_accuracy: 0.7044 - val_loss: 1.7610 - val_categorical_accuracy: 0.5454\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 23s 3ms/step - loss: 1.0758 - categorical_accuracy: 0.7230 - val_loss: 2.1068 - val_categorical_accuracy: 0.3981\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 1.0152 - categorical_accuracy: 0.7398 - val_loss: 2.1444 - val_categorical_accuracy: 0.5283\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.9557 - categorical_accuracy: 0.7566 - val_loss: 2.1152 - val_categorical_accuracy: 0.4518\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.9154 - categorical_accuracy: 0.7690 - val_loss: 1.8877 - val_categorical_accuracy: 0.5264\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.8789 - categorical_accuracy: 0.7761 - val_loss: 1.8773 - val_categorical_accuracy: 0.5620\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 23s 3ms/step - loss: 0.8292 - categorical_accuracy: 0.7888 - val_loss: 2.5129 - val_categorical_accuracy: 0.4280\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.7870 - categorical_accuracy: 0.8018 - val_loss: 2.3893 - val_categorical_accuracy: 0.4632\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.7409 - categorical_accuracy: 0.8159 - val_loss: 2.3781 - val_categorical_accuracy: 0.5140\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.7231 - categorical_accuracy: 0.8171 - val_loss: 2.3681 - val_categorical_accuracy: 0.4964\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.6913 - categorical_accuracy: 0.8266 - val_loss: 3.3097 - val_categorical_accuracy: 0.4285\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.6715 - categorical_accuracy: 0.8332 - val_loss: 2.3055 - val_categorical_accuracy: 0.5249\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 22s 3ms/step - loss: 0.6339 - categorical_accuracy: 0.8468 - val_loss: 2.4182 - val_categorical_accuracy: 0.4945\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 40000, 100)        34429700  \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 39994, 64)         44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7998, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 7992, 32)          14368     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 91)                3003      \n",
      "=================================================================\n",
      "Total params: 34,491,935\n",
      "Trainable params: 34,491,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 63s 7ms/step - loss: 1.9172 - categorical_accuracy: 0.5213 - val_loss: 2.0592 - val_categorical_accuracy: 0.4052\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 1.5048 - categorical_accuracy: 0.6098 - val_loss: 1.6457 - val_categorical_accuracy: 0.5045\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 1.3683 - categorical_accuracy: 0.6495 - val_loss: 1.9816 - val_categorical_accuracy: 0.3392\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 1.2388 - categorical_accuracy: 0.6893 - val_loss: 1.8404 - val_categorical_accuracy: 0.5221\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 1.1068 - categorical_accuracy: 0.7257 - val_loss: 1.7353 - val_categorical_accuracy: 0.5577\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.9876 - categorical_accuracy: 0.7576 - val_loss: 1.7747 - val_categorical_accuracy: 0.5216\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.8701 - categorical_accuracy: 0.7956 - val_loss: 2.0541 - val_categorical_accuracy: 0.4537\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.7433 - categorical_accuracy: 0.8285 - val_loss: 1.9765 - val_categorical_accuracy: 0.5382\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.6375 - categorical_accuracy: 0.8571 - val_loss: 2.3034 - val_categorical_accuracy: 0.4565\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.5532 - categorical_accuracy: 0.8785 - val_loss: 2.4107 - val_categorical_accuracy: 0.5083\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.4774 - categorical_accuracy: 0.8955 - val_loss: 2.6237 - val_categorical_accuracy: 0.5154\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.4179 - categorical_accuracy: 0.9132 - val_loss: 2.5767 - val_categorical_accuracy: 0.4798\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.3745 - categorical_accuracy: 0.9234 - val_loss: 2.3987 - val_categorical_accuracy: 0.5838\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.3361 - categorical_accuracy: 0.9308 - val_loss: 2.4875 - val_categorical_accuracy: 0.5202\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.3006 - categorical_accuracy: 0.9373 - val_loss: 3.8362 - val_categorical_accuracy: 0.4580\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.2820 - categorical_accuracy: 0.9422 - val_loss: 2.7801 - val_categorical_accuracy: 0.5026\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.2603 - categorical_accuracy: 0.9467 - val_loss: 2.6471 - val_categorical_accuracy: 0.5439\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.2396 - categorical_accuracy: 0.9526 - val_loss: 2.9678 - val_categorical_accuracy: 0.4447\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.2234 - categorical_accuracy: 0.9540 - val_loss: 3.0098 - val_categorical_accuracy: 0.5696\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 62s 7ms/step - loss: 0.2230 - categorical_accuracy: 0.9521 - val_loss: 3.1439 - val_categorical_accuracy: 0.5297\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0316 11:07:09.967076 140301668058944 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 40000, 100)        34429700  \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 39994, 64)         44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 7998, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 7992, 32)          14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1598, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51136)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               13091072  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 91)                23387     \n",
      "=================================================================\n",
      "Total params: 47,603,391\n",
      "Trainable params: 47,603,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 66s 8ms/step - loss: 11.4533 - categorical_accuracy: 0.2874 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 65s 8ms/step - loss: 11.4659 - categorical_accuracy: 0.2886 - val_loss: 13.2697 - val_categorical_accuracy: 0.1767\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 40000, 100)        34429700  \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 39994, 64)         44864     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 7998, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 7992, 32)          14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1598, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 51136)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              52364288  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 91)                11739     \n",
      "=================================================================\n",
      "Total params: 86,996,159\n",
      "Trainable params: 86,996,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 73s 9ms/step - loss: 2.3339 - categorical_accuracy: 0.4088 - val_loss: 3.6182 - val_categorical_accuracy: 0.3235\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 1.7263 - categorical_accuracy: 0.5371 - val_loss: 1.8985 - val_categorical_accuracy: 0.4622\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 1.4362 - categorical_accuracy: 0.6036 - val_loss: 1.9522 - val_categorical_accuracy: 0.4342\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 1.1448 - categorical_accuracy: 0.6867 - val_loss: 2.0406 - val_categorical_accuracy: 0.4176\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.8062 - categorical_accuracy: 0.7795 - val_loss: 2.6540 - val_categorical_accuracy: 0.3796\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.5719 - categorical_accuracy: 0.8474 - val_loss: 3.1965 - val_categorical_accuracy: 0.3682\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.4314 - categorical_accuracy: 0.8968 - val_loss: 3.3197 - val_categorical_accuracy: 0.4266\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.3259 - categorical_accuracy: 0.9273 - val_loss: 4.2063 - val_categorical_accuracy: 0.4366\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.2568 - categorical_accuracy: 0.9437 - val_loss: 4.4297 - val_categorical_accuracy: 0.4114\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.2128 - categorical_accuracy: 0.9539 - val_loss: 5.3564 - val_categorical_accuracy: 0.3653\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.2103 - categorical_accuracy: 0.9619 - val_loss: 4.5793 - val_categorical_accuracy: 0.4409\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1712 - categorical_accuracy: 0.9678 - val_loss: 4.8848 - val_categorical_accuracy: 0.4181\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1341 - categorical_accuracy: 0.9743 - val_loss: 5.5595 - val_categorical_accuracy: 0.3815\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1699 - categorical_accuracy: 0.9740 - val_loss: 6.0004 - val_categorical_accuracy: 0.3558\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1257 - categorical_accuracy: 0.9797 - val_loss: 5.5951 - val_categorical_accuracy: 0.3862\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1246 - categorical_accuracy: 0.9793 - val_loss: 5.2192 - val_categorical_accuracy: 0.3720\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1427 - categorical_accuracy: 0.9797 - val_loss: 6.3850 - val_categorical_accuracy: 0.4038\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.2771 - categorical_accuracy: 0.9716 - val_loss: 5.7915 - val_categorical_accuracy: 0.4299\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1444 - categorical_accuracy: 0.9815 - val_loss: 6.6619 - val_categorical_accuracy: 0.3487\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 71s 8ms/step - loss: 0.1113 - categorical_accuracy: 0.9847 - val_loss: 6.3779 - val_categorical_accuracy: 0.3710\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=True))\n",
    "model.add(Conv1D(64, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
