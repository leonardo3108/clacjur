{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>arquivo</th>\n",
       "      <th>areas</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>547240.txt</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 010.084/2015-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>549518.txt</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 005.933/2014-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>554399.txt</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 042.038/2012-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>545010.txt</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 000.742/2014-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>544046.txt</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>;-;;Wania Lucia Pasquarelli do NascimentoTCUWa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao     arquivo               areas  \\\n",
       "0  297/2016-P  547240.txt    Responsabilidade   \n",
       "1  366/2016-P  549518.txt   Finanças Públicas   \n",
       "2  944/2016-P  554399.txt    Responsabilidade   \n",
       "3   30/2016-P  545010.txt  Direito Processual   \n",
       "4   55/2016-P  544046.txt             Pessoal   \n",
       "\n",
       "                                               texto  \n",
       "0  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 010.084/2015-0...  \n",
       "1  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 005.933/2014-5...  \n",
       "2  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 042.038/2012-0...  \n",
       "3  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 000.742/2014-7...  \n",
       "4  ;-;;Wania Lucia Pasquarelli do NascimentoTCUWa...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-unicos.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "areas\n",
       "Competência do TCU          405\n",
       "Contrato Administrativo     549\n",
       "Convênio                    477\n",
       "Desestatização               82\n",
       "Direito Processual         1446\n",
       "Finanças Públicas           199\n",
       "Gestão Administrativa       130\n",
       "Licitação                  1815\n",
       "Pessoal                    2802\n",
       "Responsabilidade           1834\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['areas']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Competência do TCU', 'Contrato Administrativo', 'Convênio', 'Desestatização', 'Direito Processual', 'Finanças Públicas', 'Gestão Administrativa', 'Licitação', 'Pessoal', 'Responsabilidade'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = df.groupby(['areas']).groups.keys()\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318318 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 320000\n",
    "limite_texto = 40000\n",
    "dim_vetor = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['texto'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['texto'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9739, 40000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model-50.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 318318\n",
      "Encontrados no modelo: 110315 = 34.655595976350696\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9739, 40000), (9739, 10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento\n",
    "\n",
    "## Embedding com pesos fixos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0311 20:58:13.164321 140121442830144 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding = Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0311 20:58:13.397454 140121442830144 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0311 20:58:13.399392 140121442830144 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0311 20:58:13.407265 140121442830144 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0311 20:58:13.407787 140121442830144 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0311 20:58:15.860045 140121442830144 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0311 20:58:15.926752 140121442830144 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0311 20:58:16.014409 140121442830144 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40000, 50)         16000000  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000000)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                128000064 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 144,290,122\n",
      "Trainable params: 128,290,122\n",
      "Non-trainable params: 16,000,000\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 44s 6ms/step - loss: 2.6561 - categorical_accuracy: 0.3027 - val_loss: 1.9507 - val_categorical_accuracy: 0.1910\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.9451 - categorical_accuracy: 0.3100 - val_loss: 1.9997 - val_categorical_accuracy: 0.1910\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.9281 - categorical_accuracy: 0.3107 - val_loss: 1.9681 - val_categorical_accuracy: 0.1910\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.9055 - categorical_accuracy: 0.3116 - val_loss: 1.9817 - val_categorical_accuracy: 0.1910\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.8979 - categorical_accuracy: 0.3118 - val_loss: 1.9692 - val_categorical_accuracy: 0.1910\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.8587 - categorical_accuracy: 0.3102 - val_loss: 2.0007 - val_categorical_accuracy: 0.1150\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.8392 - categorical_accuracy: 0.3084 - val_loss: 1.9571 - val_categorical_accuracy: 0.1910\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.8225 - categorical_accuracy: 0.3028 - val_loss: 1.9109 - val_categorical_accuracy: 0.1910\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.8055 - categorical_accuracy: 0.3122 - val_loss: 1.9350 - val_categorical_accuracy: 0.1910\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7847 - categorical_accuracy: 0.3116 - val_loss: 1.9386 - val_categorical_accuracy: 0.1910\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7833 - categorical_accuracy: 0.3157 - val_loss: 1.9048 - val_categorical_accuracy: 0.1853\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7627 - categorical_accuracy: 0.3182 - val_loss: 1.8815 - val_categorical_accuracy: 0.1792\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7716 - categorical_accuracy: 0.3136 - val_loss: 1.8066 - val_categorical_accuracy: 0.2469\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7572 - categorical_accuracy: 0.3312 - val_loss: 1.8482 - val_categorical_accuracy: 0.2002\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7634 - categorical_accuracy: 0.3322 - val_loss: 1.8621 - val_categorical_accuracy: 0.1905\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7498 - categorical_accuracy: 0.3268 - val_loss: 1.8067 - val_categorical_accuracy: 0.2182\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7331 - categorical_accuracy: 0.3373 - val_loss: 1.8205 - val_categorical_accuracy: 0.2187\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7300 - categorical_accuracy: 0.3439 - val_loss: 1.8738 - val_categorical_accuracy: 0.1853\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7282 - categorical_accuracy: 0.3414 - val_loss: 2.0691 - val_categorical_accuracy: 0.1910\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 40s 5ms/step - loss: 1.7191 - categorical_accuracy: 0.3481 - val_loss: 1.8080 - val_categorical_accuracy: 0.2546\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.7163 - categorical_accuracy: 0.3501 - val_loss: 1.8788 - val_categorical_accuracy: 0.1709\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.7076 - categorical_accuracy: 0.3489 - val_loss: 1.8262 - val_categorical_accuracy: 0.2146\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.7042 - categorical_accuracy: 0.3536 - val_loss: 1.7643 - val_categorical_accuracy: 0.2500\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.7069 - categorical_accuracy: 0.3591 - val_loss: 1.7822 - val_categorical_accuracy: 0.2567\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.7026 - categorical_accuracy: 0.3552 - val_loss: 1.7629 - val_categorical_accuracy: 0.2305\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6948 - categorical_accuracy: 0.3572 - val_loss: 1.7827 - val_categorical_accuracy: 0.2325\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.7007 - categorical_accuracy: 0.3604 - val_loss: 1.7736 - val_categorical_accuracy: 0.2295\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6741 - categorical_accuracy: 0.3661 - val_loss: 3.4421 - val_categorical_accuracy: 0.2556\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6896 - categorical_accuracy: 0.3685 - val_loss: 1.8953 - val_categorical_accuracy: 0.1520\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6847 - categorical_accuracy: 0.3664 - val_loss: 1.7901 - val_categorical_accuracy: 0.2680\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6837 - categorical_accuracy: 0.3618 - val_loss: 1.8129 - val_categorical_accuracy: 0.2633\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6762 - categorical_accuracy: 0.3654 - val_loss: 1.7159 - val_categorical_accuracy: 0.2572\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6658 - categorical_accuracy: 0.3703 - val_loss: 1.7556 - val_categorical_accuracy: 0.2490\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6763 - categorical_accuracy: 0.3653 - val_loss: 1.7798 - val_categorical_accuracy: 0.2664\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6906 - categorical_accuracy: 0.3609 - val_loss: 1.7853 - val_categorical_accuracy: 0.2449\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6683 - categorical_accuracy: 0.3699 - val_loss: 1.7534 - val_categorical_accuracy: 0.2556\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6734 - categorical_accuracy: 0.3691 - val_loss: 1.7554 - val_categorical_accuracy: 0.2531\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6701 - categorical_accuracy: 0.3702 - val_loss: 1.7438 - val_categorical_accuracy: 0.2469\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6672 - categorical_accuracy: 0.3680 - val_loss: 1.8294 - val_categorical_accuracy: 0.2038\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.6584 - categorical_accuracy: 0.3744 - val_loss: 1.7949 - val_categorical_accuracy: 0.2310\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
