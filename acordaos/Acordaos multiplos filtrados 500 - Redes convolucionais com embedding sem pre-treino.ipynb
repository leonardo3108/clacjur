{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>areas</th>\n",
       "      <th>filtrado_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>conta conta gerência instituto nacional seguro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>senado petróleo petróleo regime aduaneiro expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>tribunal conta plenário embargo declaração aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>embargo declaração inss recorrente marco antôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>senac senac senac empresa senac giselle araújo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao               areas  \\\n",
       "0  297/2016-P    Responsabilidade   \n",
       "1  366/2016-P   Finanças Públicas   \n",
       "2  944/2016-P    Responsabilidade   \n",
       "3   30/2016-P  Direito Processual   \n",
       "4   55/2016-P             Pessoal   \n",
       "\n",
       "                                        filtrado_500  \n",
       "0  conta conta gerência instituto nacional seguro...  \n",
       "1  senado petróleo petróleo regime aduaneiro expo...  \n",
       "2  tribunal conta plenário embargo declaração aco...  \n",
       "3  embargo declaração inss recorrente marco antôn...  \n",
       "4  senac senac senac empresa senac giselle araújo...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-selecionada-filtrados-500.csv', sep = '|')\n",
    "df['filtrado_500']=df['filtrado_500'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10524, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10524, 91)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['areas']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33339 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 35000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado_500'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado_500'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10524, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10524, 500), (10524, 91))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0314 19:30:21.801186 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0314 19:30:21.834861 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0314 19:30:21.838189 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0314 19:30:21.883604 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0314 19:30:21.902296 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0314 19:30:21.909354 140089484011328 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0314 19:30:21.940982 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0314 19:30:21.946850 140089484011328 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0314 19:30:22.028043 140089484011328 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 91)                23387     \n",
      "=================================================================\n",
      "Total params: 4,348,891\n",
      "Trainable params: 4,348,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 8s 987us/step - loss: 1.6825 - categorical_accuracy: 0.5400 - val_loss: 1.6390 - val_categorical_accuracy: 0.5278\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 1.2857 - categorical_accuracy: 0.6475 - val_loss: 1.5362 - val_categorical_accuracy: 0.5572\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 1.0527 - categorical_accuracy: 0.7225 - val_loss: 1.6266 - val_categorical_accuracy: 0.5525\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 217us/step - loss: 0.8437 - categorical_accuracy: 0.7825 - val_loss: 1.7841 - val_categorical_accuracy: 0.5340\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 223us/step - loss: 0.6502 - categorical_accuracy: 0.8282 - val_loss: 1.9351 - val_categorical_accuracy: 0.5715\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 228us/step - loss: 0.4987 - categorical_accuracy: 0.8661 - val_loss: 2.3068 - val_categorical_accuracy: 0.5349\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 222us/step - loss: 0.3883 - categorical_accuracy: 0.8979 - val_loss: 2.4404 - val_categorical_accuracy: 0.4964\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 213us/step - loss: 0.3086 - categorical_accuracy: 0.9217 - val_loss: 2.7910 - val_categorical_accuracy: 0.5083\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 223us/step - loss: 0.2495 - categorical_accuracy: 0.9399 - val_loss: 3.2339 - val_categorical_accuracy: 0.4689\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 216us/step - loss: 0.2109 - categorical_accuracy: 0.9517 - val_loss: 3.1986 - val_categorical_accuracy: 0.4722\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 224us/step - loss: 0.1862 - categorical_accuracy: 0.9561 - val_loss: 3.5479 - val_categorical_accuracy: 0.4888\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 223us/step - loss: 0.1652 - categorical_accuracy: 0.9609 - val_loss: 3.9810 - val_categorical_accuracy: 0.4432\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 0.1439 - categorical_accuracy: 0.9663 - val_loss: 3.7117 - val_categorical_accuracy: 0.4836\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 213us/step - loss: 0.1320 - categorical_accuracy: 0.9688 - val_loss: 4.0558 - val_categorical_accuracy: 0.4646\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 224us/step - loss: 0.1228 - categorical_accuracy: 0.9730 - val_loss: 3.9284 - val_categorical_accuracy: 0.4855\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 217us/step - loss: 0.1114 - categorical_accuracy: 0.9747 - val_loss: 3.8892 - val_categorical_accuracy: 0.4912\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 0.0993 - categorical_accuracy: 0.9779 - val_loss: 3.9570 - val_categorical_accuracy: 0.4926\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 0.0905 - categorical_accuracy: 0.9797 - val_loss: 4.1258 - val_categorical_accuracy: 0.5021\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 213us/step - loss: 0.0877 - categorical_accuracy: 0.9802 - val_loss: 4.3290 - val_categorical_accuracy: 0.5040\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 0.0735 - categorical_accuracy: 0.9818 - val_loss: 4.2346 - val_categorical_accuracy: 0.4955\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 91)                11739     \n",
      "=================================================================\n",
      "Total params: 3,935,707\n",
      "Trainable params: 3,935,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 2s 253us/step - loss: 1.7434 - categorical_accuracy: 0.5264 - val_loss: 1.6348 - val_categorical_accuracy: 0.5492\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 202us/step - loss: 1.3385 - categorical_accuracy: 0.6339 - val_loss: 1.5612 - val_categorical_accuracy: 0.5273\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 207us/step - loss: 1.1206 - categorical_accuracy: 0.7026 - val_loss: 1.6746 - val_categorical_accuracy: 0.5164\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 207us/step - loss: 0.9229 - categorical_accuracy: 0.7589 - val_loss: 1.7342 - val_categorical_accuracy: 0.5515\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 209us/step - loss: 0.7509 - categorical_accuracy: 0.8021 - val_loss: 1.8578 - val_categorical_accuracy: 0.5335\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 211us/step - loss: 0.5984 - categorical_accuracy: 0.8394 - val_loss: 2.1246 - val_categorical_accuracy: 0.5230\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 205us/step - loss: 0.4782 - categorical_accuracy: 0.8735 - val_loss: 2.1722 - val_categorical_accuracy: 0.5577\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 0.3914 - categorical_accuracy: 0.8957 - val_loss: 2.8408 - val_categorical_accuracy: 0.5059\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 200us/step - loss: 0.3227 - categorical_accuracy: 0.9128 - val_loss: 2.8964 - val_categorical_accuracy: 0.5211\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 209us/step - loss: 0.2734 - categorical_accuracy: 0.9285 - val_loss: 2.7580 - val_categorical_accuracy: 0.5140\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 218us/step - loss: 0.2407 - categorical_accuracy: 0.9393 - val_loss: 3.0487 - val_categorical_accuracy: 0.5401\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 0.2025 - categorical_accuracy: 0.9495 - val_loss: 3.1919 - val_categorical_accuracy: 0.5321\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 208us/step - loss: 0.1831 - categorical_accuracy: 0.9546 - val_loss: 3.2757 - val_categorical_accuracy: 0.4789\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 213us/step - loss: 0.1655 - categorical_accuracy: 0.9596 - val_loss: 3.6732 - val_categorical_accuracy: 0.4855\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 218us/step - loss: 0.1547 - categorical_accuracy: 0.9613 - val_loss: 3.4953 - val_categorical_accuracy: 0.5040\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 214us/step - loss: 0.1415 - categorical_accuracy: 0.9676 - val_loss: 3.7778 - val_categorical_accuracy: 0.4675\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 207us/step - loss: 0.1321 - categorical_accuracy: 0.9685 - val_loss: 3.9199 - val_categorical_accuracy: 0.4679\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 0.1199 - categorical_accuracy: 0.9714 - val_loss: 4.0112 - val_categorical_accuracy: 0.4713\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 219us/step - loss: 0.1165 - categorical_accuracy: 0.9730 - val_loss: 4.2236 - val_categorical_accuracy: 0.4898\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 0.1040 - categorical_accuracy: 0.9746 - val_loss: 4.2289 - val_categorical_accuracy: 0.4903\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 91)                11739     \n",
      "=================================================================\n",
      "Total params: 6,877,659\n",
      "Trainable params: 6,877,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 3s 343us/step - loss: 1.7578 - categorical_accuracy: 0.5290 - val_loss: 1.5730 - val_categorical_accuracy: 0.5653\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 280us/step - loss: 1.3341 - categorical_accuracy: 0.6402 - val_loss: 1.8324 - val_categorical_accuracy: 0.4470\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 275us/step - loss: 1.0887 - categorical_accuracy: 0.7122 - val_loss: 1.7345 - val_categorical_accuracy: 0.5273\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 277us/step - loss: 0.8366 - categorical_accuracy: 0.7862 - val_loss: 2.0613 - val_categorical_accuracy: 0.5126\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 281us/step - loss: 0.6163 - categorical_accuracy: 0.8392 - val_loss: 2.1637 - val_categorical_accuracy: 0.5439\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 295us/step - loss: 0.4883 - categorical_accuracy: 0.8703 - val_loss: 2.6560 - val_categorical_accuracy: 0.5135\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 286us/step - loss: 0.4059 - categorical_accuracy: 0.8992 - val_loss: 3.0272 - val_categorical_accuracy: 0.4850\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 270us/step - loss: 0.3597 - categorical_accuracy: 0.9121 - val_loss: 3.1508 - val_categorical_accuracy: 0.5026\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 293us/step - loss: 0.3024 - categorical_accuracy: 0.9241 - val_loss: 3.7305 - val_categorical_accuracy: 0.4518\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 276us/step - loss: 0.2867 - categorical_accuracy: 0.9305 - val_loss: 3.8493 - val_categorical_accuracy: 0.4542\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 283us/step - loss: 0.2632 - categorical_accuracy: 0.9391 - val_loss: 4.0672 - val_categorical_accuracy: 0.4257\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 270us/step - loss: 0.2422 - categorical_accuracy: 0.9433 - val_loss: 4.1960 - val_categorical_accuracy: 0.4480\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 278us/step - loss: 0.2286 - categorical_accuracy: 0.9448 - val_loss: 4.0993 - val_categorical_accuracy: 0.4608\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 273us/step - loss: 0.2309 - categorical_accuracy: 0.9457 - val_loss: 4.3183 - val_categorical_accuracy: 0.5131\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 287us/step - loss: 0.2165 - categorical_accuracy: 0.9506 - val_loss: 4.6376 - val_categorical_accuracy: 0.4038\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 285us/step - loss: 0.2108 - categorical_accuracy: 0.9507 - val_loss: 4.5741 - val_categorical_accuracy: 0.4138\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 297us/step - loss: 0.1951 - categorical_accuracy: 0.9581 - val_loss: 3.9960 - val_categorical_accuracy: 0.4456\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 292us/step - loss: 0.2079 - categorical_accuracy: 0.9562 - val_loss: 4.6023 - val_categorical_accuracy: 0.4551\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 283us/step - loss: 0.2097 - categorical_accuracy: 0.9577 - val_loss: 4.7127 - val_categorical_accuracy: 0.4304\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 287us/step - loss: 0.1975 - categorical_accuracy: 0.9577 - val_loss: 4.2803 - val_categorical_accuracy: 0.4879\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          3500000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 46, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1472)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               377088    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 91)                23387     \n",
      "=================================================================\n",
      "Total params: 3,930,107\n",
      "Trainable params: 3,930,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8419 samples, validate on 2105 samples\n",
      "Epoch 1/20\n",
      "8419/8419 [==============================] - 2s 278us/step - loss: 1.7871 - categorical_accuracy: 0.5428 - val_loss: 1.8180 - val_categorical_accuracy: 0.4105\n",
      "Epoch 2/20\n",
      "8419/8419 [==============================] - 2s 228us/step - loss: 1.5056 - categorical_accuracy: 0.6136 - val_loss: 1.7080 - val_categorical_accuracy: 0.4950\n",
      "Epoch 3/20\n",
      "8419/8419 [==============================] - 2s 216us/step - loss: 1.4211 - categorical_accuracy: 0.6433 - val_loss: 2.1172 - val_categorical_accuracy: 0.4504\n",
      "Epoch 4/20\n",
      "8419/8419 [==============================] - 2s 223us/step - loss: 1.3560 - categorical_accuracy: 0.6558 - val_loss: 1.9415 - val_categorical_accuracy: 0.5188\n",
      "Epoch 5/20\n",
      "8419/8419 [==============================] - 2s 217us/step - loss: 1.2952 - categorical_accuracy: 0.6774 - val_loss: 2.1622 - val_categorical_accuracy: 0.5321\n",
      "Epoch 6/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 1.2256 - categorical_accuracy: 0.6890 - val_loss: 2.1568 - val_categorical_accuracy: 0.5026\n",
      "Epoch 7/20\n",
      "8419/8419 [==============================] - 2s 225us/step - loss: 1.1765 - categorical_accuracy: 0.7153 - val_loss: 2.8347 - val_categorical_accuracy: 0.4803\n",
      "Epoch 8/20\n",
      "8419/8419 [==============================] - 2s 222us/step - loss: 1.2121 - categorical_accuracy: 0.7276 - val_loss: 2.6389 - val_categorical_accuracy: 0.5007\n",
      "Epoch 9/20\n",
      "8419/8419 [==============================] - 2s 214us/step - loss: 1.2470 - categorical_accuracy: 0.7270 - val_loss: 2.9813 - val_categorical_accuracy: 0.4399\n",
      "Epoch 10/20\n",
      "8419/8419 [==============================] - 2s 212us/step - loss: 1.2403 - categorical_accuracy: 0.7398 - val_loss: 3.2976 - val_categorical_accuracy: 0.4608\n",
      "Epoch 11/20\n",
      "8419/8419 [==============================] - 2s 233us/step - loss: 1.2134 - categorical_accuracy: 0.7392 - val_loss: 2.5851 - val_categorical_accuracy: 0.5268\n",
      "Epoch 12/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 1.1987 - categorical_accuracy: 0.7475 - val_loss: 2.6845 - val_categorical_accuracy: 0.4323\n",
      "Epoch 13/20\n",
      "8419/8419 [==============================] - 2s 216us/step - loss: 1.1705 - categorical_accuracy: 0.7503 - val_loss: 2.4768 - val_categorical_accuracy: 0.4451\n",
      "Epoch 14/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 1.2970 - categorical_accuracy: 0.7475 - val_loss: 2.8976 - val_categorical_accuracy: 0.4931\n",
      "Epoch 15/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 1.3533 - categorical_accuracy: 0.7529 - val_loss: 2.7772 - val_categorical_accuracy: 0.5131\n",
      "Epoch 16/20\n",
      "8419/8419 [==============================] - 2s 225us/step - loss: 1.2741 - categorical_accuracy: 0.7576 - val_loss: 3.1995 - val_categorical_accuracy: 0.4556\n",
      "Epoch 17/20\n",
      "8419/8419 [==============================] - 2s 223us/step - loss: 1.3585 - categorical_accuracy: 0.7558 - val_loss: 3.4134 - val_categorical_accuracy: 0.4979\n",
      "Epoch 18/20\n",
      "8419/8419 [==============================] - 2s 220us/step - loss: 1.3294 - categorical_accuracy: 0.7526 - val_loss: 3.7841 - val_categorical_accuracy: 0.5059\n",
      "Epoch 19/20\n",
      "8419/8419 [==============================] - 2s 221us/step - loss: 1.2922 - categorical_accuracy: 0.7594 - val_loss: 3.0856 - val_categorical_accuracy: 0.4855\n",
      "Epoch 20/20\n",
      "8419/8419 [==============================] - 2s 215us/step - loss: 1.4145 - categorical_accuracy: 0.7541 - val_loss: 2.7357 - val_categorical_accuracy: 0.3249\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=5e-3),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
