{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>areas</th>\n",
       "      <th>filtrado_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>conta conta gerência instituto nacional seguro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>senado petróleo petróleo regime aduaneiro expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>tribunal conta plenário embargo declaração aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>embargo declaração inss recorrente marco antôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>senac senac senac empresa senac giselle araújo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao               areas  \\\n",
       "0  297/2016-P    Responsabilidade   \n",
       "1  366/2016-P   Finanças Públicas   \n",
       "2  944/2016-P    Responsabilidade   \n",
       "3   30/2016-P  Direito Processual   \n",
       "4   55/2016-P             Pessoal   \n",
       "\n",
       "                                        filtrado_500  \n",
       "0  conta conta gerência instituto nacional seguro...  \n",
       "1  senado petróleo petróleo regime aduaneiro expo...  \n",
       "2  tribunal conta plenário embargo declaração aco...  \n",
       "3  embargo declaração inss recorrente marco antôn...  \n",
       "4  senac senac senac empresa senac giselle araújo...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-unicos-filtrados-500.csv', sep = '|')\n",
    "df['filtrado_500']=df['filtrado_500'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['areas']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32293 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 40000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado_500'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado_500'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9739, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9739, 500), (9739, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0312 21:52:56.737843 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0312 21:52:56.759804 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0312 21:52:56.761871 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0312 21:52:56.788939 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0312 21:52:56.809366 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0312 21:52:56.817259 140453498459968 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0312 21:52:56.857168 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0312 21:52:56.863486 140453498459968 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0312 21:52:56.944568 140453498459968 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,828,074\n",
      "Trainable params: 4,828,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 4s 485us/step - loss: 1.1484 - categorical_accuracy: 0.6017 - val_loss: 1.2718 - val_categorical_accuracy: 0.5703\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 2s 230us/step - loss: 0.8225 - categorical_accuracy: 0.7233 - val_loss: 1.1922 - val_categorical_accuracy: 0.6099\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 2s 227us/step - loss: 0.6076 - categorical_accuracy: 0.8016 - val_loss: 1.2983 - val_categorical_accuracy: 0.6047\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 2s 217us/step - loss: 0.4015 - categorical_accuracy: 0.8760 - val_loss: 1.4983 - val_categorical_accuracy: 0.5903\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 2s 221us/step - loss: 0.2472 - categorical_accuracy: 0.9244 - val_loss: 1.9496 - val_categorical_accuracy: 0.5524\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 2s 228us/step - loss: 0.1419 - categorical_accuracy: 0.9540 - val_loss: 2.2507 - val_categorical_accuracy: 0.5344\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 2s 219us/step - loss: 0.0843 - categorical_accuracy: 0.9737 - val_loss: 2.4877 - val_categorical_accuracy: 0.5560\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 2s 222us/step - loss: 0.0541 - categorical_accuracy: 0.9820 - val_loss: 3.0038 - val_categorical_accuracy: 0.5375\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 2s 230us/step - loss: 0.0448 - categorical_accuracy: 0.9856 - val_loss: 3.2499 - val_categorical_accuracy: 0.5406\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 2s 230us/step - loss: 0.0341 - categorical_accuracy: 0.9891 - val_loss: 3.5847 - val_categorical_accuracy: 0.5467\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 2s 233us/step - loss: 0.0275 - categorical_accuracy: 0.9908 - val_loss: 4.3977 - val_categorical_accuracy: 0.5180\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 2s 226us/step - loss: 0.0219 - categorical_accuracy: 0.9929 - val_loss: 4.1367 - val_categorical_accuracy: 0.5246\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 2s 221us/step - loss: 0.0217 - categorical_accuracy: 0.9929 - val_loss: 4.0759 - val_categorical_accuracy: 0.5524\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 2s 219us/step - loss: 0.0184 - categorical_accuracy: 0.9932 - val_loss: 4.5157 - val_categorical_accuracy: 0.5390\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 2s 232us/step - loss: 0.0191 - categorical_accuracy: 0.9929 - val_loss: 4.3905 - val_categorical_accuracy: 0.5595\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 2s 235us/step - loss: 0.0225 - categorical_accuracy: 0.9932 - val_loss: 4.5919 - val_categorical_accuracy: 0.5385\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 2s 251us/step - loss: 0.0169 - categorical_accuracy: 0.9938 - val_loss: 5.0184 - val_categorical_accuracy: 0.5133\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 2s 230us/step - loss: 0.0191 - categorical_accuracy: 0.9938 - val_loss: 4.6444 - val_categorical_accuracy: 0.5560\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 2s 243us/step - loss: 0.0177 - categorical_accuracy: 0.9941 - val_loss: 4.8342 - val_categorical_accuracy: 0.5560\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 2s 227us/step - loss: 0.0191 - categorical_accuracy: 0.9933 - val_loss: 4.8004 - val_categorical_accuracy: 0.5518\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 5,633,706\n",
      "Trainable params: 5,633,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 2s 282us/step - loss: 1.1552 - categorical_accuracy: 0.6071 - val_loss: 1.5467 - val_categorical_accuracy: 0.4240\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 2s 231us/step - loss: 0.7980 - categorical_accuracy: 0.7337 - val_loss: 1.2841 - val_categorical_accuracy: 0.5549\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 2s 244us/step - loss: 0.5250 - categorical_accuracy: 0.8272 - val_loss: 1.5629 - val_categorical_accuracy: 0.5513\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 2s 249us/step - loss: 0.3025 - categorical_accuracy: 0.9068 - val_loss: 1.7347 - val_categorical_accuracy: 0.5714\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 2s 247us/step - loss: 0.1619 - categorical_accuracy: 0.9514 - val_loss: 2.3147 - val_categorical_accuracy: 0.5026\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 2s 234us/step - loss: 0.0916 - categorical_accuracy: 0.9687 - val_loss: 2.3997 - val_categorical_accuracy: 0.5560\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 2s 239us/step - loss: 0.0580 - categorical_accuracy: 0.9820 - val_loss: 2.8859 - val_categorical_accuracy: 0.5575\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 2s 250us/step - loss: 0.0415 - categorical_accuracy: 0.9867 - val_loss: 3.7089 - val_categorical_accuracy: 0.5169\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 2s 244us/step - loss: 0.0373 - categorical_accuracy: 0.9873 - val_loss: 3.5523 - val_categorical_accuracy: 0.5370\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 2s 236us/step - loss: 0.0302 - categorical_accuracy: 0.9905 - val_loss: 3.6904 - val_categorical_accuracy: 0.5714\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 2s 236us/step - loss: 0.0235 - categorical_accuracy: 0.9922 - val_loss: 3.7488 - val_categorical_accuracy: 0.5708\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 2s 239us/step - loss: 0.0263 - categorical_accuracy: 0.9915 - val_loss: 4.1711 - val_categorical_accuracy: 0.5606\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 2s 251us/step - loss: 0.0221 - categorical_accuracy: 0.9926 - val_loss: 4.6032 - val_categorical_accuracy: 0.5452\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 2s 235us/step - loss: 0.0191 - categorical_accuracy: 0.9935 - val_loss: 4.5160 - val_categorical_accuracy: 0.5431\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 2s 238us/step - loss: 0.0233 - categorical_accuracy: 0.9932 - val_loss: 4.5300 - val_categorical_accuracy: 0.5539\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 2s 233us/step - loss: 0.0212 - categorical_accuracy: 0.9936 - val_loss: 4.5492 - val_categorical_accuracy: 0.5642\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 2s 242us/step - loss: 0.0195 - categorical_accuracy: 0.9931 - val_loss: 4.5299 - val_categorical_accuracy: 0.5708\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 2s 245us/step - loss: 0.0207 - categorical_accuracy: 0.9941 - val_loss: 4.9834 - val_categorical_accuracy: 0.5447\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 2s 236us/step - loss: 0.0190 - categorical_accuracy: 0.9936 - val_loss: 4.8748 - val_categorical_accuracy: 0.5544\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 2s 248us/step - loss: 0.0139 - categorical_accuracy: 0.9950 - val_loss: 5.1698 - val_categorical_accuracy: 0.5467\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,425,258\n",
      "Trainable params: 4,425,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 2s 275us/step - loss: 1.1736 - categorical_accuracy: 0.5970 - val_loss: 1.2745 - val_categorical_accuracy: 0.5873\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 2s 218us/step - loss: 0.8599 - categorical_accuracy: 0.7136 - val_loss: 1.2452 - val_categorical_accuracy: 0.5703\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 2s 221us/step - loss: 0.6402 - categorical_accuracy: 0.7840 - val_loss: 1.5469 - val_categorical_accuracy: 0.5015\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 2s 217us/step - loss: 0.4520 - categorical_accuracy: 0.8586 - val_loss: 1.8564 - val_categorical_accuracy: 0.4810\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 2s 220us/step - loss: 0.2970 - categorical_accuracy: 0.9081 - val_loss: 1.7557 - val_categorical_accuracy: 0.5796\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 2s 213us/step - loss: 0.1921 - categorical_accuracy: 0.9408 - val_loss: 1.9688 - val_categorical_accuracy: 0.5657\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 2s 214us/step - loss: 0.1280 - categorical_accuracy: 0.9620 - val_loss: 2.1702 - val_categorical_accuracy: 0.5811\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 2s 214us/step - loss: 0.0864 - categorical_accuracy: 0.9719 - val_loss: 2.5270 - val_categorical_accuracy: 0.5693\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 2s 218us/step - loss: 0.0619 - categorical_accuracy: 0.9805 - val_loss: 2.9391 - val_categorical_accuracy: 0.5483\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 2s 217us/step - loss: 0.0423 - categorical_accuracy: 0.9859 - val_loss: 3.3960 - val_categorical_accuracy: 0.5585\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 2s 220us/step - loss: 0.0366 - categorical_accuracy: 0.9891 - val_loss: 3.5453 - val_categorical_accuracy: 0.5380\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 2s 228us/step - loss: 0.0315 - categorical_accuracy: 0.9901 - val_loss: 3.8674 - val_categorical_accuracy: 0.5380\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 2s 224us/step - loss: 0.0261 - categorical_accuracy: 0.9914 - val_loss: 4.3121 - val_categorical_accuracy: 0.5226\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 2s 219us/step - loss: 0.0209 - categorical_accuracy: 0.9929 - val_loss: 4.1179 - val_categorical_accuracy: 0.5524\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 2s 225us/step - loss: 0.0223 - categorical_accuracy: 0.9924 - val_loss: 4.3949 - val_categorical_accuracy: 0.5385\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 2s 223us/step - loss: 0.0188 - categorical_accuracy: 0.9932 - val_loss: 4.2353 - val_categorical_accuracy: 0.5498\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 2s 218us/step - loss: 0.0169 - categorical_accuracy: 0.9932 - val_loss: 4.2749 - val_categorical_accuracy: 0.5580\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 2s 234us/step - loss: 0.0200 - categorical_accuracy: 0.9927 - val_loss: 4.4960 - val_categorical_accuracy: 0.5554\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 2s 225us/step - loss: 0.0182 - categorical_accuracy: 0.9940 - val_loss: 4.8779 - val_categorical_accuracy: 0.5318\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 2s 218us/step - loss: 0.0175 - categorical_accuracy: 0.9940 - val_loss: 4.6146 - val_categorical_accuracy: 0.5508\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 7,367,210\n",
      "Trainable params: 7,367,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 3s 358us/step - loss: 1.2193 - categorical_accuracy: 0.5802 - val_loss: 1.2771 - val_categorical_accuracy: 0.5934\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 2s 282us/step - loss: 0.9129 - categorical_accuracy: 0.6875 - val_loss: 1.2562 - val_categorical_accuracy: 0.5929\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 2s 282us/step - loss: 0.6992 - categorical_accuracy: 0.7711 - val_loss: 1.4332 - val_categorical_accuracy: 0.5821\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 2s 280us/step - loss: 0.4583 - categorical_accuracy: 0.8514 - val_loss: 1.5761 - val_categorical_accuracy: 0.5524\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 2s 290us/step - loss: 0.2729 - categorical_accuracy: 0.9130 - val_loss: 2.3272 - val_categorical_accuracy: 0.5118\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 2s 288us/step - loss: 0.1460 - categorical_accuracy: 0.9535 - val_loss: 2.4222 - val_categorical_accuracy: 0.5349\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 2s 295us/step - loss: 0.0943 - categorical_accuracy: 0.9706 - val_loss: 3.0469 - val_categorical_accuracy: 0.5139\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 2s 286us/step - loss: 0.0564 - categorical_accuracy: 0.9801 - val_loss: 3.3419 - val_categorical_accuracy: 0.5231\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 2s 290us/step - loss: 0.0508 - categorical_accuracy: 0.9840 - val_loss: 4.0988 - val_categorical_accuracy: 0.5267\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 2s 285us/step - loss: 0.0532 - categorical_accuracy: 0.9858 - val_loss: 3.9270 - val_categorical_accuracy: 0.5544\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 2s 291us/step - loss: 0.0380 - categorical_accuracy: 0.9883 - val_loss: 4.4982 - val_categorical_accuracy: 0.5252\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 2s 286us/step - loss: 0.0359 - categorical_accuracy: 0.9902 - val_loss: 4.5771 - val_categorical_accuracy: 0.5560\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 2s 277us/step - loss: 0.0351 - categorical_accuracy: 0.9905 - val_loss: 4.8131 - val_categorical_accuracy: 0.5385\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 2s 277us/step - loss: 0.0429 - categorical_accuracy: 0.9895 - val_loss: 4.4354 - val_categorical_accuracy: 0.5708\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 2s 298us/step - loss: 0.0367 - categorical_accuracy: 0.9905 - val_loss: 5.2205 - val_categorical_accuracy: 0.5128\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 2s 290us/step - loss: 0.0313 - categorical_accuracy: 0.9915 - val_loss: 5.1819 - val_categorical_accuracy: 0.5051\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 2s 294us/step - loss: 0.0351 - categorical_accuracy: 0.9908 - val_loss: 5.5507 - val_categorical_accuracy: 0.5010\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 2s 296us/step - loss: 0.0327 - categorical_accuracy: 0.9914 - val_loss: 5.1202 - val_categorical_accuracy: 0.5344\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 2s 286us/step - loss: 0.0308 - categorical_accuracy: 0.9922 - val_loss: 5.0579 - val_categorical_accuracy: 0.5436\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 2s 277us/step - loss: 0.0225 - categorical_accuracy: 0.9935 - val_loss: 5.3921 - val_categorical_accuracy: 0.5287\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 46, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1472)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               377088    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,409,290\n",
      "Trainable params: 4,409,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 2s 310us/step - loss: 1.2506 - categorical_accuracy: 0.5957 - val_loss: 1.4671 - val_categorical_accuracy: 0.5667\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 2s 222us/step - loss: 1.0096 - categorical_accuracy: 0.6768 - val_loss: 1.5431 - val_categorical_accuracy: 0.5503\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 2s 221us/step - loss: 0.8842 - categorical_accuracy: 0.7147 - val_loss: 1.5590 - val_categorical_accuracy: 0.5406\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 2s 229us/step - loss: 0.7638 - categorical_accuracy: 0.7624 - val_loss: 2.0456 - val_categorical_accuracy: 0.5354\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 2s 242us/step - loss: 0.6512 - categorical_accuracy: 0.7984 - val_loss: 1.6717 - val_categorical_accuracy: 0.5041\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 2s 231us/step - loss: 0.5529 - categorical_accuracy: 0.8337 - val_loss: 1.9915 - val_categorical_accuracy: 0.4707\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 2s 221us/step - loss: 0.4768 - categorical_accuracy: 0.8570 - val_loss: 2.5075 - val_categorical_accuracy: 0.5236\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 2s 219us/step - loss: 0.4235 - categorical_accuracy: 0.8819 - val_loss: 2.6812 - val_categorical_accuracy: 0.4754\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 2s 226us/step - loss: 0.4124 - categorical_accuracy: 0.8930 - val_loss: 2.7380 - val_categorical_accuracy: 0.5036\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 2s 221us/step - loss: 0.3462 - categorical_accuracy: 0.9080 - val_loss: 2.9518 - val_categorical_accuracy: 0.4553\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 2s 232us/step - loss: 0.3626 - categorical_accuracy: 0.9146 - val_loss: 3.0219 - val_categorical_accuracy: 0.4122\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 2s 235us/step - loss: 0.3412 - categorical_accuracy: 0.9185 - val_loss: 3.5386 - val_categorical_accuracy: 0.4533\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 2s 240us/step - loss: 0.3291 - categorical_accuracy: 0.9247 - val_loss: 3.2407 - val_categorical_accuracy: 0.4415\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 2s 227us/step - loss: 0.3433 - categorical_accuracy: 0.9275 - val_loss: 3.4001 - val_categorical_accuracy: 0.4384\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 2s 228us/step - loss: 0.2835 - categorical_accuracy: 0.9366 - val_loss: 3.8358 - val_categorical_accuracy: 0.4451\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 2s 227us/step - loss: 0.3203 - categorical_accuracy: 0.9384 - val_loss: 3.3790 - val_categorical_accuracy: 0.4266\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 2s 241us/step - loss: 0.3220 - categorical_accuracy: 0.9426 - val_loss: 3.8654 - val_categorical_accuracy: 0.4692\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 2s 230us/step - loss: 0.3311 - categorical_accuracy: 0.9388 - val_loss: 4.0909 - val_categorical_accuracy: 0.4035\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 2s 231us/step - loss: 0.2950 - categorical_accuracy: 0.9435 - val_loss: 4.1064 - val_categorical_accuracy: 0.4661\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 2s 230us/step - loss: 0.2965 - categorical_accuracy: 0.9483 - val_loss: 3.9834 - val_categorical_accuracy: 0.4815\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, input_length=x.shape[1]))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=5e-3),  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
