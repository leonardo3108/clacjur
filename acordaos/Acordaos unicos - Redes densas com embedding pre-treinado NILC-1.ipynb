{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>arquivo</th>\n",
       "      <th>areas</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>547240.txt</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 010.084/2015-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>549518.txt</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 005.933/2014-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>554399.txt</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 042.038/2012-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>545010.txt</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>TRIBUNAL DE CONTAS DA UNIÃO\\tTC 000.742/2014-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>544046.txt</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>;-;;Wania Lucia Pasquarelli do NascimentoTCUWa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao     arquivo               areas  \\\n",
       "0  297/2016-P  547240.txt    Responsabilidade   \n",
       "1  366/2016-P  549518.txt   Finanças Públicas   \n",
       "2  944/2016-P  554399.txt    Responsabilidade   \n",
       "3   30/2016-P  545010.txt  Direito Processual   \n",
       "4   55/2016-P  544046.txt             Pessoal   \n",
       "\n",
       "                                               texto  \n",
       "0  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 010.084/2015-0...  \n",
       "1  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 005.933/2014-5...  \n",
       "2  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 042.038/2012-0...  \n",
       "3  TRIBUNAL DE CONTAS DA UNIÃO\\tTC 000.742/2014-7...  \n",
       "4  ;-;;Wania Lucia Pasquarelli do NascimentoTCUWa...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-unicos.csv', sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['areas']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318318 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 320000\n",
    "limite_texto = 40000\n",
    "dim_vetor = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['texto'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['texto'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9739, 40000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model-50.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 318318\n",
      "Encontrados no modelo: 110315 = 34.655595976350696\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0311 01:45:35.436347 140657734137664 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding = Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9739, 40000), (9739, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento\n",
    "\n",
    "## Embedding com pesos fixos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0311 01:45:35.821992 140657734137664 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0311 01:45:35.898277 140657734137664 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0311 01:45:35.944079 140657734137664 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0311 01:45:35.945749 140657734137664 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0311 01:45:45.731803 140657734137664 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0311 01:45:45.775670 140657734137664 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0311 01:45:45.891288 140657734137664 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40000, 50)         16000000  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000000)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                128000064 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 144,019,274\n",
      "Trainable params: 128,019,274\n",
      "Non-trainable params: 16,000,000\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 43s 5ms/step - loss: 3.2851 - categorical_accuracy: 0.3097 - val_loss: 2.0062 - val_categorical_accuracy: 0.1910\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.9636 - categorical_accuracy: 0.3114 - val_loss: 1.9717 - val_categorical_accuracy: 0.1910\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.8959 - categorical_accuracy: 0.3127 - val_loss: 1.9754 - val_categorical_accuracy: 0.1910\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.8804 - categorical_accuracy: 0.3124 - val_loss: 1.9855 - val_categorical_accuracy: 0.1910\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.8583 - categorical_accuracy: 0.3161 - val_loss: 1.9362 - val_categorical_accuracy: 0.1910\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.8272 - categorical_accuracy: 0.3110 - val_loss: 1.9195 - val_categorical_accuracy: 0.1910\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.7876 - categorical_accuracy: 0.3209 - val_loss: 1.9135 - val_categorical_accuracy: 0.1555\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.7732 - categorical_accuracy: 0.3313 - val_loss: 1.8131 - val_categorical_accuracy: 0.2259\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.7416 - categorical_accuracy: 0.3441 - val_loss: 1.8811 - val_categorical_accuracy: 0.1766\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.7200 - categorical_accuracy: 0.3623 - val_loss: 1.8828 - val_categorical_accuracy: 0.1812\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.7020 - categorical_accuracy: 0.3671 - val_loss: 1.7997 - val_categorical_accuracy: 0.2248\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6639 - categorical_accuracy: 0.3858 - val_loss: 1.8708 - val_categorical_accuracy: 0.1771\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6636 - categorical_accuracy: 0.3874 - val_loss: 1.7762 - val_categorical_accuracy: 0.2377\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6705 - categorical_accuracy: 0.3880 - val_loss: 1.8948 - val_categorical_accuracy: 0.2428\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6415 - categorical_accuracy: 0.3998 - val_loss: 1.8695 - val_categorical_accuracy: 0.2556\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6426 - categorical_accuracy: 0.4007 - val_loss: 1.7806 - val_categorical_accuracy: 0.2336\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6236 - categorical_accuracy: 0.4139 - val_loss: 1.8118 - val_categorical_accuracy: 0.2094\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.6046 - categorical_accuracy: 0.4129 - val_loss: 1.8528 - val_categorical_accuracy: 0.1874\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.5989 - categorical_accuracy: 0.4152 - val_loss: 1.7354 - val_categorical_accuracy: 0.2490\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.5921 - categorical_accuracy: 0.4187 - val_loss: 1.7035 - val_categorical_accuracy: 0.2603\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/30\n",
      "7791/7791 [==============================] - 39s 5ms/step - loss: 1.5790 - categorical_accuracy: 0.4180 - val_loss: 1.7491 - val_categorical_accuracy: 0.2531\n",
      "Epoch 2/30\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.5787 - categorical_accuracy: 0.4213 - val_loss: 1.7150 - val_categorical_accuracy: 0.2562\n",
      "Epoch 3/30\n",
      "7791/7791 [==============================] - 38s 5ms/step - loss: 1.5657 - categorical_accuracy: 0.4223 - val_loss: 1.9301 - val_categorical_accuracy: 0.2669\n",
      "Epoch 4/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5667 - categorical_accuracy: 0.4270 - val_loss: 1.8647 - val_categorical_accuracy: 0.2726\n",
      "Epoch 5/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5629 - categorical_accuracy: 0.4250 - val_loss: 1.7065 - val_categorical_accuracy: 0.2613\n",
      "Epoch 6/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5519 - categorical_accuracy: 0.4309 - val_loss: 1.7423 - val_categorical_accuracy: 0.2618\n",
      "Epoch 7/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5619 - categorical_accuracy: 0.4282 - val_loss: 1.7117 - val_categorical_accuracy: 0.2572\n",
      "Epoch 8/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5543 - categorical_accuracy: 0.4284 - val_loss: 1.8719 - val_categorical_accuracy: 0.2741\n",
      "Epoch 9/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5684 - categorical_accuracy: 0.4310 - val_loss: 1.7076 - val_categorical_accuracy: 0.2675\n",
      "Epoch 10/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5603 - categorical_accuracy: 0.4282 - val_loss: 1.7232 - val_categorical_accuracy: 0.2731\n",
      "Epoch 11/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5540 - categorical_accuracy: 0.4311 - val_loss: 1.7351 - val_categorical_accuracy: 0.2654\n",
      "Epoch 12/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5516 - categorical_accuracy: 0.4349 - val_loss: 1.7015 - val_categorical_accuracy: 0.2521\n",
      "Epoch 13/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5456 - categorical_accuracy: 0.4337 - val_loss: 1.7139 - val_categorical_accuracy: 0.2464\n",
      "Epoch 14/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5426 - categorical_accuracy: 0.4343 - val_loss: 1.7144 - val_categorical_accuracy: 0.2685\n",
      "Epoch 15/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5438 - categorical_accuracy: 0.4308 - val_loss: 1.8611 - val_categorical_accuracy: 0.2721\n",
      "Epoch 16/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5415 - categorical_accuracy: 0.4334 - val_loss: 1.9207 - val_categorical_accuracy: 0.2736\n",
      "Epoch 17/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5413 - categorical_accuracy: 0.4359 - val_loss: 1.7171 - val_categorical_accuracy: 0.2644\n",
      "Epoch 18/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5318 - categorical_accuracy: 0.4369 - val_loss: 1.7175 - val_categorical_accuracy: 0.2490\n",
      "Epoch 19/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5293 - categorical_accuracy: 0.4395 - val_loss: 1.7596 - val_categorical_accuracy: 0.2731\n",
      "Epoch 20/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5438 - categorical_accuracy: 0.4377 - val_loss: 1.7143 - val_categorical_accuracy: 0.2546\n",
      "Epoch 21/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5340 - categorical_accuracy: 0.4397 - val_loss: 1.7195 - val_categorical_accuracy: 0.2433\n",
      "Epoch 22/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5291 - categorical_accuracy: 0.4406 - val_loss: 1.7212 - val_categorical_accuracy: 0.2562\n",
      "Epoch 23/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5297 - categorical_accuracy: 0.4381 - val_loss: 1.7220 - val_categorical_accuracy: 0.2510\n",
      "Epoch 24/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5423 - categorical_accuracy: 0.4337 - val_loss: 1.7476 - val_categorical_accuracy: 0.2444\n",
      "Epoch 25/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5328 - categorical_accuracy: 0.4399 - val_loss: 1.7211 - val_categorical_accuracy: 0.2474\n",
      "Epoch 26/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5259 - categorical_accuracy: 0.4388 - val_loss: 1.7185 - val_categorical_accuracy: 0.2505\n",
      "Epoch 27/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5129 - categorical_accuracy: 0.4432 - val_loss: 1.7501 - val_categorical_accuracy: 0.2541\n",
      "Epoch 28/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5208 - categorical_accuracy: 0.4403 - val_loss: 1.7077 - val_categorical_accuracy: 0.2541\n",
      "Epoch 29/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5301 - categorical_accuracy: 0.4364 - val_loss: 1.7142 - val_categorical_accuracy: 0.2592\n",
      "Epoch 30/30\n",
      "7791/7791 [==============================] - 37s 5ms/step - loss: 1.5375 - categorical_accuracy: 0.4347 - val_loss: 1.7693 - val_categorical_accuracy: 0.2664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=30, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
