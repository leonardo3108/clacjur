{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acordao</th>\n",
       "      <th>areas</th>\n",
       "      <th>filtrado_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>conta conta gerência instituto nacional seguro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366/2016-P</td>\n",
       "      <td>Finanças Públicas</td>\n",
       "      <td>senado petróleo petróleo regime aduaneiro expo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>944/2016-P</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>tribunal conta plenário embargo declaração aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/2016-P</td>\n",
       "      <td>Direito Processual</td>\n",
       "      <td>embargo declaração inss recorrente marco antôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55/2016-P</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>senac senac senac empresa senac giselle araújo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acordao               areas  \\\n",
       "0  297/2016-P    Responsabilidade   \n",
       "1  366/2016-P   Finanças Públicas   \n",
       "2  944/2016-P    Responsabilidade   \n",
       "3   30/2016-P  Direito Processual   \n",
       "4   55/2016-P             Pessoal   \n",
       "\n",
       "                                        filtrado_500  \n",
       "0  conta conta gerência instituto nacional seguro...  \n",
       "1  senado petróleo petróleo regime aduaneiro expo...  \n",
       "2  tribunal conta plenário embargo declaração aco...  \n",
       "3  embargo declaração inss recorrente marco antôn...  \n",
       "4  senac senac senac empresa senac giselle araújo...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dados/acordaos-unicos-filtrados-500.csv', sep = '|')\n",
    "df['filtrado_500']=df['filtrado_500'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Competência do TCU', 'Contrato Administrativo', 'Convênio',\n",
       "       'Desestatização', 'Direito Processual', 'Finanças Públicas',\n",
       "       'Gestão Administrativa', 'Licitação', 'Pessoal',\n",
       "       'Responsabilidade'], dtype='<U23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "areas = df.groupby(['areas']).groups.keys()\n",
    "lbArea = LabelBinarizer()\n",
    "lbArea.fit([x for x in areas])\n",
    "lbArea.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9739, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lbArea.transform(df['areas'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32293 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "vocabulario = 40000\n",
    "limite_texto = 500\n",
    "dim_vetor = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocabulario)\n",
    "tokenizer.fit_on_texts(df['filtrado_500'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['filtrado_500'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9739, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(sequences, maxlen=limite_texto)\n",
    "\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../externos/model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 32293\n",
      "Encontrados no modelo: 24014 = 74.3628650171864\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulario, dim_vetor))\n",
    "\n",
    "ok = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[i] = model[word]\n",
    "        ok += 1\n",
    "print('Vocabulario:', i)\n",
    "print('Encontrados no modelo:', ok, '=', ok * 100. / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9739, 500), (9739, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento\n",
    "\n",
    "## Embedding com pesos fixos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0317 11:18:20.807693 140283004180288 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0317 11:18:20.931797 140283004180288 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0317 11:18:20.933876 140283004180288 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0317 11:18:20.940917 140283004180288 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0317 11:18:20.941570 140283004180288 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0317 11:18:21.663737 140283004180288 deprecation.py:506] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0317 11:18:21.713837 140283004180288 deprecation_wrapper.py:119] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0317 11:18:21.809627 140283004180288 deprecation.py:323] From /home/leonardo/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          4000000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              102402048 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 106,929,162\n",
      "Trainable params: 102,929,162\n",
      "Non-trainable params: 4,000,000\n",
      "_________________________________________________________________\n",
      "Train on 7791 samples, validate on 1948 samples\n",
      "Epoch 1/20\n",
      "7791/7791 [==============================] - 32s 4ms/step - loss: 3.7354 - categorical_accuracy: 0.4536 - val_loss: 1.6207 - val_categorical_accuracy: 0.3819\n",
      "Epoch 2/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 1.3960 - categorical_accuracy: 0.5718 - val_loss: 1.4269 - val_categorical_accuracy: 0.5421\n",
      "Epoch 3/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 1.1277 - categorical_accuracy: 0.6347 - val_loss: 1.5541 - val_categorical_accuracy: 0.5313\n",
      "Epoch 4/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.9363 - categorical_accuracy: 0.6963 - val_loss: 1.5528 - val_categorical_accuracy: 0.5329\n",
      "Epoch 5/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.7873 - categorical_accuracy: 0.7432 - val_loss: 1.6619 - val_categorical_accuracy: 0.5205\n",
      "Epoch 6/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.6277 - categorical_accuracy: 0.7993 - val_loss: 1.9409 - val_categorical_accuracy: 0.4430\n",
      "Epoch 7/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.5039 - categorical_accuracy: 0.8425 - val_loss: 1.8554 - val_categorical_accuracy: 0.5139\n",
      "Epoch 8/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.3793 - categorical_accuracy: 0.8820 - val_loss: 2.5178 - val_categorical_accuracy: 0.4887\n",
      "Epoch 9/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.3259 - categorical_accuracy: 0.9058 - val_loss: 2.8348 - val_categorical_accuracy: 0.4872\n",
      "Epoch 10/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.2597 - categorical_accuracy: 0.9306 - val_loss: 2.6876 - val_categorical_accuracy: 0.4969\n",
      "Epoch 11/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.2124 - categorical_accuracy: 0.9401 - val_loss: 2.7361 - val_categorical_accuracy: 0.5082\n",
      "Epoch 12/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.2056 - categorical_accuracy: 0.9471 - val_loss: 3.2348 - val_categorical_accuracy: 0.4861\n",
      "Epoch 13/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1751 - categorical_accuracy: 0.9555 - val_loss: 2.7352 - val_categorical_accuracy: 0.4805\n",
      "Epoch 14/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1646 - categorical_accuracy: 0.9580 - val_loss: 3.2072 - val_categorical_accuracy: 0.4923\n",
      "Epoch 15/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1716 - categorical_accuracy: 0.9644 - val_loss: 3.6327 - val_categorical_accuracy: 0.4764\n",
      "Epoch 16/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1319 - categorical_accuracy: 0.9675 - val_loss: 3.1321 - val_categorical_accuracy: 0.5411\n",
      "Epoch 17/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1243 - categorical_accuracy: 0.9718 - val_loss: 3.6376 - val_categorical_accuracy: 0.4743\n",
      "Epoch 18/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1301 - categorical_accuracy: 0.9686 - val_loss: 3.7755 - val_categorical_accuracy: 0.4938\n",
      "Epoch 19/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1130 - categorical_accuracy: 0.9741 - val_loss: 3.6015 - val_categorical_accuracy: 0.4995\n",
      "Epoch 20/20\n",
      "7791/7791 [==============================] - 29s 4ms/step - loss: 0.1001 - categorical_accuracy: 0.9786 - val_loss: 4.1272 - val_categorical_accuracy: 0.4543\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulario, dim_vetor, weights=[embedding_matrix], input_length=limite_texto, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',  metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(x, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
